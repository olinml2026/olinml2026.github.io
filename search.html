<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.17.2 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<script>
class AnchorNoProxy extends HTMLElement {
  constructor() {
    super();
    this.attachShadow({ mode: "open" });
    this._$a = null;
  }
  connectedCallback() {
    const href = this.getAttribute("href") || "#";
    if (this.dataset.hasOwnProperty('canvas')) {
        const canvasURL = this.dataset.canvas;
        this.shadowRoot.innerHTML = `<style>a:hover, a:active { outline: 0; }\na { color: #5197ad; }\na:visited { color: #5197ad; }\na:hover { color: #266477; outline: 0; }</style><a href="${href}" data-canvas="${canvasURL}"><slot></slot></a>`;
    } else {
        this.shadowRoot.innerHTML = `<style>a:hover, a:active { outline: 0; }\na { color: #5197ad; }\na:visited { color: #5197ad; }\na:hover { color: #266477; outline: 0; }</style><a href="${href}"><slot></slot></a>`;
    }
    this._$a = this.shadowRoot.querySelector("a");
    this._$a.addEventListener("click", e => {
      var url = this.getAttribute('href');
      e.preventDefault();
      if (document.referrer.startsWith('https://lms.hypothes.is') && this.dataset.hasOwnProperty('canvas')) {
        // get rid of proxy if it was added
        var n = this.dataset.canvas.search('https://olin.instructure.com');
        window.open(this.dataset.canvas.substring(n), '_blank');
      } else {
        window.open(url, '_blank');
      }
    });
  }
  static get observedAttributes() { return ["href"]; }
  attributeChangedCallback(name, oldValue, newValue) {
    if (oldValue !== newValue) {
      if (this._$a === null) return;
      this._$a.setAttribute("href", newValue);
    }
  }
}

customElements.define("a-no-proxy", AnchorNoProxy);

class NoProxy extends HTMLAnchorElement {
  connectedCallback() {
    this.addEventListener("click", e => {
      e.preventDefault();
      if (document.referrer.startsWith('https://lms.hypothes.is') && this.dataset.hasOwnProperty('canvas')) {
        // get rid of proxy if it was added
        var n = this.dataset.canvas.search('https://olin.instructure.com');
      	window.open(this.dataset.canvas.substring(n), '_blank');
      } else {
      	window.open(this.href, '_blank');
      }
    });
  }
}

customElements.define("no-proxy", NoProxy, { extends: "a" });

class ConfirmLink extends HTMLAnchorElement {
  connectedCallback() {
    this.addEventListener("click", e => {
      const result = confirm(`Are you sure you want to go to '${this.href}'?`);
      if (!result) e.preventDefault();
    });
  }
}

customElements.define("confirm-link", ConfirmLink, { extends: "a" });

</script>

<!-- begin _includes/seo.html --><title>Search Results - Machine Learning Spring 2026 @ Olin College</title>
<meta name="description" content="Website">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Machine Learning Spring 2026 @ Olin College">
<meta property="og:title" content="Search Results">
<meta property="og:url" content="/search.html">


  <meta property="og:description" content="Website">












<link rel="canonical" href="/search.html">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": null,
      "url": "/"
    
  }
</script>






<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Machine Learning Spring 2026 @ Olin College Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->
<script src="https://cdn.jsdelivr.net/npm/mermaid@11.9.0/dist/mermaid.min.js"></script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css" integrity="sha384-ZPe7yZ91iWxYumsBEOn7ieg8q/o+qh/hQpSaPow8T6BwALcXSCS6C6fSRPIAnTQs" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js" integrity="sha384-ljao5I1l+8KYFXG7LNEA7DyaFvuvSCmedUf6Y6JI7LJqiu8q5dEivP2nDdFH31V4" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
<script>
    // https://github.com/KaTeX/KaTeX/blob/main/docs/autorender.md
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            // customised options
            // • auto-render specific keys, e.g.:
                delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false},
                {left: "\begin{equation}", right: "\end{equation}", display: true},
                {left: "\begin{align}", right: "\end{align}", display: true},
            ],
            // • rendering keys, e.g.:
            throwOnError : false
        });
    });
</script>


<script type="text/javascript">
function HideShowElement(divID) {
    const x = document.getElementById(divID);
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>
<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

    <link href="http://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css" rel="stylesheet">

<script type="text/javascript">
document.addEventListener('DOMContentLoaded', function() {
    const urlParams = new URLSearchParams(window.location.search);
    const showSolutions = urlParams.get('showSolutions');
    const showAllSolutions = urlParams.get('showAllSolutions');
    const divs = document.querySelectorAll('button.togglebutton');

    if (showSolutions == 'true') {
        // Loop through the selected divs and manipulate them
        divs.forEach(div => {
            div.removeAttribute('hidden');
        });
    }

    const solutionDivs = document.querySelectorAll('[id^=solution]');
    const subpartSolutionDivs = document.querySelectorAll('[id^=subpartsolution]');

    if (showAllSolutions == 'true') {
        solutionDivs.forEach(div => {
            console.log('test')
            div.style.display = 'block';
        });

        subpartSolutionDivs.forEach(div => {
            console.log('test')
            div.style.display = 'block';
        });
    }
});
</script>

<script type="text/javascript">
function HideShowElement(divID) {
    const x = document.getElementById(divID);
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>
<style>
:root {
    --box-bg-color: #fff; /* Default background color */
}

.homework-box {
    background-color: var(--box-bg-color);
    border: 2px solid #ccc;
    padding: 15px;
    border-radius: 10px;
    margin-bottom: 20px;
    width: 300px;
}

.homework-header {
    display: flex;
    align-items: center;
    margin-bottom: 10px;
    position: relative;
}

.homework-icon {
    width: 40px;
    height: 40px;
    margin-right: 10px;
}

/* Handle missing or empty src attribute */
.homework-icon[src=""],
.homework-icon:not([src]) {
    content: url('https://upload.wikimedia.org/wikipedia/commons/a/ab/Games_for_Learning_%2827470%29_-_The_Noun_Project.svg');
    width: 40px;
    height: 40px;
    margin-right: 10px;
}

.homework-title {
    margin: 0;
    font-size: 18px;
    font-weight: bold;
}

.homework-content {
    font-size: 16px;
    color: #333;
}
</style>

<style>
.solution {
    display: none; /* Hide solutions by default */
    background-color: #f9f9f9;
    padding: 10px;
    border-left: 4px solid #007bff;
    margin-top: 10px;
}

.toggle-button {
    background-color: #007bff;
    color: #fff;
    padding: 5px 10px;
    border: none;
    border-radius: 5px;
    cursor: pointer;
    margin-top: 10px;
    display: inline-block;
}

.toggle-button.hide-solution {
    background-color: #dc3545; /* Red background for hide button */
}

img.mermaid {
     max-width:500px;
     text-align: center;
}

</style>

<div style="display:none;">
$
\newcommand{\mlvec}[1]{\mathbf{#1}}
\newcommand{\mlmat}[1]{\mathbf{#1}}
\DeclareMathOperator*{\argmax}{arg\,max\,}
\DeclareMathOperator*{\argmin}{arg\,min\,}
$
</div>

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="https://qeacourse.github.io/RoboNinjaWarrior/website_graphics/olinlogo.png" alt=""></a>
        
        <a class="site-title" href="/">
          Machine Learning Spring 2026 @ Olin College
          
        </a>
        <ul class="visible-links"></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  

  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Search Results">
    
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Search Results
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
	      
                
	      	
            </nav>
          </aside>
        
        <div class="header-search">
  <form class="header-search-form" action="/search" method="get">
    <input type="text" id="search-box" name="query" />
    <input type="submit" value="search" />
  </form>
</div>

<!-- List where search results will be rendered -->
<ul id="search-results"></ul>

<script>
  // Template to generate the JSON to search
  window.store = {"404-html": {
        "title": "",
        "author": "",
        "category": "",
        "content": "  404  Page not found :(  The requested page could not be found.",
        "url": "/404.html"
      },"assignments-assignment16-imagesqad-html": {
        "title": "Quality Assessed Deliverable: Machine Learning with Images",
        "author": "",
        "category": "",
        "content": "Learning ObjectivesThe intent of this quality assessed deliverable is to demonstrate your understanding of a few key concepts from the Images as Data module (largely focusing on convolutional neural networks).Most of the questions pull directly or indirectly from your prior assignments. The intent here is to minimize the workload (assuming you have been keeping up on your assignments) and to revisit concepts from the assignments now that you have had a chance to ask questions in class.\t\t        \tLearning Objectives\t\t\t     Identify and explain key components of a convolutional neural network (CNN)  Create and apply filters like a CNN  Calculate the output size and values resulting from a given filter\tWill be a Canvas quiz.      a. Manually calculate the output matrix resulting from applying the following filter. Do not add padding.\\(\\begin{bmatrix}0 &amp; ~~~1 &amp; ~~~0 \\\\  1 &amp; -4 &amp; ~~~1 \\\\  0 &amp; ~~~1 &amp; ~~~0 \\\\  \\end{bmatrix}\\)to this image (via a convolution):\\(\\begin{bmatrix}0 &amp; 0 &amp; 0 &amp; 0 \\\\  0 &amp; 0 &amp; 50 &amp; 50 \\\\  0 &amp; 50 &amp; 50 &amp; 50 \\\\  0 &amp; 0 &amp; 50 &amp; 0 \\\\  \\end{bmatrix}\\)        b. What is the name for this kind of filter?    How many weights (parameters, excluding biases) need to be learned for a convolutional layer that starts with a 10x10x3 a.k.a a 10x10 RGB color image and results in an output with a size of 6x6x10, using no padding and a stride of 1?          Solution: This question requires knowledge of the effects of the filter size on output image size, knowledge that an RGB image has a depth of 3, knowledge that each filter on a color image has size fxfx3, knowledge of how stride affects output size.                  To go from a 10x10 to a 6x6 with a stride of 1 and no padding requires a 5x5 filter (losing 2 on each side).          Each filter (kernel) therefore is a 5x5x3, so 75 weights to be learned.          The output has 10 layers (channels), so there are 10 filters to be learned, so 75x10 = 750                    Common mistakes:                  If 250, you may have forgotten about the RGB part.          If 300*360 = 108000, then you’re probably doing a fully connected layer          if 25*7 = 175, then you may have misunderstood what happens with color images and a kernel.          if 270, then you assumed a filter size of 3x3 (ChatGPT 4o mini made this error)                                Compared to the situation in the previous question (convolutional layer), how would the number of weights change if you instead had a fully connected weights between each node in the input layer and each node in the output? a. The number of weights would increase significantly (fully connected weights needed are more than 10x what is needed for convolutional layer). b. The number of weights would increase somewhat (fully connected weights needed are less than 10x what is needed for convolutional layer). c. The number of weights would stay the same. d. The number of weights would decrease somewhat (convolutional layer weights needed are less than 10x what is needed for fully connected layer).  e. The number of weights would decrease significantly (convolutional layer weights needed are more than 10x what is needed for fully connected layer).Consider the following situations where 9 3x3 filters are applied to the following images (no padding):A. a 24x24 grayscale image with a stride of 1.B. a 24x24 grayscale image with a stride of 2.C. a 32x32 grayscale image with a stride of 2.      Rank order the number of nodes in the output from largest to smallest:a. A, then B, then Cb. A, then C, then Bc. A and B are the same, then Cd. B and C are the same, then Ae. B, then C, then Af. C, then B, then Ag. C, then A, then Bh. C, then A and B are the samei. They are all the same        Ignoring the bias term, rank order each situation based on the number of weights to be learned (from largest to smallest):a. A, then B, then Cb. A, then C, then Bc. A and B are the same, then Cd. B and C are the same, then Ae. B, then C, then Af. C, then B, then Ag. C, then A, then Bh. C, then A and B are the samei. They are all the same        Write code for a 5x5 filter that will result in any vertical edges showing up as positive values if the the edge is darker on the right and lighter on the left and as negative values if the edge is darker on the left and lighter on the right.  Apply no padding and use a stride of 1.  You should be able to copy your padding and apply filter code from Assignment 15 directly into this and then just add the filter. Please note that if you were getting a swirly looking penguin in Assignment 15, this was likely due to an issue with the datatype when you created the image. To solve this, you can either start with:image_filtered= np.zeros((output_size,output_size))or image_filtered = np.zeros_like(image, dtype = np.float32)  (this also gives you the wrong size for this exercise)If you’re still getting something like this, please reach out to us.https://colab.research.google.com/github/olinml2024/notebooks/blob/main/ML2024_ML_with_Images_As_Data_Manual_Convolutions.ipynbPut the values of your filter here.Upload the figure generated by your code here.  Match the loss curve to what is happening(shuffle these answers in the Canvas)      Generally, why are convolutional layers useful for image processing? Check all that apply. a. They reduce the number of weights in the model compared to a fully connected layer, reducing the number of parameters that the model needs to learn. b. They increase the number of weights in the model compared to a fully connected layer, allowing to model to learn more information. c. They preserve some of the spatial information of the image. d. They extract image features that are relevant for the task (e.g., classifying types of images). e. They extract tokens that minimize the variance. f. Convolutional layers detect objects by directly classifying each pixel as an object. g. Convolutional layers are useful for image processing because they treat each pixel individually without considering its neighbors.        In transfer learning for image processing, why are pre-trained models often fine-tuned? A. To make the model smaller and more efficientB. To adapt the model to specific features in the new datasetC. To replace all layers with random weightsD. To ignore the data used in the original training        In transfer learning, what does it mean to use a model as a “feature extractor”?  A. The model’s final layers are replaced to match the new task’s requirementsB. Only the output layer is trained while other layers are frozenC. All layers are re-trained to fit the new datasetD. The model’s earlier layers are used to extract general features, which are then used in a new model        What is one potential drawback of using transfer learning for an image processing model?A. It requires significantly more data than training from scratchB. It can be harder to interpret and understand the model’s decisionsC. It prevents the model from learning new featuresD. It is only effective for small-scale image processing tasks  ",
        "url": "/assignments/assignment16/ImagesQAD.html"
      },"assignments-assignment09-learningasoptimizationtakeaways-html": {
        "title": "Learning as Optimization - Key takeaways",
        "author": "",
        "category": "",
        "content": "  Big picture structural things          Supervised learning problem setup (X, y, model, and loss)      Training, validation, and testing      Feature engineering - you can pre-process datasets, augment datasets, and even transform data to represent non-linear information in a linear model      Model parameters can be turned to reduce loss. This is done using partial derivatives &amp; gradients. We use gradient descent for this optimization.        Linear regression          The model - prediction as a weighted sum of the inputs      Squared loss - explain/interpret the loss function (e.g., draw a picture of what this measures)        Logistic regression          The model - linear regression and the sigmoid function to map to a probability in a binary case      Log loss - Explain scenarios when a model and examples would give a high or low loss. Compute the log loss of a model given model predictions (probabilities) and ground truth        Multilayer perceptrons / Neural networks          Adding layers can increase your model’s ability to fit the data, can reduce the need for feature engineering, and can increase your chances of overfitting.      Drawings of neural networks can be mapped to a series of weighted sums and non-linear functions. These weighted sums can be represented as matrix multiplications, dot products, or summation loops. You should be able to map between drawings of a multilayer perceptron and the layers that you would construct in PyTorch.      In neural networks, backpropagation is the application of the chain rule for computing the partial derivatives of the model’s loss with respect to the weights of the network. This can be automated using the concept of dataflow diagrams. Draw a simple data flow diagram and calculate partial derivatives.      ",
        "url": "/assignments/assignment09/LearningAsOptimizationTakeaways.html"
      },"assignments-assignment01-assignment01-html": {
        "title": "Assignment 1",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Gain some familiarity with some of the key ideas in machine learning and the machine learning lifecycle.  Explore metrics to assess machine learning classifiers.  Review of mathematical concepts we will be using in the beginning part of this course.  Familiarize yourself with computational tools for machine learning, including python.This document contains a lot of external links. They are there to helpyou learn more if you are interested. You are not required to read/watchall the linked material.\tThere is a substantial Jupyter notebook that is part of your assignment linked at the end of this document. Just warning you here so you can avoid thinking that you’re almost done, only to realize that you’re only halfway finished.Please read the syllabusThe syllabus is available on Canvas. Please read it, it contains a lotof helpful information. There will be an ungraded competitive gamearound what’s in the syllabus in the next class! If you have anyquestions about the syllabus, please post them on the Slack so we canclarify (and practice using Slack as a class). Or if it is a personalquestion, you can always email us or catch us after class.Fill Out Some Surveys                        \tExercise 1    \tBefore we get into the semester, we’d like to understand how you all think abouttopics such as X, Y, an Z.  Please fill out the surveys (it should take about 20 minutes).Note: that these surveys can be used as part of an education research project we are doing this semester that you have the option to participate in.    Show / Hide Solution    Solution     Join the Slack if you wantWe’ll have an optional course-wide Slack workspace for asking questions. Of course you can always go to office hours and send emails, but Slack can make it easier to create a thread about a specific question. The link to join Slack is found on the syllabus. Good thing you just read the syllabus!The Machine Learning LifecycleIn class, we explored aspects of the machine learning lifecycle. Please continue to read through this short article to continue to build your sense of the big picture (about 10 minutes).Types of ML and general ML workflowWe will talk about some types of machine learning and the general machine learning workflow.There are a few different ways to categorize machine learning problems, but most texts will reference the three main types of machine learning problems.Supervised LearningIn supervised learning, you are given a training set of data points and corresponding desired outputs.  Let’s use \\(\\mathbf{x}_i\\) to denote the \\(i\\)th training input and $y_i$ to denote the $i$th training output.  The training set is composed of \\(\\mathbf{X}_{train} = \\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_N\\) and \\(\\mathbf{y}_{train} = y_1, y_2, \\ldots, y_N\\), where $y_i$ is the label for the $i^{th}$ individual example (sometimes called a datapoint, training instance, or sample) and \\(\\mathbf{x}_i\\) contains the features (input information) for that sample.In the classic examples, $\\mathbf{x}_i$ will be a vector of features and $y_i$ will be a scalar label. We’ll talk about when this type of problem shows up and how the problem changes depending on the values that $y_i$ can take on.A supervised machine learning algorithm can take as input $\\mathbf{X}_{train}$ and produce a model capable of taking in an unseen datapoint, $\\mathbf{x}_{test}$, and estimating the corresponding label, $y_{test}$.  In order to evaluate the quality of these predictions, you'll want to have a set of test points, $\\mathbf{X}_{test}$ to compute a relevant performance metrix (as we did in assignment 1).graph TB;    id1[X Train and y Train];    id2[Supervised Learning Algorithm];    id3[Predictive Model];    id4[X Test and y Test]    id5[Model Metrics]    id1 --&gt; id2;    id2 --&gt; id3;    id4 --&gt; id3;    id3 --&gt; id5;In addition to having a test set, you may also use a validation set to help tune your machine learning model.  We’ll talk a bit about how this would work.Unsupervised LearningIn unsupervised learning, you are given set a of data points (there are no corresponding outputs).  The training set is $\\mathbf{X}_{train} = \\mathbf{x}_1, \\mathbf{x}_2 \\ldots, \\mathbf{x}_N$.In an unsupervised learning problem, our goal is to understand something about the structure of these training points.  For example, perhaps the data lies in some low dimensional subspace (sounding a little familiar?).  Examples of problems that fit under unsupervised learning are clustering, sequence learning (e.g., as is done in language models), and dimensionality reduction.Reinforcement LearningReinforcement learning involves an agent learning to interact with an environment in an optimal fashion.  We won’t define notation for reinforcement learning as we aren’t planning to cover it in this class (it could be a great final project).  Examples of reinforcement learning problems would be an agent learning to play a game (e.g., Chess), a robot learning to interact with its environment, or even determining treatment regimes in a clinical setting.  The reinforcement learning book has a bunch of sample applications if you are curious.Six Big Ideas in Machine LearningNote: We suggest you timebox this section to a maximum of 60 minutesto start, including the exercise. Beware of the many interesting rabbitholes that could consume your day. You can always revisit this later.Before diving into the specifics of our first machine learningalgorithm, let’s examine some important ideas in machine learning.Idea 1: Correlations for the Win?ML algorithms learn to exploit correlations in data in order to makepredictions. For instance, if one was using an ML algorithm to recognizewhether someone was smiling in an image, the algorithm might learn thatbright pixels around the mouth region are correlated with smiles (e.g.,these bright pixels could indicate that a person’s teeth are showing). This correlation wouldlikely be useful for determining whether a new image of a face was of a smiling person (or not).Now suppose you take this model and apply it to a newdataset. You may find that faces that are angry are mistakenly marked assmiling! Why? In the case of angry facial expressions the teeth may alsobe showing. Of course you would expect the learning algorithm to besmart enough to realize that just using the presence of teeth is notenough to conclusively determine whether someone is smiling. Whether ornot this actually happens is a function of the training data given tothe ML algorithm. If, for instance, the training set was scraped fromprofile pictures from a dating website, the training set may not containpictures of angry faces. Unfortunately, while exploiting correlations isone of the most powerful aspects of ML systems, it is also one of themost potentially problematic.Example 1: Reinforcing Hiring Biases You may have heard that Amazonscrapped a secret AI recruiting tool that showed bias againstwomen.More specifically, the tool performed automatic keyword analysis of jobapplications to predict whether or not the applicant was worthforwarding on to a human for further evaluation. Early in thedevelopment of this system researchers discovered that the model thesystem had learned placed a negative weight on words such as “women’s”as well as the names of some women’s colleges. While there is of courseno causal link between these words appearing in a job application andthe suitability of the candidate for the job, there was a correlationin the training set between the presence of words such as “women’s” andthe candidates not being invited for interviews.Why might such a correlation exist in the training set? There are manydifferent possible explanations for this correlation, ranging from overtor unconscious bias in the applicant evaluators whose judgments helpedform the training data to systemic discrimination that denies womenequal access to educational opportunities in STEM. The important thingto take away from this is not why there was a correlation, but thatthe existence of the correlation in the training data caused the modelto utilize the correlation in order to evaluate new data. Amazonrealized that this was very bad and decided to take steps to address theproblem (they say they never used the system to make actualjob-screening decisions). Despite efforts to prevent the algorithm forexploiting such correlations, the group determined that they couldn’tfully guarantee that the algorithm had not found another way to achievethe same discriminatory outcome and terminated the project.A more modern example of the Amazon AI recruiting tool the task of detecting and mitigating bias in large language models (LLMs).  Researchers are hard at work creating additional methods to mitigate and detect biases in these models (you might consider skimming the linked article for a high-level picture of what this looks like in practice.)Example 2: Adversarial Machine LearningA second example of an ML algorithm exploiting correlations in trainingdata in unexpected ways can be found in computer vision methods forobject detection. Identifying salient visual objects such as road signsand pedestrians is an important building block for applications such asautonomous cars. A popular algorithm for this task,YOLO (You Only Look Once)1, canidentify and localize objects in images with surprising accuracy. Forinstance, in the image below YOLO identified the stop sign in the imagesuccessfully.While this all seems great, there is a catch. It is very difficult tounderstand how YOLO is making these predictions. That is, what is itabout this image that causes the YOLO algorithm to be able to tell thatit is a stop sign? Perhaps it is the white text on the red background.Perhaps it is the word “STOP.” In fact, the network that makes thisprediction is so complex, that it is impossible for us to saydefinitively exactly how it makes its decision. What we do know is thatthe model exploits correlations in the training data between inputfeatures (pixels) and outputs (object locations) in potentiallyunpredictable ways.                            Figure 1: A stop sign with a specially crafted sticker that causes a neural network to fail to identify it as a stop sign.    The complexity of the model makes it vulnerable to bad actors (oradversaries). Researchers at University of Michigan used a form of MLknown as adversarial machine learning to create a specially craftedsticker that could be attached to a stop sign that would make itinvisible to the YOLOmodel(that is YOLO would not identify it as a stop sign). Clearly, this hasmajor implications for the safety of using a model such as this in anapplication like a self-driving car. An example of the attack is shownin Figure 1.Idea 2: There’s No Such Thing as a Free Lunch  “All models are wrong, but someuseful.”  — George BoxAt the beginning of this document we have a reminder of the basicsupervised machine learning setup. A one sentence statement of the setupis that we try to generalize from a set of training data to construct afunction $\\hat{f}^\\star$ that best predicts the corresponding outputdata for unseen input data (e.g., predicting the facial expression of aface that was not in the training set based on a training set of samplefaces). In the previous big idea, we discussed how machine learningcould go wrong when there are correlations in the data that seem usefulto the ML algorithm but are ultimately counterproductive to how we’dlike the system to make decisions. It turns out that even before youchoose the training data for your algorithm, you must provide aninductive bias toconstrain the space of possible models you might fit. Examples of commoninductive biases include the following (the previously linked articlehas some more).The prediction function $\\hat{f}^\\star$ should change smoothly as youvary the input $\\mathbf{x}$.The prediction function has a particular form (e.g., linear).The prediction function is sparse (it ignores the majority of theinputs).In fact, there are a whole class of theorems called No-Free-Lunch (NFL)theorems thatstate that without inductive biases (such as the ones stated above),learning from data is essentially impossible. This connects us back tothe quote from George Box. While the inductive bias we encode into ourmodel will never fully represent reality, having this bias is necessaryto allow the model to do the useful work of making predictions. What’simportant for us as machine learning scientists and practitioners is tobe explicit about the biases we are introducing when settling on aparticular model so that we can best evaluate our results and predictthe limitations of our systems.Idea 3: It’s All About How You Frame the ProblemUsing Machine Learning algorithms can be a bit disorienting for someoneused to the typical engineering workflow. A cartoon picture of theengineering workflow is that you are given a problem (perhaps it isinitially difficult to solve or ambiguous), you might reframe theproblem to make it easier to solve, and then you work to devise asolution to the reframed problem. In machine learning, the last step isreplaced by providing examples of how you’d like your system to work(i.e., input / output pairs), and then the creation of the actual systemis automated by the ML algorithm! Your job as an ML practitioner is toreframe the original problem (both by specifying the form of the modeland giving appropriate training data) so that the ML algorithm cancompute a solution. If you’ve done the reframing properly, the solutionto the reframed problem will also be a good solution to the originalproblem.As an example of when a solution to the reframed problem would not bedesirable, consider the use of a machine learning algorithm to teach avirtual character to walk in a simulated environment. You might reframethis problem for the ML algorithm as tasking it with computing acontroller for the virtual character that moves the character’s centerof mass forward as fast as possible. The ML algorithm can now searchover a vast space of possible control strategies to learn the one thatmost quickly propels the center of mass. However, it doesn’t necessarilyfollow that this controller will result in the character walking using anormal bipedal gait.The notion that the solution an algorithm finds might be unpredictableto the designer is known as “emergence.” Some cool examples of thisplayed out in actual experiments in evolving virtual creatures, whichare summarized in the paper The Surprising Creativity of DigitalEvolution. For instance, avirtual character learned that falling down, see picture above, andgetting up was more efficient for locomotion than constantly hopping(which is what the designer had intended the system to learn).For more examples of this sort of thing, consider checking out KarlSims: Evolved VirtualCreatures or the shortarticle When AI SurprisesUs.This also connects back to the age-old debate over whether falling withstyle can be consideredflying.Idea 4: ML Systems Can Learn Intermediate RepresentationsIn the next few weeks we’ll learn about artificial neural networks(ANNs). ANNs are biologically inspired algorithms since theirfunctioning, at an abstract level, is modeled on the functioning ofbiological neurons (e.g., in the brain).                            Figure 2: An artificial neural network with a single hidden layer.    ANNs accept input patterns at an array of virtual neurons called theinput layer (see Figure 2). The neurons in the input layer are connected toother neurons via virtual axonsthat control to what extent a particular input neuron activates adownstream neuron. The second set of neurons, called the “hidden layer”(shown in blue in the middle of the figure), is responsible forcomputing intermediate, hidden representations of the input data. Thisprocess continues as activations propagate through the network untilactivations are generated at the output layer (shown in green on theright of the figure). These outputs could correspond to any salientproperties of the input (e.g., if the input is an image, the outputmight encode the objects in the image).What’s amazing about ANNs is that there are learning algorithms forsetting the connection strengths between these virtual neurons (theblack arrows in Figure 2) based on training data (input / output pairs).These learning algorithms tune the connections strengths (also called“weights”) such that for the provided training data the network producesthe appropriate training outputs (e.g., if you show the network atraining set of images of cats or dogs, over time the network willadjust its weights so that the output is “cat” when the network ispresented an image of a cat and “dog” if presented an image of a dog).The algorithms used to tune the network weights are only concerned withreproducing the output patterns, the network is free to choose how itrepresents information within the network (i.e., at the hidden layer).                            Figure 3: 12x12 receptive fields learned from an neural network trained to optimally compress images    What’s super amazing is that we can actually examine the internalrepresentations of a neural network to understand how it’s performingthe computation from input to output. For instance, Figure 32 shows a visualization of the internalrepresentations learned by a network trained to best compress a trainingset of images (these sorts of networks are called “auto-encoders”). Thereceptive fields of each of the hidden units in the network and can beunderstood as specifying how each input pixel activates a particularhidden unit (gray corresponds to no activation, black to negativeactivation, and white to positive activation). It’s remarkable thatthese receptive fields have coherent structure: they are localized inspace, tuned to particular orientations, and tuned to features at aparticular scale. You can think of these as oriented edge detectors thatthe network learned completely on its own (it was never told to extractedges from the images in the training set).What’s super-duper amazing is that if we compare the receptive fieldslearned by the artificial neural network to the simplecells in the primary visualcortex of a cat, there are a number of striking similarities. Just as inthe ANN, the biological neural network responds to edges at particularorientations and scales. The scientists Hubel and Wiesel performed thepioneering work in neuroscience to establish the properties of receptivefields in the primary visual cortex. Consider watching a video of theirexperiment that eventuallygarnered a Nobel prize (note that in the video the static soundcorresponds to the measurement of spikes in activity of an individualneuron in the brain of an anesthetized cat).3. The implication of thesimilarity between the receptive fields of the neurons in the cat brainand the virtual neurons in the ANN is that they are similar because theyare fundamentally solving the same problem (i.e., efficientlyrepresenting visual information). In this light, that they should findsimilar solutions to this problem is not as surprising as it may firstseem.Idea 5: Machine Learning Zoomed OutHistorically, most ML courses have been laser-focused on learning aboutlearning algorithms (e.g., neural networks, support vector machines,decision trees, etc.). In some courses there would be a little bit ofemphasis on machine learning applications, which have always beenstrongly tied to the research in ML algorithms and theory. The focus onML algorithms also reflected the positioning of these courses withinComputer Science curricula, which approached the field more from aliberal arts perspective rather than an engineering one.A number of recent trends have made the almost sole focus on learningalgorithms insufficient for those who want to either use ML in theircareers or go into ML as a field.The explosion of data has made the skills necessary for collecting,wrangling, exploring, and cleaning data very relevant.Improvements in the accuracy of ML algorithms coupled with the abilityto deploy ML systems to a wide variety of devices (e.g., mobile phones)means that it is increasingly important to consider how ML systems willbehave in real-world, highly complex settings.The first point ties into a set of skills sometimes grouped under “DataScience.” While we will have a comparatively lesser focus on thisskillset than in our dedicated Data Science course, we will be learningsome of these skills. The second point corresponds to ML systems asembedded in larger and more complex contexts. As you’ve seen from someof the examples earlier in this document, unexpected things can happenwhen ML algorithms meet messy and/or biased real world data (take forexample the automated job applicant evaluator). In light of this, again,we think that the traditional focus on ML algorithms is not adequate fora modern class on ML. Here are two figures to further illustrate thispoint.In the figure above, the box labeled ML Code is the actual learningalgorithm. But in modern systems, this is but a small fraction of all ofthe tools needed to deploy a real world ML system. This is not to saythat we will be spending a lot of time learning about each of theseother boxes (we will learn about some of them), but it helps to have asense of the software ecosystem in which your ML model would bedeployed.In addition to understanding how ML code is situated within largersoftware ecosystems, it is even more important to realize thesocio-technicalcontext in whichan ML system is deployed. The figure above shows a socio-technicalanalysis of a technology. The figure highlights the need to considercontextual factors such as user impacts, culture, and regulations whenanalyzing technologies.Using the tools of socio-technical systems analysis is becomingincreasingly popular for analyzing machine learning systems. We’ll bedigging into some of these resources later in the course, but here aretwo papers in this spirit.Reframing AIDiscourseFairness and Abstraction in SociotechnicalSystemsIdea 6: It’s Not All Doom and GloomWhile we’ll be talking a lot about how ML can go wrong, unleashingunexpected consequences, we’ll also be talking about the positive thingsthat ML can do. Here are just a couple of resources that discuss suchsystems (not to say that these systems don’t have the potential forthings to go wrong!). We’ll leave this list deliberately short to giveyou a chance to find your own example in the exercise below.  Some of these examples are a little old, but they are still good starting points.  AI for social good: 7 inspiringexamples  While not without controversy, some companies (and researchers) are working on Enhancing Accessibility with AI and ML.  19 Times Data Analysis Empowered Students andSchools  Austin Veseliza put together a list of links to AI for social goodprojectsthat you might use for inspiration.4                        \tExercise 2    \tNow, we want to hear from you!Part AChoose one of the big ideas above and write a short response to it. Yourresponse could incorporate something surprising you read, athought-provoking question, your personal experience, an additionalresource that builds upon or shifts the discussion. We hope that thisreflection will help scaffold class discussions and get you thinkingabout your interests in the big space that is ML. Also, you have licensefrom us to customize the structure of your response as you see fit. As arough guide, you should aim for a response of a 1-2 paragraphs.Show / Hide Solution    SolutionThere’s no one right answer here!Part BIdea 6 talks about the idea of ML for positive impact. What is oneexample of an ML application (real or imagined) that you think wouldhave the largest (or most unambiguously) positive impact on the world?Why? Alternatively, what is an example of an ML application (real orimagined) that no matter how carefully the designers approach it, shouldjust not exist due to the harm it would cause the world? Why?Show / Hide Solution    SolutionThere’s no one right answer here!Mathematical BackgroundWe’ll be using some math in this class that you’ve probably seen before (but maybe that has faded into a distant memory). We are giving you a little heads up here to give you ample time to refresh before we actually start using this math. Even if most of these concepts feel pretty new or unfamiliar, you still belong in this class (feel free to reach out to us if you have questions).\t\t        \tNotice\t\t\t   For the purposes of this class, we will try to be consistent with the notationwe use. Of course, when we link to other resources, they may use othernotation. If notation is different in a way that causes confusion, wewill try to point out pitfalls you should watch out for. Please use thislink to access our guide to our notationconventions\t\t\t        \tExternal Resources\t\t\t   In order to engage with this and future assignments, you’ll want to makesure you are familiar with the concepts (links to resourcesembedded below):      Vector-vector multiplication: Section 2.1 of Zico Kolter’s Linear Algebra Review andReference    Matrix-vector multiplication          Section 2.2 of Zico Kolter’s Linear Algebra Review andReference      The first bits of the Khan academy video on LinearTransformations        Partial derivatives and gradients          Khan Academy videos on partial derivatives:intro,graphicalunderstanding,and formaldefinition      Khan Academy video onGradient      \t                        \tExercise 3    \tWork through these math exercises to figure out which of the topics above you need to spend some more time on.Part ASuppose $f(x, y) = 2x \\sin{y} + y^2 x^3$. Calculate$\\frac{\\partial{f}}{\\partial{x}}$, $\\frac{\\partial{f}}{\\partial{y}}$,and $\\nabla f$.Show / Hide Solution    Solution\\[\\begin{align}\\frac{\\partial{f}}{\\partial{x}} &amp;= 2 \\sin y + 3 y^2 x^2 \\\\ \\frac{\\partial{f}}{\\partial{y}} &amp;= 2x \\cos y + 2 y x^3 \\\\ \\nabla f &amp;= \\begin{bmatrix} 2 \\sin y + 3 y^2 x^2 \\\\ 2x \\cos y + 2 y x^3 \\end{bmatrix} \\end{align}\\]Part BSuppose $\\mathbf{x} = \\begin{bmatrix} 3 \\ -1 \\ 4 \\end{bmatrix}$ and$\\mathbf{y} = \\begin{bmatrix} 2 \\  7 \\ 4 \\end{bmatrix}$. Calculate$\\mathbf{x} \\cdot \\mathbf{y}$, $\\mathbf{x}^\\top \\mathbf{y}$, and$\\mathbf{x} \\mathbf{y}^\\top$.Show / Hide Solution    Solution\\[\\begin{align*}\\mathbf{x} \\cdot \\mathbf{y} &amp;= 3 \\times 2 + -1 \\times 7 + 4 \\times 4 = 15 \\\\ \\mathbf{x}^\\top \\mathbf{y} &amp;= \\mathbf{x} \\cdot \\mathbf{y} = 15 \\\\ \\mathbf{x} \\mathbf{y}^\\top &amp;= \\begin{bmatrix} 3 \\times 2 &amp; 3 \\times 7 &amp; 3 \\times 4 \\\\ -1 \\times 2 &amp; -1 \\times 7 &amp; -1 \\times 4 \\\\ 4 \\times 2 &amp; 4 \\times 7 &amp; 4 \\times 4 \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} 6 &amp; 21 &amp; 12 \\\\ -2 &amp; -7 &amp; -4 \\\\ 8 &amp; 28 &amp; 16 \\end{bmatrix}\\end{align*}\\]Part CLet \\(\\mathbf{A} = \\begin{bmatrix} \\mathbf{a_1} &amp; \\mathbf{a_2} &amp; \\ldots &amp; \\mathbf{a_n} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{row}_1 \\\\ \\mathbf{row}_2 \\\\ \\vdots \\\\ \\mathbf{row}_m \\end{bmatrix}\\)where each $\\mathbf{row_{i}}$ is a row vector (vectors in this class will default to being column vectors, so here we’re giving it a special name to indicate it’s a row vector).So, the matrix $\\mathbf{A}$ can either be thought of as consistingof the columns $\\mathbf{a_1}, \\ldots, \\mathbf{a_n}$ or the rows$\\mathbf{row_1}, \\ldots, \\mathbf{row_m}$.Let $\\mathbf{v}$ be an arbitrary $n$-dimensional vector.Compute $\\mathbf{A}\\mathbf{v}$ in terms of$\\mathbf{a_1}, \\ldots, \\mathbf{a_n}$.Show / Hide Solution    Solution\\[\\begin{aligned}\\mathbf{A} \\mathbf{v} &amp;= v_1 \\mathbf{a}_1 + v_2 \\mathbf{a}_2 + \\ldots + v_n \\mathbf{a}_n\\end{aligned}\\]Part DCompute $\\mathbf{A} \\mathbf{v}$ in terms of the rows of$\\mathbf{row_1}, \\ldots, \\mathbf{row_m}$.Show / Hide Solution    Solution\\[\\begin{aligned}\\mathbf{A} \\mathbf{v} &amp;= \\begin{bmatrix} \\mathbf{v} \\cdot \\mathbf{row}_1 \\\\   \\mathbf{v} \\cdot \\mathbf{row}_2 \\\\ \\vdots \\\\ \\mathbf{v} \\cdot \\mathbf{row}_m \\end{bmatrix}\\end{aligned}\\]Key Metrics for Assessing ClassifiersThe last part of this assignment is to meet some key metrics for assessing classification models while also getting our python brains warmed up for the coding in this class.Please work through the exercises in this Jupyter notebook: https://colab.research.google.com/drive/1MxD0SFsR9g0FGBhii34hu7qusM_AECj5?usp=sharingIt’s hosted on Google Colab, so you can either make your own copy and run it on Colab or download and run it locally (you may have to make small tweaks).Footnotes            A Cool video of YOLO version3,a TED talk from the creator of YOLOresearcher, andnewer variants of YOLO have been created by other researchers &#8617;              From Sparse coding of sensoryinputs &#8617;              There are a variety of opinions on the ethics of performingresearch onanimals &#8617;              This list was part of the original version of this assignment,made in 2019. We are glad we can remember one of the many goodthings Austin created at Olin. &#8617;      ",
        "url": "/assignments/assignment01/assignment01.html"
      },"assignments-assignment02-assignment02-html": {
        "title": "Assignment 2",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Compare several models and evaluate which, if any, are suitable for a task.  Learn how image transformations can be used for augmenting test data.  Upload data to Google Colab for model evaluation.\tModel AnalysisIn this assignment we are going to continue to work with the dessert classification problem (thanks again Ayush and Jess for putting this together!).  The work for this assignment is entirely contained with the Assignment 2 Notebook.  Enjoy!",
        "url": "/assignments/assignment02/assignment02.html"
      },"assignments-assignment03-assignment03-html": {
        "title": "Assignment 3",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Learn linear regression from three angles:          “top-down” (big picture, visual)      “bottom-up” (mathematical derivation)      computational (implementing in python)        build python skills of dealing with data and writing functions\tSupervised Learning Problem SetupSuppose you are given a training set of data points, $(\\mathbf{x_1}, y_1), (\\mathbf{x}_2, y_2), \\ldots, (\\mathbf{x}_n, y_n)$ where each $\\mathbf{x_i}$ represents an element of an input space (e.g., a d-dimensional feature vector) and each $y_i$ represents an element of an output space (e.g., a scalar target value).  We will consider $\\mathbf{x_i}$ to be a row vector of size 1 x d, representing each of the feature values for one sample/exemplar, as this will make our lives easier when we get more data points.  In the supervised learning setting, your goal is to determine a function $\\hat{f}$ that maps from the input space to the output space.  For example, if we provide an input $\\mathbf{x}$ to $\\hat{f}$ it would generate the predicted output $\\hat{y} = \\hat{f}(\\mathbf{x})$.We typically also assume that there is some loss function, $\\ell$, that determines the amount of loss that a particular prediction $\\hat{y_i}$ incurs due to a mismatch with the actual output $y_i$.  We can define the best possible model, $\\hat{f}^\\star$ as the one that minimizes these losses over the training set.  This notion can be expressed with the following equation  (note: that $\\argmin$ in the equation below just means the value that minimizes the expression inside of the $\\argmin$, e.g., $\\argmin_{x} (x - 2)^2 = 2$, whereas $\\min_{x} (x-2)^2 = 0$).\\begin{align}\\hat{f}^\\star &amp;= \\argmin_{\\hat{f}} \\sum_{i=1}^n \\ell \\left ( \\hat{f}(\\mathbf{x_i}), y_i \\right )\\end{align}Linear Regression from the Top-DownMotivation: Why Learn About Linear Regression?Before we jump into the what of linear regression, let’s spend a little bit of time talking about the why of linear regression.  As you’ll soon see, linear regression is among the simplest (perhaps the simplest) machine learning algorithm.  It has many limitations, which you’ll also see, but also a of ton strengths.  First, it is a great place to start when learning about machine learning since the algorithm can be understood and implemented using a relatively small number of mathematical ideas (you’ll be reviewing these ideas later in this assignment).  In terms of the algorithm itself, it has the following very nice properties.  Transparent: it’s pretty easy to examine the model and understand how it arrives at its predictions.  Computationally tractable: models can be trained efficiently on datasets with large numbers of features and data points.  Easy to implement: linear regression can be implemented using a number of different algorithms (e.g., gradient descent, closed-form solution).  Even if the algorithm is not built into your favorite numerical computation library, the algorithm can be implemented in only a couple of lines of code.For linear regression our input data, $\\mathbf{x_i}$, are d-dimensional row vectors (each entry of these vectors can be thought of as a feature), our output data, $y_i$, are scalars, and our prediction functions, $\\hat{f}$, are all of the form $\\hat{f}(\\mathbf{x}) =\\mathbf{x} \\cdot \\mathbf{w} = \\mathbf{x} \\mathbf{w} = \\sum_{i=1}^d x_i w_i$ for some vector of weights $\\mathbf{w}$ (you could think of $\\hat{f}$ as also taking $\\mathbf{w}$ as an input, e.g., writing $\\hat{f}(\\mathbf{x}, \\mathbf{w}$).  Most of the time we’ll leave $\\mathbf{w}$ as an implicit input: writing $\\hat{f}(\\mathbf{x})$).In the function, $\\hat{f}$, the elements of the vector $\\mathbf{w}$ represent weights that multiply various dimensions (features) of the input.  For instance, if an element of $\\mathbf{w}$ is high, that means that as the corresponding element of $\\mathbf{x}$ increases, the prediction that $\\hat{f}$ generates would also increase (you may want to mentally think through other cases, e.g., what would happen is the element of $\\mathbf{x}$ decreases, or what would happen if the entry of $\\mathbf{w}$ was large and negative).  The products of the weights and the features are then summed to arrive at an overall prediction.Given this model, we can now define our very first machine learning algorithm: ordinary least squares (OLS)!  In the ordinary least squares algorithm, we use our training set to select the $\\mathbf{w}$ that minimizes the sum of squared differences between the model’s predictions and the training outputs.  Thinking back to the supervised learning problem setup, this corresponds to choosing $\\ell(y, \\hat{y}) = (y - \\hat{y})^2$.Therefore, the OLS algorithm will use the training data to select the optimal value of $\\mathbf{w}$ (called $\\mathbf{w}^\\star$), which minimizes the sum of squared differences between the model’s predictions and the training outputs.\\[\\begin{align*}\\mathbf{w}^\\star &amp;= \\argmin_{\\mathbf{w}} \\sum_{i=1}^n \\ell \\left ( \\hat{f}(\\mathbf{x_i}, \\mathbf{w}) , y_i \\right) \\\\&amp;= \\argmin_{\\mathbf{w}} \\sum_{i=1}^n \\left ( \\hat{f}(\\mathbf{x_i}, \\mathbf{w}) - y_i \\right)^2 \\\\ &amp;= \\argmin_{\\mathbf{w}} \\sum_{i=1}^n \\left ( \\mathbf{x_i} \\mathbf{w} - y_i \\right)^2\\end{align*}\\]\t\t        \tNotice\t\t\t   Digesting mathematical equations like this can be daunting, but your understanding will be increased by unpacking them carefully.  Make sure you understand what was substituted and why in each of these lines.  Make sure you understand what each symbol represents.  If you are confused, ask for help (e.g., post on Slack).\tBelow, we will talk about how to find $\\mathbf{w}^\\star$, for now we’ll just assume we have it.  With $\\mathbf{w}^\\star$, we can predict a value for a new input sample, $\\mathbf{x_i}$, by predicting the corresponding (unknown) output, $y_i$, as $\\hat{y_i} = \\mathbf{x_i} \\mathbf{w^\\star}$. Because $\\mathbf{x_i}$ is a row vector, this is equivalent to the dot product. At this point, we have used the training data to learn how to make predictions about unseen data, which is the hallmark of supervised machine learning!                        \tExercise 1    \tDraw a scatter plot in 2D (the x-axis is the independent variable and the y-axis is the dependent variable).  In other words, draw five or so data points, placed wherever you like. Next, draw a potential line of best fit, a straight line that is as close to your data points.  On the plot mark the vertical differences between the data points and the line (these differences are called the residuals).  Draw a second potential line of best fit and mark the residuals.  From the point of view of ordinary least-squares, which of these lines is better (i.e. has the smallest residuals)?    Show / Hide Solution    SolutionThe red line (line 1) would be better since the residuals are generally smaller.  Line 2 also has several large residuals, which when squared will cause a large penalty for line 2.     Getting a Feel for Linear RegressionIn this class we’ll be learning about algorithms using both a top-down and a bottom-up approach.  By bottom-up we mean applying various mathematical rules to derive a solution to a problem and only then trying to understand how to apply it and how it well it might work for various problems.  By top-down we mean starting by applying the algorithm to various problems and through these applications gaining a sense of the algorithm’s properties.  We’ll start our investigation of linear regression using a top-down approach.Linear Regression with One Input Variable: Line of Best FitIf any of what we’ve said so far sounds familiar, it is likely because you have seen the idea of a line of best fit in some previous class.  To understand more intuitively what the OLS algorithm is doing, we want you to investigate its behavior when there is a single input variable (i.e., you are computing a line of best fit).                        \tExercise 2    \tUse the line of best fit online app to create some datasets, guess the line of best fit, and then compare the results to the OLS solution (line of best fit).Part AExamine the role that outliers play in determining the line of best fit.  Does OLS seem sensitive or insensitive to the presence of outliers in the data?Show / Hide Solution    SolutionOLS is very sensitive to outliers.  A single outlier can change the slope of the line of best fit dramatically.  Here is an example of this phenomenon.Part BWere there any times when the line of best fit didn’t seem to really be “best” (e.g., it didn’t seem to capture the trends in the data)?Show / Hide Solution    SolutionThis could happen for many reasons.  If the dataset is pieceweise linear (e.g., composed of multiple line segments), if it has some other non-linear form (e.g., if it is quadratic), or if there are outliers.Linear Regression from the Bottom-UpNow that we’ve built a little intuition on linear regression, we’ll be diving into the mathematics of how to find the vector $\\mathbf{w}^\\star$ that best fits a particular training set.  The outline of the steps we are going to take to learn this are:  Solve the special case of linear regression with a single input ($d=1$, meaning a 1-dimensional feature vector).  Learn some mathematical tricks for manipulating matrices and vectors and computing gradients of functions involving matrices and vectors (these will be useful for solving the general case of linear regression).  Solve the general case of linear regression (where $d$ can be any positive, integer value).Linear regression with one variable                        \tExercise 3    \tPart AGiven a dataset $(x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)$ (where each $x_i$ and each $y_i$ is a scalar) and a potential value of $w$ (note that $w$ is a scalar in the case where $d=1$), write an expression for the sum of squared errors between the model predictions, $\\hat{f}$, and the targets, $y_i$.  Note: In contrast to the line of best fit we saw above, here we are not computing a y-intercept (so we are effectively forcing the y-intercept to be $0$).  This choice may result in a worse fit, but it is easier to work out and helps build mathematical intuition.Show / Hide Solution    Solution\\[\\text{Sum of Squared Errors} = e(w) = \\sum_{i=1}^n \\left (  x_i w - y_i \\right)^2~~  \\\\  \\text{(note: we define error $e(w)$ for convenience)}\\]Part BCompute the derivative of the expression for the sum of squared errors from part (a).Show / Hide Solution    Solution\\[\\begin{align}\\frac{de}{dw} &amp; = \\sum_{i=1}^n 2 \\left ( x_i w  - y_i \\right)x_i   \\\\  &amp;= w \\sum_{i=1}^n 2 x_i^2 - \\sum_{i=1}^n 2 x_i y_i\\end{align}\\]Part CSet the derivative to 0, and solve for $w^\\star$.  $w^\\star$ corresponds to a critical point of your sum of squared errors function.  Is this critical point a minimum, maximum, or neither? (here is a refresher on classifying critical points).Show / Hide Solution    Solution\\[\\begin{align}\\frac{de}{dw} &amp;= 0 \\\\&amp;= w^\\star \\sum_{i=1}^n 2 x_i^2 - \\sum_{i=1}^n 2 x_i y_i   \\\\\\sum_{i=1}^n 2 x_i y_i  &amp;= w^\\star \\sum_{i=1}^n 2 x_i^2  \\\\  w^\\star &amp;=\\frac{\\sum_{i=1}^n x_i y_i}{\\sum_{i=1}^n x_i^2}\\end{align}\\]If we take the second derivative of $e(w)$ we get:\\[\\begin{align}\\frac{d^2e}{dw^2} &amp;= \\sum_{i=1}^n 2x_i^2 \\enspace .\\end{align}\\]We can see from the form of the second derivative that it is always non-negative, and therefore the critical point at $w^\\star$ corresponds to a minimum.Reminder of mathematical ideasIn a previous assignment, we asked you to solidify your knowledge of three different mathematical concepts.  The box below summarizes what you were supposed to learn and provides the resources we provided to help you.\t\t        \tExternal Resources\t\t\t         Vector-vector multiplication: Section 2.1 of Zico Kolter’s Linear Algebra Review andReference    Matrix-vector multiplication          Section 2.2 of Zico Kolter’s Linear Algebra Review andReference      The first bits of the Khan academy video on LinearTransformations        Partial derivatives and gradients          Khan Academy videos on partial derivatives:intro,graphicalunderstanding,and formaldefinition      Khan Academy video onGradient      \tBuilding our bag of mathematical tricksThe derivation of linear regression for the single variable case made use of your background from single variable calculus, and you used some rules for manipulating such functions.  When approaching linear regression with multiple variables, you have two choices.  You can apply the same bag of tricks you used for the single variable problem and only at the end convert things (necessarily) to a multivariable representation.  You can approach the whole problem from a multivariable perspective.This second approach requires that you learn some additional mathematical tricks, but once you learn these tricks, the derivation of linear regression is very straightforward.  The secondary benefit of this approach is that the new mathematical tricks you learn will apply to all sorts of other problems.                        \tExercise 4    \tA quadratic form can be expressed in matrix-vector form as $\\mathbf{x}^\\top \\mathbf{A} \\mathbf{x}$.  Written this way, it looks very mysterious, but in this exercise you’ll build some intuition about what the expression represents. Further, it turns out that expressions like this show up in all sorts of places in machine learning.   To get a better understanding of what a quadratic form is (we’ll see what it’s good for later), watch this Khan Academy video.After you’ve watched the Khan academy video, answer these questions.Note: This $\\mathbf{x}$ is a generic column vector, not the $\\mathbf{x_i}$ sample vector of features that we were talking about above. We are using the generic $\\mathbf{x}$ here to align with the way most resources explain this form.Part AMultiply out the expression $\\begin{bmatrix} x_1 \\ x_2 \\ x_3 \\end{bmatrix}^\\top \\begin{bmatrix} a_{1,1} &amp; a_{1,2} &amp; a_{1,3} \\ a_{2,1} &amp; a_{2,2} &amp; a_{2,3} \\ a_{3,1} &amp; a_{3,2} &amp; a_{3,3} \\end{bmatrix}\\begin{bmatrix} x_1 \\ x_2 \\ x_3 \\end{bmatrix}$.Show / Hide Solution    Solution\\[\\begin{align}\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}^\\top \\begin{bmatrix} a_{1,1} &amp; a_{1,2} &amp; a_{1,3} \\\\ a_{2,1} &amp; a_{2,2} &amp; a_{2,3} \\\\ a_{3,1} &amp; a_{3,2} &amp; a_{3,3} \\end{bmatrix}\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} =&amp;  \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}^\\top \\begin{bmatrix} a_{1,1} x_1 + a_{1,2} x_2 + a_{1,3} x_3 \\\\ a_{2,1} x_1 + a_{2,2} x_2 + a_{2,3} x_3 \\\\ a_{3,1} x_1 + a_{3,2} x_2 + a_{3,3} x_3 \\end{bmatrix}  \\\\  = a_{1,1} x_1^2 + a_{1,2}x_1x_2 + a_{1,3} x_1 x_3 + a_{2,1}x_1 x_2 + a_{2,2} x_2^2  \\nonumber \\\\&amp;+ a_{2,3} x_2 x_3 + a_{3,1} x_3 x_1 + a_{3,2} x_3 x_2 + a_{3,3} x_3^2\\end{align}\\]Part BComplete the following expression by filling in the part on the righthand side inside the nested summation.$\\begin{bmatrix} x_1 \\ x_2 \\ \\vdots \\ x_d \\end{bmatrix}^\\top \\begin{bmatrix} a_{1,1} &amp; a_{1,2} &amp; \\ldots &amp; a_{1,d} \\ a_{2,1} &amp; a_{2,2} &amp; \\ldots &amp; a_{2,d} \\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\ a_{d,1} &amp; a_{d,2} &amp; \\ldots &amp; a_{d,d} \\end{bmatrix}\\begin{bmatrix} x_1 \\ x_2 \\ \\vdots \\ x_d \\end{bmatrix} = \\sum_{i=1}^d \\sum_{j=1}^d \\left (\\text{your answer here} \\right )$Show / Hide Solution    Solution\\[\\begin{align}\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\end{bmatrix}^\\top \\begin{bmatrix} a_{1,1} &amp; a_{1,2} &amp; \\ldots &amp; a_{1,d} \\\\ a_{2,1} &amp; a_{2,2} &amp; \\ldots &amp; a_{2,d} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{d,1} &amp; a_{d,2} &amp; \\ldots &amp; a_{d,d} \\end{bmatrix}\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\end{bmatrix} &amp;= \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\end{bmatrix}^\\top \\begin{bmatrix} \\sum_{j=1}^d a_{1,j} x_j \\\\ \\sum_{j=1}^d a_{2,j} x_j  \\\\ \\vdots \\\\ \\sum_{j=1}^d a_{d,j} x_j \\end{bmatrix}  \\\\   &amp;= \\sum_{i=1}^d \\sum_{j=1}^d a_{i,j}  x_i x_j\\end{align}\\]                        \tExercise 5    \tMatrix multiplication distributes over addition.  That is, $(\\mathbf{A} + \\mathbf{B}) (\\mathbf{C} + \\mathbf{D}) = \\mathbf{A}\\mathbf{C} + \\mathbf{A}\\mathbf{D} + \\mathbf{B} \\mathbf{C} + \\mathbf{B} \\mathbf{D}$.  Use this fact coupled with the fact that $\\left(\\mathbf{A} \\mathbf{B} \\right)^\\top = \\mathbf{B}^\\top \\mathbf{A}^\\top$ to expand out the following expression.\\[\\left ( \\mathbf{A} \\mathbf{x}  + \\mathbf{y} \\right )^\\top \\left (\\mathbf{v} + \\mathbf{u} \\right)\\]    Show / Hide Solution    Solution\\[\\left ( \\mathbf{A} \\mathbf{x}  + \\mathbf{y} \\right )^\\top \\left (\\mathbf{v} + \\mathbf{u} \\right) = \\mathbf{x}^\\top \\mathbf{A}^\\top \\mathbf{v} + \\mathbf{x}^\\top \\mathbf{A}^\\top \\mathbf{u} + \\mathbf{y}^\\top \\mathbf{v} + \\mathbf{y}^\\top \\mathbf{u}\\]                             \tExercise 6    \tPart AUsing the definition of the gradient, show that $\\nabla \\mathbf{c}^\\top \\mathbf{x} = \\mathbf{c}$ where the gradient is taken with respect to $\\mathbf{x}$ and $\\mathbf{c}$ is a vector of constants.If you want a hint, but not the full solution, you can click on the “solution” for the hint section below.Show / Hide Solution    Solution\\[\\begin{align}\\mathbf{c}^\\top \\mathbf{x} &amp;= \\sum_{j=1}^d c_j x_j  \\\\  \\frac{\\partial}{\\partial x_i}  \\sum_{j=1}^d c_j x_j  &amp;= c_i  \\\\  \\nabla \\mathbf{c}^\\top \\mathbf{x} &amp;= \\mathbf{c}\\end{align}\\]Part A hintShow / Hide Solution    SolutionStart by writing out the multiplication in the summation form. Then think about the partial derivative with respect to some $i^{th}$ element of $\\mathbf{x}$.Part BUsing the definition of the gradient, show that the $\\nabla \\mathbf{x}^\\top \\mathbf{A} \\mathbf{x} = 2 \\mathbf{A} \\mathbf{x}$ where the gradient is taken with respect to $\\mathbf{x}$, and $\\mathbf{A}$ is a symmetric $dxd$ matrix of constants.Hint: utilize the fact that $\\mathbf{x}^\\top \\mathbf{A} \\mathbf{x} = \\sum_{i=1}^d\\sum_{j=1}^d x_i x_j a_{i, j}$.If you are stuck and want a hint, but not the full solution, you can click on the “solution” for the hint section below.Show / Hide Solution    Solution\\[\\begin{align}\\mathbf{x}^\\top \\mathbf{A} \\mathbf{x} =&amp; \\sum_{i=1}^d\\sum_{j=1}^d   x_i  x_j  a_{i, j} &amp;\\nonumber  \\\\   \\frac{\\partial \\mathbf{x}^\\top \\mathbf{A} \\mathbf{x}}{\\partial x_k} &amp;= \\sum_{i=1}^d\\sum_{j=1}^d   a_{i,j} \\left ( \\frac{\\partial{x_i }}{\\partial x_k} x_j  +  x_i \\frac{\\partial{x_j}}{\\partial x_k} \\right)  \\text{    } \\text{apply the  product rule} \\nonumber   \\\\    &amp;= \\sum_{i=1}^d\\sum_{j=1}^d   a_{i,j}  \\frac{\\partial{x_i }}{\\partial x_k} x_j +   \\sum_{i=1}^d\\sum_{j=1}^d  a_{i,j}  x_i \\frac{\\partial{x_j}}{\\partial x_k}  \\text{      }\\text{ split into two summations} \\nonumber   \\\\     &amp;= \\sum_{j=1}^d   a_{k,j}  x_j +   \\sum_{i=1}^d a_{i,k}  x_i  \\text{      }\\text{take partial derivatives, many terms are 0} \\nonumber   \\\\   &amp;=  \\sum_{j=1}^d   a_{k,j}  x_j +   \\sum_{i=1}^d a_{k,i}  x_i  \\text{      } \\text{ since $\\mathbf{A}$ is symmetric, $a_{i,j} = a_{j,i}$} \\nonumber   \\\\   &amp;= 2  \\sum_{j =1}^d a_{k,j}  x_j \\text{      } \\text{the two summations are the same} \\nonumber   \\\\   &amp;= 2 \\mathbf{row}_k^\\top \\mathbf{x} \\text{         } \\text{this is the dot product between $\\mathbf{x}$ and the $k$th row of $\\mathbf{A}$} \\nonumber   \\\\   \\nabla \\mathbf{x}^\\top \\mathbf{A} \\mathbf{x} &amp;= 2 \\mathbf{A}\\mathbf{x} \\text{         }   \\text{stacking up the partials gives this form} \\nonumber\\end{align}\\]Part B hintShow / Hide Solution    SolutionYou can use the concepts in the first part of this exercise to expand things out to a summation.After a little work, you should reach something that looks like:\\(\\frac{\\partial \\mathbf{x}^\\top \\mathbf{A} \\mathbf{x}}{\\partial x_k} = \\sum_{i=1}^d\\sum_{j=1}^d   a_{i,j}  \\frac{\\partial{x_i }}{\\partial x_k} x_j +   \\sum_{i=1}^d\\sum_{j=1}^d  a_{i,j}  x_i \\frac{\\partial{x_j}}{\\partial x_k}\\)Then, think about how you can simplify the iteration in the summation because of the terms that are zero.Linear Regression with Multiple Variables                        \tExercise 7    \tConsider the case where $\\mathbf{w}$ is a $d$-dimensional vector.  We will represent our $n$ training inputs as an $n \\times d$ matrix $\\mathbf{X} = \\begin{bmatrix} \\mathbf{x}_1 \\ \\mathbf{x}_2 \\ \\vdots \\ \\mathbf{x}_n \\end{bmatrix}$, where here we are again treating $\\mathbf{x_i}$ as a row vector containing the $d$ features for a single exemplar of our dataset. We will store our $n$ training outputs as an $n$-dimensional vector $\\mathbf{y} = \\begin{bmatrix} y_1 \\ y_2 \\ \\vdots \\ y_n \\end{bmatrix}$.In order to solve this problem, you’ll be leveraging some of the new mathematical tricks you picked up early in this assignment.  As you go through the derivation, make sure to treat vectors as first-class objects (e.g., work with the gradient instead of the individual partial derivatives).Part AGiven $\\mathbf{w}$, write an expression for the vector of predictions \\(\\mathbf{\\hat{y}} = \\begin{bmatrix} \\hat{f}(\\mathbf{x}_1) \\\\  \\hat{f}(\\mathbf{x}_2) \\\\  \\vdots \\\\  \\hat{f}(\\mathbf{x}_n)\\end{bmatrix}\\) in terms of the training input matrix $\\mathbf{X}$ (Hint: you should come up with something very simple).Show / Hide Solution    Solution\\[\\mathbf{\\hat{y}} = \\begin{bmatrix} \\mathbf{x_1}  \\mathbf{w} \\\\ \\mathbf{x_2} \\mathbf{w} \\\\ \\vdots \\\\ \\mathbf{x_n} \\mathbf{w} \\end{bmatrix} = \\mathbf{X} \\mathbf{w}\\]Part BWrite an expression for the sum of squared errors for the vector $\\mathbf{w}$ on the training set in terms of $\\mathbf{X}$, $\\mathbf{y}$, and $\\mathbf{w}$.  Hint: you will want to use the fact that $\\sum_{i=1} v_i^2 = \\mathbf{v} \\cdot \\mathbf{v} = \\mathbf{v}^\\top \\mathbf{v}$.  Simplify your expression by distributing matrix multiplication over addition (don’t leave terms such as $\\left (\\mathbf{u} +\\mathbf{v}  \\right ) \\left ( \\mathbf{d} + \\mathbf{c} \\right)$ in your answer).Show / Hide Solution    Solution\\[\\begin{align}\\text{Sum of Squared Errors} &amp;= \\sum_{i=1}^n \\left ( \\hat{y}_i - y_i \\right)^2  \\\\  &amp;= \\left (\\mathbf{\\hat y} - \\mathbf{y} \\right)^\\top  \\left (\\mathbf{\\hat y} - \\mathbf{y} \\right)  \\\\  &amp;=\\left ( \\mathbf{X} \\mathbf{w} - \\mathbf{y} \\right)^\\top  \\left ( \\mathbf{X} \\mathbf{w} - \\mathbf{y} \\right)  \\\\  &amp;= \\mathbf{w}^\\top \\mathbf{X}^\\top \\mathbf{X} \\mathbf{w} - 2 \\mathbf{w}^\\top \\mathbf{X}^\\top \\mathbf{y} + \\mathbf{y}^\\top \\mathbf{y}\\end{align}\\]Part CCompute the gradient of the sum of squared errors that you found in part (b) with respect to $\\mathbf{w}$.  Make sure to use the results from the previous exercises to compute the gradients.Show / Hide Solution    Solution\\[\\begin{align}\\nabla \\text{Sum of Squared Errors}  &amp;= 2 \\mathbf{X}^\\top \\mathbf{X} \\mathbf{w} - 2 \\mathbf{X}^\\top \\mathbf{y}\\end{align}\\]Part DSet the gradient to 0, and solve for $\\mathbf{w}$ (note: you can assume that $\\mathbf{X}^\\top \\mathbf{X}$ is invertible).  This value of $\\mathbf{w}$ corresponds to a critical point of your sum of squared errors function.  We will show in a later assignment that this critical point corresponds to a global minimum.  In other words, this value of $\\mathbf{w}$ is guaranteed to drive the sum of squared errors as low as possible.Show / Hide Solution    Solution\\[\\begin{align}\\nabla \\text{Sum of Squared Errors}  &amp;= 0  \\\\  &amp;= 2 \\mathbf{X}^\\top \\mathbf{X} \\mathbf{w} - 2 \\mathbf{X}^\\top \\mathbf{y}  \\\\  \\mathbf{w} &amp;= \\left ( \\mathbf{X}^\\top \\mathbf{X} \\right )^{-1} \\mathbf{X}^\\top \\mathbf{y}\\end{align}\\]Linear Regression in Python                        \tExercise 8    \tPlease note that this part is of non-trivial length (likely 2-5 hours).Work through the Assignment 3 Companion Notebook to get some practice with numpy and explore linear regression using a top-down approach.  You can place your answers directly in the Jupyter notebook so that you have them for your records.    Show / Hide Solution    SolutionThe solutions can be found directly in the notebook.     ",
        "url": "/assignments/assignment03/assignment03.html"
      },"assignments-assignment04-assignment04-html": {
        "title": "Assignment 4",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Implement variations of linear regression on a dataset  Explore the effects of penalizing for weight size (ridge regression)  Contemplate confounding variables and Simpson’s paradox  Learn about log loss for binary classification\tLinear Regression and Ridge Regression AppliedSo far, you have experimented two types of supervised learning: classification and regression. You worked through the derivation of linear regression. We are going to start this assignment by applying linear regression to our bike share dataset. You will find and plot residuals, practice splitting your data into a training and testing set, and apply a fancy twist on linear regression called ridge regression.                        \tExercise 1    \tWork through this notebook . Long link: https://colab.research.google.com/drive/1Lc9xK8W29lLhEvWQW-1MFXivKJpEIdqL?usp=sharing    Show / Hide Solution    SolutionSolutions in the notebook.     Ridge Regression MathIn the Companion Notebook, you manipulated the value of lambda ($\\lambda$) to change the penalty for having large weights. One way to mitigate the problem of having two little data or having features that are linear combinations of each other is to modify the linear regression problem to prefer solutions that have small weights.  We do this by penalizing the sum of the squares of the weights themselves.  This is called ridge regression (or Tikhonov regularization).  Below, we show the original version of ordinary least squares along with ridge regression.Ordinary least squares:\\[\\begin{align}\\mathbf{w^\\star} &amp;= \\argmin_\\mathbf{w} \\sum_{i=1}^n \\left ( \\mathbf{w}^\\top \\mathbf{x_i} - y_i \\right)^2  \\\\  &amp;= \\argmin_\\mathbf{w} \\left ( \\mathbf{X}\\mathbf{w} - \\mathbf{y} \\right)^\\top \\left ( \\mathbf{X}\\mathbf{w} - \\mathbf{y} \\right)\\end{align}\\]Formula for the optimal weights in linear regression:\\[\\begin{align}\\mathbf{w^\\star} = \\left ( \\mathbf{X}^\\top \\mathbf{X} \\right)^{-1} \\mathbf{X}^\\top \\mathbf{y}\\end{align}\\]Ridge regression (note that $\\lambda$ is a non-negative parameter that controls how much the algorithm cares about fitting the data and how much it cares about having small weights):\\[\\begin{align}\\mathbf{w^\\star} &amp;= \\argmin_\\mathbf{w} \\sum_{i=1}^n \\left ( \\mathbf{w}^\\top \\mathbf{x_i} - y_i \\right)^2 + \\lambda\\sum_{i=1}^d w_i^2  \\\\  &amp;= \\argmin_\\mathbf{w} \\left ( \\mathbf{X}\\mathbf{w} - \\mathbf{y} \\right)^\\top \\left ( \\mathbf{X}\\mathbf{w} -  \\mathbf{y} \\right) + \\lambda \\mathbf{w}^\\top \\mathbf{w}\\end{align}\\]The penalty term may seem a little arbitrary, but it can be motivated on a conceptual level pretty easily.  The basic idea is that in the absence of sufficient training data to suggest otherwise, we should try to make the weights small.  Small weights have the property that changes to the input result in minor changes to our predictions, which is a good default behavior.                        \tExercise 2    \tDerive an expression to compute the optimal weights, $\\mathbf{w^\\star}$, to the ridge regression problem.Note: we may have gone over this already in class. You don’t need to write the whole thing out again if we covered it, but please review your notes to make sure you understand what’s going on.Part - first hintThis is very, very similar to an exercise you did on the last assignment. You can click the slow solution button below this for a hint.Show / Hide Solution    SolutionIf you follow the same steps as you did in the exercise on linear regression with multiple variables from assignment 3, you’ll arrive at an expression that looks like this (note: $\\mathbf{I}_{d \\times d}$ is the $d$ by $d$ identity matrix).\\[\\mathbf{w^\\star} = \\argmin_\\mathbf{w} \\mathbf{w}^\\top \\mathbf{X}^\\top \\mathbf{X} \\mathbf{w} - 2\\mathbf{w}^\\top \\mathbf{X}^\\top \\mathbf{y} + \\mathbf{y}^\\top \\mathbf{y} + \\lambda \\mathbf{w}^\\top  \\mathbf{I}_{d \\times d} \\mathbf{w}\\]Part  - another hintIf you want another hint, click on this solutionShow / Hide Solution    SolutionTo get $\\mathbf{w^\\star}$, take the gradient, set it to 0 and solve for $\\mathbf{w}$.Part  - Full SolutionOkay, now check against the full solution.Show / Hide Solution    Solution\\[\\begin{align*}\\mathbf{w^\\star} &amp;= \\argmin_\\mathbf{w} \\left ( \\mathbf{X}\\mathbf{w} - \\mathbf{y} \\right)^\\top \\left ( \\mathbf{X}\\mathbf{w} -  \\mathbf{y} \\right) + \\lambda \\mathbf{w}^\\top \\mathbf{w} &amp; \\\\&amp;= \\argmin_\\mathbf{w} \\mathbf{w}^\\top \\mathbf{X}^\\top \\mathbf{X} \\mathbf{w} - 2\\mathbf{w}^\\top \\mathbf{X}^\\top \\mathbf{y} + \\mathbf{y}^\\top \\mathbf{y} + \\lambda \\mathbf{w}^\\top  \\mathbf{I}_{d \\times d} \\mathbf{w} &amp; \\\\&amp;= \\argmin_{\\mathbf{w}} \\mathbf{w}^\\top \\left ( \\mathbf{X}^\\top \\mathbf{X} + \\lambda \\mathbf{I_{d \\times d}} \\right )\\mathbf{w} - 2\\mathbf{w}^\\top \\mathbf{X}^\\top \\mathbf{y} + \\mathbf{y}^\\top \\mathbf{y} &amp; \\\\0&amp;= 2 \\left (  \\mathbf{X}^\\top \\mathbf{X} + \\lambda \\mathbf{I_{d \\times d}} \\right ) \\mathbf{w^\\star} - 2 \\mathbf{X}^\\top \\mathbf{y} &amp; \\textit{(take the gradient and set to 0)}  \\\\\\\\\\mathbf{w}^\\star &amp;= \\left ( \\mathbf{X}^\\top \\mathbf{X} + \\lambda \\mathbf{I_{d \\times d}} \\right)^{-1} \\mathbf{X}^\\top \\mathbf{y} &amp; \\textit{(solve for \\(\\mathbf{w}^\\star\\))}\\end{align*}\\]Confounding variablesYou may have observed that some variables in the bikeshare data were correlated with each other. When dealing with data, we must be aware of the relationships of our variables and potential confounds. This matters both when we are creating our models and when we are interpreting our models. Hic sunt dracones.                        \tExercise 3    \tPart APlease watch this video on Simpson’s Paradox. Explain what happen’s in Simpson’s paradox.Show / Hide Solution    SolutionSee the video.Part BPlease come up with an example of Simpson’s paradox that was not mentioned in the video. You don’t have to know for sure that your example falls in to Simpson’s paradox– a reasonable suspicion of a confounding variable is fine. Please describe the paradox and the confounding variable that you suspect. This is a simple question, but it may be challenging to answer. If you are stuck, you might consider studies related to diet or health, the pandemic, or statistics related to elections. You may look up recent studies or articles to spark your imagination. We discourage you from Googling or just asking a large language model for “Simpson’s paradox examples”… the point is to think. It’s okay if you’re not right.Show / Hide Solution    SolutionSimpson’s paradox has to do with a lurking or confounding variable that isn’t accounted for.The Classification ProblemSo far in this class we’ve looked at supervised learning problems including a quick look at classification and a deeper look at regression. In regression, the responses $y_i$ are continuous-valued and the loss function is quadratic ($\\ell(y, \\hat{y}) = (y-\\hat{y})^2$).  There are many times, however, where it is unnatural to frame a problem as a regression.  For instance, it may be the case that $y_i$ does not come from a continuous range but instead can only take on a few different values.  This sort of problem is known as a classification problem.  For instance, you might want to have a system that takes in an image of a person and predicts their identity.  The identity could be thought of as the output, $y_i$, and it would only make sense for $y_i$ to be one of several values (e.g., each value might represent a particular person the system was trained to recognize).  In this next section, you’ll learn about a special case of the classification problem known as binary classification (where $y_i$ is either 0 or 1, e.g., a Sam versus Paul recognizer).In this course, we will formalize the binary classification problem and see a very useful algorithm for solving it called logistic regression.  You will also see that the logistic regression algorithm is a very natural extension of linear regression.  Our plan for getting there is going to be pretty similar to what we did for linear regression.  Build some mathematical foundations  Introduce logistic regression from a top-down perspective  Learn about logistic regression from a bottom-up perspectiveIn this assignment, we will focus on building the mathematical foundations, specifically learning about loss functions.Formalizing the Classification ProblemLet’s start by making the binary classification problem more formal.  Suppose, we are given a training set, $(\\mathbf{x_1}, y_1), (\\mathbf{x_2}, y_2), \\ldots, (\\mathbf{x_n}, y_n)$, where each $\\mathbf{x_i}$ is an element of the input space (e.g., a vector) and each $y_i$ is a binary number (either 1 or 0).  In this setting we will attempt to use the training data to determine a function, $\\hat{f}^\\star$, that predicts the corresponding output, $y$, for any possible input, $\\mathbf{x}$.  For example,  $\\mathbf{x}$ could be an image and $y_i$ could be $1$ when the picture contains a puppy and $0$ otherwise.                        \tExercise 4    \tPart AGiven this partial setup of the binary classification problem, we still need to specify the loss function, $\\ell$.  Recall that $\\ell$ takes as input the actual output $y$, and the predicted output $\\hat{y}$.  What function could you use for $\\ell$ that would result in the learning algorithm choosing a good model?  If the choice of $\\ell$ depends on the application, how so?Show / Hide Solution    SolutionAn easy choice is to output a $1$ if the values don’t match and a $0$ otherwise (essentially counting the number of mistakes the model makes).  Alternatively, you could have different penalties for a false positive (the model says $\\hat{y} = 1$, but the actual value is $y = 0$) or false negatives (the model says $\\hat{y} = 0$, but the actual value is $y = 1$).Part BOne natural choice for $\\ell$, which you may have already come up with, is to define our loss function as $\\ell(y, \\hat{y}) = \\mathbb{I}[y \\neq \\hat{y}]$. The funny looking $\\mathbb{I}$ is the indicator function that takes on value 1 when the condition inside is true and 0 otherwise.  Given this choice the supervised learning problem becomes:\\(\\begin{align}\\hat{f}^\\star &amp;= \\argmin_{\\hat{f}} \\sum_{i=1}^n \\mathbb{I} \\left [  \\hat{f}(\\mathbf{x_i}) \\neq y_i\\right ] \\enspace . \\label{eq:minimizeerror}\\end{align}\\)Convert the equation above to English to make sure you understand it.Show / Hide Solution    SolutionThe equation says that $\\hat{f}^\\star$ is the function that minimizes the number of mistakes it makes on the training set.While the loss function given in the exercise above on 0-1 loss (minimizing mistakes on the training set) is a totally reasonable choice for the loss function, it turns out that it has a number of drawbacks.  It is all or nothing.  Either we are completely right or completely wrong.  It is not a particularly easy function to work with mathematically.  In fact, for many common classes of models, it will be difficult for the learning algorithm to find the best possible model. Note: One of the key challenges that must be met in machine learning, and modeling in general, is balancing computational considerations (e.g., how long does it take to find the best possible model) with the realism of the model (e.g., how directly does the task you pose to the learning algorithm match the problem you are solving).  Sometimes these things are in conflict and you must make tradeoffs..It turns out that we can create a more natural loss function by thinking about predictions in terms of probabilities.Probability and the log lossImagine that instead of our model, $\\hat{f}$, spitting out either 0 or 1, it outputs a confidence that the input $\\mathbf{x}$ has an output $y= 1$.  In other words, rather than giving us its best guess (0 or 1), the classifier would indicate to us its degree of certainty regarding its prediction.  This notion of “certainty” can be formalized using the concept of a probability.  That is, a model can output a probability that the output for a particular input is 1.We haven’t formally defined probability in this class, but here are a few things to keep in mind about probabilities:  A probability, $p$, specifies the chance that some event occurs.  $p = 0$ means that the even will definitely not occur and $p=1$ means that it will definitely occur.  A probability, $p$, must be between 0 and 1 ($0 \\leq p \\leq 1$).  If the probability an event occurs is $p$, then the probability that the event doesn’t occur is $1 - p$.                        \tExercise 5    \tFor these questions, assume that for a given input the classifier outputs a probability that the output will be 1.Part AIf a classifier has no clear idea of whether the output for a particular input is 1 or 0, what probability should the classifier output?Show / Hide Solution    SolutionThe output would be about 0.5.Part BIf a classifier is relatively certain that the output for a particular input is 1, what probability should the classifier output?Show / Hide Solution    SolutionThe output would be close to 1 (e.g., 0.99).  The degree of closeness to 1 would depend on how certain the classifier was.Part CIf a classifier is relatively certain that the output for a particular input is 0, what probability should the classifier output?Show / Hide Solution    SolutionThe output would be close to 0 (e.g., 0.01).  The degree of closeness to 0 would depend on how certain the classifier was.Log lossIf our model outputs a probability $p$ when supplied with an input $\\mathbf{x}$ (i.e., $\\hat{f}(\\mathbf{x}) = p$), we might then ask ourselves what loss function we should choose in order to select the best possible model?  This loss function will be used to quantify how bad a prediction $p$ is given the actual output $y$ (recall that for binary classification the output is either $0$ or $1$).  To make this more intuitive, consider the task of quantifying the quality of a weatherperson’s predictions.  Let’s assume that on the $i$th day the weather is either sunny ($y_i = 1$) or rainy ($y_i = 0$).  Suppose that each night the weatherperson gives the probability of it being sunny the next day.  Here are two potential choices for quantifying the loss of each prediction compared to the outcome (the actual weather).  0-1 loss: we will extract from the weatherperson’s prediction the most likely output (e.g., if $p = 0.75$, that would be sunny, if $p = 0.4$, that would be rainy).  If the most likely output matches the actual output we give a loss of 0, otherwise we give a loss of 1 (this is similar to the equation given in the exercise above on 0-1 loss.  squared loss: one downside of 0-1 loss is that it doesn’t take into account the certainty expressed by the weatherperson.  The weatherperson gets the same loss if it is rainy and they predicted $p = 0.51$ or $p = 1$.  For squared loss we compute the difference between the outcome and $p$ and square it to arrive at the loss.  For example if the weatherperson predicts $p = 0.51$ and it is sunny the loss is $(1 - 0.51)^2$.  If it was rainy in this same example, the loss is $(0 - 0.51)^2$.As an example, here are hypothetical predictions from two forecasters, the actual weather, and the resulting loss with either 0-1 loss or squared loss.            actual weather      forecast 1      0-1 loss      squared loss      forecast 2      0-1 loss      squared loss                  sunny (y = 1)      p = 0.2      1      (1 - 0.2)^2 = 0.64      p = 0.9      0      (1 - 0.9)^2 = 0.01              rainy (y = 0)      p = 0.6      1      (0 - 0.6)^2 = 0.36      p = 0.999      1      (0 - 0.999)^2 = 0.998              sunny (y = 1)      p = 0.8      0      (1 - 0.8)^2 = 0.16      p = 0.99      0      (1 - 0.99)^2 = 0.0001              sum             2      1.16             1      1.01                              \tExercise 6    \tAccording to the table above, which forecaster is better with regards to 0-1 loss?  Which forecaster is better with regards to squared loss?    Show / Hide Solution    SolutionForecaster 2 is better with respect to both loss functions (the losses are, on average, smaller).     One entry in the table above is particularly interesting.  In the third row the second forecaster assigned a probability of $0.999$ to it being sunny.  It turned out to rain (boo!!!).  The forecaster was almost certain it would be sunny and it wasn’t.  The 0-1 loss of course doesn’t capture this at all.  The squared loss seems to assign a fairly large loss.  One might argue, though, that this loss does not fully capture how bad the prediction was (for one thing the loss can never be above 1).  This last observation motivates a third loss function that we can use to evaluate probabilistic predictions: the log loss.\t\t        \tExternal Resources\t\t\t   Towards Data Science has a nice writeup that explains the concept of log loss.  Or you’re welcome to search for your own resources about log loss. If you find a nice video, please post it to the Slack so others can enjoy too.\t                        \tExercise 7    \tRevisit the example from before with the two weather forecasters.  Compute the log loss for each forecaster.  Who makes better predictions according to the log loss?    Show / Hide Solution    Solution            actual weather      forecast 1      log loss      forecast 2      log loss                  sunny (y = 1)      p = 0.2      -ln 0.2      p = 0.9      -ln 0.9              rainy (y = 0)      p = 0.6      -ln 0.4      p = 0.999      -ln 0.001              sunny (y = 1)      p = 0.8      -ln 0.8      p = 0.99      -ln 0.99              sum             2.75             7.02           Note that log loss is also sometimes referred to as binary cross entropy loss.",
        "url": "/assignments/assignment04/assignment04.html"
      },"assignments-assignment05-assignment05-html": {
        "title": "Assignment 5",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Learn about the logistic regression algorithm.  Learn about gradient descent for optimization.  Build the foundational understanding we will need to implement the micrograd algorithm.\tThis builds on:  Supervised learning problem framing.  Calculating gradients.  Log lossThe Logistic Regression ModelIn class we went over a simple application of logistic regression to the Titanic Dataset.  So you have it handy, here is a link to the notebook from class.  You don’t have to do anything with this notebook for this assignment, but we wanted you to have it handy.\t\t        \tNotice\t\t\t   RecallIn the last assignment, you were introduced to the idea of binary classification, which based on some input $\\mathbf{x}$ has a corresponding output $y$ that is $y= 0$ or $y= 1$. In logistic regression, this model, $\\hat{f}$, instead of spitting out either 0 or 1, outputs a confidence that the input $\\mathbf{x}$ has an output $y= 1$.  In other words, rather than giving us its best guess (0 or 1), the classifier indicates to us its degree of certainty regarding its prediction as a probability.We also explored three possible loss functions for a model that outputs a probability $p$ when supplied with an input $\\mathbf{x}$ (i.e., $\\hat{f}(\\mathbf{x})=p$). The loss function is used to quantify how bad a prediction $p$ is given the actual output $y$ (for binary classification the output is either $0$ or $1$).  0-1 loss: This is an all-or-nothing approach. If the prediction is correct, the loss is zero; if the prediction is incorrect, the loss is 1. This does not take into account the level certainty expressed by the probability (the model gets the same loss if $y = 1$ and it predicted $p = 0.51$ or $p = 1$).  squared loss: For squared loss we compute the difference between the outcome and $p$ and square it to arrive at the loss.  For example, if $y = 1$ and the model predicts $p = 0.51$, the loss is $(1 - 0.51)^2$.  If instead $y = 0$, the loss is $(0 - 0.51)^2$.  log loss: The log loss also penalizes based on the difference between the outcome, $y_i$, and the predicted probabilty, $p_i$, using the formula below.\\begin{align} \\text{logloss} = -\\frac{1}{N}\\sum_{i=1}^n \\Big( y_i \\ln (p_i) + (1-y_i) \\ln (1 - p_i) \\Big )\\tag{1}\\end{align}Since $y_i$ is always 0 or 1, we will essentially switch between the two chunks of this equation based on the true value of $y_i$. As the predicted probability, $p_i$ (which is constrained between 0 an 1) gets farther from $y_i$, the log-loss value increases.\tNow that you have refreshed on how probabilities can be used as a way of quantifying confidence in predictions, you are ready to learn about the logistic regression algorithm.As always, we assume we are given a training set of inputs and outputs.  As in linear regression we will assume that each of our inputs is a $d$-dimensional vector $\\mathbf{x_i}$ and since we are dealing with binary classification, the outputs, $y_i$, will be binary numbers (indicating whether the input belongs to class 0 or 1).  Our hypothesis functions, $\\hat{f}$, output the probability that a given input has an output of 1.  What’s cool is that we can borrow a lot of what we did in the last couple of assignments when we learned about linear regression.  In fact, all we’re going to do in order to make sure that the output of $\\hat{f}$ is between 0 and 1 is pass $\\mathbf{w}^\\top \\mathbf{x}$ through a function that “squashes” its input so that it outputs a value between 0 and 1.  This idea is shown graphically in thie following figure.                            Figure 1: Graphical representation of both linear and logistic regression.  The key difference is the application of the squashing function shown in yellow. Original Source - Towards Data Science    To make this intuition concrete, we define each $\\hat{f}$ as having the following form (note: this equation looks daunting. We have some tips for interpreting it below).\\begin{align}\\hat{f}(\\mathbf{x}) &amp;= \\text{probability that output, $y$, is 1} \\nonumber  \\\\  &amp;=\\frac{1}{1 + e^{-\\mathbf{w}^\\top \\mathbf{x}}} \\tag{2}\\end{align}Here are a few things to notice about this equation:  The weight vector that we saw in linear regression, $\\mathbf{w}$, has made a comeback. We are using the dot product between $\\mathbf{x}$ and $\\mathbf{w}$ (which creates a weighted sum of the $x_i$’s), just as we did in linear regression!  As indicated in Figure 1, the dot product $\\mathbf{w}^\\top \\mathbf{x}$ has been passed through a squashing function known as the sigmoid function.  The graph of $\\sigma(u) = \\frac{1}{1+e^{-u}}$ is shown in Figure 2.  $\\sigma( \\mathbf{w}^\\top \\mathbf{x})$ is exactly what we have in \\(\\hat{f}(\\mathbf{x}) =\\frac{1}{1 + e^{-\\mathbf{w}^\\top \\mathbf{x}}}\\)                            Figure 2: A graph of the sigmoid function $\\frac{1}{1+e^{-x}}$.    Deriving the Logistic Regression Learning RuleNow we will formalize the logistic regression problem and derive a learning rule to solve it (i.e., compute the optimal weights). The formalization of logistic regression will combine Equation 2 with the selection of $\\ell$ to be log loss (Equation 1).  This choice of $\\ell$ results in the following objective function (this is a straightforward substitution.  there’s nothing too tricky going on here).\\[\\begin{align*}\\mathbf{w}^\\star &amp;= \\argmin_{\\mathbf{w}} \\sum_{i=1}^n \\Big ( - y_i \\ln \\sigma(\\mathbf{w}^\\top \\mathbf{x_i}) - (1-y_i) \\ln (1 - \\sigma(\\mathbf{w}^\\top \\mathbf{x_i}) ) \\Big)  \\\\&amp;= \\argmin_{\\mathbf{w}} \\sum_{i=1}^n \\Bigg (  - y_i \\ln \\left ( \\frac{1}{1+e^{-\\mathbf{w}^\\top \\mathbf{x_i}}} \\right) - (1-y_i) \\ln  \\left (1 - \\frac{1}{1+e^{-\\mathbf{w}^\\top \\mathbf{x_i}}} \\right ) \\Bigg) &amp;\\text{expanded out if you prefer this form}\\end{align*}\\]While this looks a bit intense, since $y_i$ is either 0 or 1, the multiplication of the expressions in the summation by either $y_i$ or $1-y_i$ are essentially acting like a switch—depending on the value of $y_i$ we either get one term or the other.  Our typical recipe for finding $\\mathbf{w}^\\star$ has been to take the gradient of the expression inside the $\\arg\\,min\\,$, set it to $0$, and solve for $\\mathbf{w}^\\star$ (which will be a critical point and hopefully a minimum).  The last two steps will be a bit different for reasons that will become clear soon, but we will need to find the gradient.  We will focus on finding the gradient in the next couple of parts.Useful Properties of the Sigmoid FunctionThe equation for $\\mathbf{w}^\\star$ above looks really hairy! We see that in order to compute the gradient we will have to compute the gradient of $\\mathbf{x}^\\top \\mathbf{w}$ with respect to $\\mathbf{w}$ (we just wrapped our minds around this last assignment).  Additionally, we will have to take into account how the application of the sigmoid function and the log function changes this gradient.  In this section we’ll learn some properties for manipulating the sigmoid function and computing its derivative.                        \tExercise 1    \tThe sigmoid function, $\\sigma$, is defined as\\[\\begin{align*}\\sigma(x) &amp;= \\frac{1}{1+e^{-x}}\\end{align*}\\]Part AShow that $\\sigma(-x) = 1 - \\sigma(x)$.Show / Hide Solution    Solution\\[\\begin{align*}\\sigma(-x) &amp;= \\frac{1}{1+e^{x}} \\\\&amp;= \\frac{e^{-x}}{e^{-x} + 1}~~\\text{multiply by top and bottom by $e^{-x}$} \\\\ \\sigma(-x)  - 1&amp;= \\ \\frac{e^{-x}}{e^{-x} + 1} - \\frac{1 + e^{-x}}{1 + e^{-x}} ~~\\text{subtract $-1$ on both sides} \\\\ &amp;= \\frac{-1}{1+e^{-x}} \\\\ &amp;= -\\sigma(x) \\\\ \\sigma(-x) &amp;= 1 - \\sigma(x)\\end{align*}\\]Part BShow that the derivative of the logistic function $\\frac{d}{dx} \\sigma(x) = \\sigma(x) (1 - \\sigma(x))$Show / Hide Solution    SolutionTwo solutions for the price of 1!Solution 1:\\[\\begin{align*}\\frac{d}{dx} \\sigma(x)  &amp;= e^{-x} \\sigma(x)^2 &amp;\\text{apply quotient rule} \\\\&amp;= \\sigma(x) \\left ( \\frac{e^{-x}}{1 + e^{-x}} \\right) &amp;\\text{expand out one of the $\\sigma(x)$'s}\\\\&amp;= \\sigma(x) \\left ( \\frac{1}{e^{x} + 1} \\right) &amp; \\text{multiply top and bottom by $e^{x}$}\\\\&amp;=  \\sigma(x) (  \\sigma(-x)) &amp;\\text{substitute for $\\sigma(-x)$} \\\\&amp;=  \\sigma(x) (1 -  \\sigma(x) ) &amp;\\text{apply $\\sigma(-x)=1-\\sigma(x)$}\\end{align*}\\]Solution 2:\\[\\begin{align*}\\frac{d}{dx} \\sigma(x)  &amp;=\\frac{e^{-x}}{(1+e^{-x} )^2} &amp; \\text{apply quotient rule} \\\\&amp;= \\frac{e^{-x}}{1+2e^{-x} + e^{-2x}} &amp; \\text{expand the bottom}\\\\&amp;= \\frac{1}{e^{x}+2 + e^{-x}} &amp; \\text{multiply top and bottom by $e^{x}$}\\\\&amp;= \\frac{1}{(1+e^{x})(1+e^{-x})} &amp; \\text{factor} \\\\&amp;= \\sigma(x)\\sigma(-x) &amp; \\text{decompose using definition of $\\sigma(x)$}\\\\&amp;= \\sigma(x)(1-\\sigma(x)) &amp;\\text{apply $\\sigma(-x)=1-\\sigma(x)$}\\end{align*}\\]Chain Rule for GradientsWe now know how to take derivatives of each of the major pieces of the logistic regression loss function.  What we need is a way to put these derivatives together.  You probably remember that in the case of single variable calculus you have just such a tool.  This tool is known as the chain rule.  The chain rule tells us how to compute the derivative of the composition of two single variable functions $f$ and $g$.\\begin{align}h(x)&amp;= g(f(x))&amp;\\text{h(x) is the composition of $f$ with $g$} \\nonumber \\\\h'(x) &amp;= g'(f(x))f'(x)&amp;\\text{this is the chain rule!}\\end{align}Suppose that instead of the input being a scalar $x$, the input is now a vector, $\\mathbf{w}$.  In this case $h$ takes a vector input and returns a scalar, $f$ takes a vector input and returns a scalar, and $g$ takes a scalar input and returns a scalar.\\begin{align}h(\\mathbf{w}) &amp;= g(f(\\mathbf{w}))&amp;\\text{h($\\mathbf{w}$) is the composition of $f$ with $g$} \\nonumber \\\\\\nabla h(\\mathbf{w}) &amp;= g'(f(\\mathbf{w})) \\nabla f(\\mathbf{w}) &amp; \\text{this is the multivariable chain rule}\\end{align}                        \tExercise 2    \tPart ASuppose $h(x) = \\sin(x^2)$, compute $h’(x)$ (x is a scalar so you can apply the single-variable chain rule).Show / Hide Solution    SolutionApplying the chain rule gives\\(\\begin{align}h'(x) &amp;= cos(x^2) 2x\\end{align}\\)Part BDefine $h(\\mathbf{v}) = (\\mathbf{c}^\\top \\mathbf{v})^2$.  Compute $\\nabla_{\\mathbf{v}} h(\\mathbf{v})$ (the gradient of the function with respect to $\\mathbf{v}$).Show / Hide Solution    SolutionWe can see that $h(\\mathbf{v}) = g(f(\\mathbf{v}))$ with $g(x) = x^2$ and $f(\\mathbf{v}) = \\mathbf{c}^\\top \\mathbf{v}$ The gradient can now easily be found by applying the chain rule.\\[\\begin{align}\\nabla h(\\mathbf{v}) &amp;= 2(\\mathbf{c}^\\top \\mathbf{v}) \\mathbf{c}\\end{align}\\]Part CCompute the gradient of this expression, which comes from the beginning of the section on deriving the logistic regression learning rule:\\begin{align} \\sum_{i=1}^n -y_i \\ln \\sigma( \\mathbf{w}^\\top \\mathbf{x_i}) - (1-y_i) \\ln  \\left (1 - \\sigma( \\mathbf{w}^\\top \\mathbf{x_i}) \\right ) \\end{align}You can either use the chain rule and the identities you learned about sigmoid, or expand everything out and work from that.Show / Hide Solution    SolutionApplying the chain rule gives us\\begin{align} \\sum_{i=1}^n -y_i \\frac{\\nabla \\sigma( \\mathbf{w}^\\top \\mathbf{x_i})}{\\sigma( \\mathbf{w}^\\top \\mathbf{x_i})} - (1-y_i) \\frac{- \\nabla \\sigma( \\mathbf{w}^\\top \\mathbf{x_i})}{1 - \\sigma( \\mathbf{w}^\\top \\mathbf{x_i})}  \\enspace .\\end{align}Applying the chain rule again gives us\\begin{align}&amp; \\sum_{i=1}^n -y_i \\frac{\\sigma( \\mathbf{w}^\\top \\mathbf{x_i})(1-\\sigma( \\mathbf{w}^\\top \\mathbf{x_i}))\\nabla \\mathbf{w}^\\top \\mathbf{x_i}}{\\sigma( \\mathbf{w}^\\top \\mathbf{x_i})} - (1-y_i) \\frac{- \\sigma( \\mathbf{w}^\\top \\mathbf{x_i})(1-\\sigma( \\mathbf{w}^\\top \\mathbf{x_i}))\\nabla \\mathbf{w}^\\top \\mathbf{x_i}}{1 - \\sigma( \\mathbf{w}^\\top \\mathbf{x_i})} \\nonumber \\\\ &amp;= \\sum_{i=1}^n -y_i (1-\\sigma( \\mathbf{w}^\\top \\mathbf{x_i}))\\mathbf{x_i} + (1-y_i)  \\sigma( \\mathbf{w}^\\top \\mathbf{x_i})) \\mathbf{x_i}  \\end{align} You could certainly stop here, but if you plug in $y=0$ and $y=1$ you’ll find that the expression can be further simplified to: \\begin{align}\\sum_{i=1}^n  -(y_i - \\sigma(\\mathbf{w}^\\top \\mathbf{x_i})) \\mathbf{x_i} \\nonumber \\end{align}Gradient Descent for OptimizationIf we were to follow our derivation of linear regression we would set our expression for the gradient to 0 and solve for $\\mathbf{w}$.  It turns out this equation will be difficult to solve due to the $\\sigma$ function.  Instead, we can use an iterative approach where we start with some initial value for $\\mathbf{w}$ (we’ll call the initial value $\\mathbf{w^0}$, where the superscript corresponds to the iteration number) and iteratively adjust it by moving down the gradient (the gradient represents the direction of fastest increase for our function, therefore, moving along the negative gradient is the direction where the loss is decreasing the fastest).\t\t        \tExternal Resources\t\t\t   There are tons of great resources that explain gradient descent with both math and compelling visuals.  Recommended: Gradient descent, how neural networks learn - Deep learning, chapter 2, start at 5:20  An Introduction to Gradient Descent  The Wikipedia page on Gradient Descent  Ahmet Sacan’s video on gradient descent (this one has some extra stuff, but it’s pretty clearly explained).  There are quite a few resources out there, do you have some suggestions? (Share on Slack!)\t                        \tExercise 3    \tTo test your understanding of these resources, here are a few diagnostic questions.Part AWhen minimizing a function with gradient descent, which direction should you step along in order to arrive at the next value for your parameters?Show / Hide Solution    SolutionThe negative gradient (since we are minimizing)Part BWhat is the learning rate and what role does it serve in gradient descent?Show / Hide Solution    SolutionThe learning rate controls the size of the step that you take along the negative gradient.Part CHow do you know when an optimization performed using gradient descent has converged?Show / Hide Solution    SolutionThere are a few options.  One popular one is to check if the objective function is changing  only a minimal amount each iteration, the algorithm has converged.  You could also look at the magnitude of the gradient (which tells us the slope) to see if it is really small.Part DTrue or false: provided you tune the learning rate properly, gradient descent guarantees that you will find the global minimum of a function.Show / Hide Solution    SolutionFalse, the best gradient descent can do, in general, is converge to a local minimum.  If you know that the function you are optimizing has only one minimum, then this would also be the global minimum (this is the case for both linear and logistic regression).If we take the logic of gradient descent and apply it to the logistic regression problem, we arrive at the following learning rule.  Given some initial weights $\\mathbf{w^0}$, and a learning rate $\\eta$, we can iteratively update our weights using the formula below.We start by applying the results from our exercise on the chain rule.\\begin{align}\\mathbf{w^{n+1}} &amp;= \\mathbf{w^n} - \\eta \\sum_{i=1}^n  -(y_i - \\sigma(\\mathbf{w}^\\top \\mathbf{x_i})) \\mathbf{x_i} \\\\&amp;=  \\mathbf{w^n} + \\eta \\sum_{i=1}^n  (y_i - \\sigma(\\mathbf{w}^\\top \\mathbf{x_i})) \\mathbf{x_i}  ~~~\\text{distribute the negative}\\end{align}This beautiful equation turns out to be the recipe for logistic regression.\t\t        \tNotice\t\t\t   We won’t be assigning a full implementation of logistic regression from scratch. In future assignments, we will spend more time applying logistic regression and gradient descent.If it’s helpful for your learning to see a worked example with code now (to help the math make sense), you can optionally check out this example of binary classification for admission to college, noting that some of the math notation is slightly different than ours.You are also welcome to implement logistic regression using gradient descent if it’s helpful for your learning and/or if you already have significant experience with machine learning and want a challenge. This is completely optional, and we assume that most of you will not choose to do this. If you do decide to implement logistic regression using gradient descent, you will need to search for a good learning rate or you may consider implementing some strategies for automatically tuning the learning rate.\tDataflow Diagrams and Foundations of MicrogradNow that we have derived a learning rule for logistic regression, we are going to look at another way of representing multivariable functions and computing their partial derivatives.  This way of thinking about multivariable functions may seem a little strange at first, but this notion is going to lay the foundation for being able to derive learning rules for a whole range of machine learning models in an automated fashion!!First, let’s look at a multivariable function defined by the equations below.  We have a single scalar input variable $t$ that affects both input arguments of $f$ (through $x(t)$ and $y(t)$).\\begin{align}x &amp;= x(t) \\\\y &amp;= y(t) \\\\f &amp;= f(x, y) \\\\\\end{align}Let’s represent this system of equations using a data flow diagram (in some resources this is called a tree diagram, in which case it is drawn a bit differently).flowchart BT id1[\"$$f = f(x,y)~~~~$$\"] id2[\"$$x = x(t)~~$$\"] id3[\"$$y = y(t)~~$$\"] id2 --&gt; id1 id3 --&gt; id1 t --&gt; id2 t --&gt; id3This diagram represents how data moves from the inputs of a function (in this case $x$ and $y$) to its output (in this case $f$).  If we were to take a chart like this and figure out how to evaluate a function given some inputs, you’d have to make sure you always evaluate the inputs to a block before you try to evaluate the block itself.  For instance, I wouldn’t be able to evaluate the block $f = f(x,y)$ until I’ve evaluated the blocks $x = x(t)$ and $y=y(t)$.  To evaluate a block, you can imagine that the output of a block flows along the arrow into the downstream block, which then processes that input further until it arrives at the output.Let’s say we want to calculate $\\frac{\\partial f}{\\partial t}$.  We’ve learned about the chain rule for single variable functions, but this case is a bit different.  It turns out that, in this case, we can compute the partial derivative we seek in the following way.\\begin{align}\\frac{\\partial f}{\\partial t} &amp;= \\frac{\\partial f}{\\partial x} \\frac{\\partial x}{\\partial t} +  \\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial t}\\end{align}What is this formula saying???  Well it looks awfully like the single variable chain rule in the sense that we are multiplying derivatives together.  The only difference is that we are having to account for the multiple pathways from the input (independent variable) $t$ to the output (dependent variable) $f$.In the resources below, you will see how we can use our data flow diagram to compute these partial derivatives.\t\t        \tExternal Resources\t\t\t   This Harvey Mudd College calculus tutorials explain the concept of the chain rule using dataflow diagrams.  You can view this at HMC Multivariable Chain Rule Page.There is another nice writeup on this at Math LibreTexts (Note: that this writeup uses a slightly different graph structure where inputs that branch to multiple downstream functions are replicated)\t                        \tExercise 4    \tDraw a dataflow diagram to represent the function $f(x,y,z) = \\cos(x^2 y) + x^2 \\sqrt{z}$.  Compute $\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}, \\frac{\\partial f}{\\partial z}$ using the dataflow diagram method.    Show / Hide Solution    Solutionflowchart BT  id1[\"$$f = h_3 + h_5~~$$\"]  id2[\"$$h_3 = \\cos(h_2)~~$$\"]  id3[\"$$h_5 = h_1 \\times h_4~~$$\"]  id4[\"$$h_1 = x^2$$\"]  id5[\"$$h_4 = \\sqrt{z}~~$$\"]  id6[\"$$h_2 = h_1 \\times y~~$$\"]  id2 --&gt; id1  id3 --&gt; id1  id4 --&gt; id3  id6 --&gt; id2  id5 --&gt; id3  id4 --&gt; id6  x --&gt; id4  y --&gt; id6  z --&gt; id5\\begin{align}\\frac{\\partial f}{\\partial x}&amp;= \\frac{\\partial h_1}{\\partial x} \\frac{\\partial h_2}{\\partial h_1}  \\frac{\\partial h_3}{\\partial h_2} \\frac{\\partial h_f}{\\partial h_3} +  \\frac{\\partial h_1}{\\partial x} \\frac{\\partial h_5}{\\partial h_1} \\frac{\\partial f}{\\partial h_5} \\nonumber \\\\&amp;= 2x \\times y \\times -\\sin(h_2) \\times 1 + 2x \\times h_4  \\times 1 \\\\&amp;= -2xy \\sin(x^2 y) + 2x \\sqrt{z} \\\\\\frac{\\partial f}{\\partial y} &amp;= \\frac{\\partial h_2}{\\partial y} \\frac{\\partial h_3}{\\partial h_2} \\frac{\\partial f}{\\partial h_3}\\nonumber \\\\&amp;= h_1 \\times -\\sin(h_2) \\times 1 \\\\&amp;= -x^2 \\sin(x^2 y) \\\\ \\frac{\\partial f}{\\partial z} &amp;= \\frac{\\partial h_4}{\\partial z} \\frac{\\partial h_5}{\\partial h_4} \\frac{\\partial f}{\\partial h_5} \\\\&amp;= \\frac{1}{2} \\frac{1}{\\sqrt{z}} \\times h_1 \\times 1 \\\\&amp;= \\frac{1}{2} \\frac{x^2}{\\sqrt{z}}\\end{align}                             \tExercise 5    \tCome up with your own multivariable function and use a dataflow diagram to compute the partial derivative of the function with respect to each of its inputs.  If doable, sanity check your result by computing derivatives by hand.    Show / Hide Solution    SolutionThis is person dependent, so no solution here.  If you have a nice sample, let us know.                             \tExercise 6    \tSuppose we have a logistic regression model with two inputs $x_1$ and $x_2$ (each of these are just scalars now) and binary outputs $y$.  Given the data flow diagram for computing the log loss of this logistic regression model, compute the partial derivative of the log loss with respect to each of its weights $w_1$ and $w_2$.flowchart BT  x1[\"$$x_1$$\"]  x2[\"$$x_2$$\"]  w1[\"$$w_1$$\"]  w2[\"$$w_2$$\"]  h3[\"$$h_3 = h_1 + h_2$$\"]  h1[\"$$h_1 = x_1 w_1$$\"]  h2[\"$$h_2 = x_2 w_2$$\"]  h4[\"$$h_4 = \\sigma(h_3)$$\"]  h5[\"$$\\ell = -y\\,\\ln(h_4) - (1-y)\\,\\ln(1-h_4)~~~~$$\"]  x1 --&gt; h1  w1 --&gt; h1  x2 --&gt; h2  w2 --&gt; h2  h1 --&gt; h3  h2 --&gt; h3  h3 --&gt; h4  h4 --&gt; h5  y --&gt; h5    Show / Hide Solution    Solution\\begin{align}\\frac{\\partial{\\ell}}{w_1} &amp;= \\frac{\\partial h_1}{\\partial w_1} \\frac{\\partial h_3}{\\partial h_1}  \\frac{\\partial h_4}{\\partial h_3} \\frac{\\partial \\ell}{\\partial h_4} \\\\&amp;= x_1 \\times 1 \\times \\sigma(h_3) (1-\\sigma(h_3)) \\times \\Bigg(-y \\frac{1}{\\sigma(h_3)} + (1-y)\\frac{1}{1-\\sigma(h_3)}\\Bigg) \\\\&amp;= - y x_1 \\sigma(h_3) (1-\\sigma(h_3)) \\frac{1}{\\sigma(h_3)} + (1-y) x_1 \\sigma(h_3) (1-\\sigma(h_3)) \\frac{1}{1-\\sigma(h_3)} \\\\&amp;= -y x_1 (1-\\sigma(h_3)) + (1-y) x_1  \\sigma(h_3) \\\\&amp;= - x_1 (y-\\sigma(h_3))~~~~~\\text{If you plug in $y=0$ and $y=1$ you will see this is true} \\\\&amp;= - x_1 (y-\\sigma(w_1 x_1 + w_2 x_2))\\end{align}     ",
        "url": "/assignments/assignment05/assignment05.html"
      },"assignments-assignment06-assignment06-html": {
        "title": "Assignment 6",
        "author": "",
        "category": "",
        "content": "\t\t        \tNotice\t\t\t   Everyone should submit all parts of this assignment.This assignment contains two major components, each of which has parts that you must submit (regardless of which grading component you chose).You can do them in any order.Part 1: Preparation for COMPAS recidivism discussionThis falls under the “Context &amp; Ethics / Discussion Prep”. This will include questions about the assigned readings. The topic we are venturing into is very complex. We ask that you spend real time reading and considering these topics. It is not appropriate to just glance at this and ask ChatGPT for a summary. You are welcome to work with others to read and try to make sense of this together.Part 2: Model evaluation and basic concepts and terms in MLThis is the first of the “Quality Assessed Assignments” (see syllabus). It will be assessed for correctness. You can find this on Canvas at the end of Module 1. You should work on this independently.Note that the late penalty for this course is quiet lenient. Please prioritize completing Part 1 on time in order to foster meaningful conversation within the entire class.\tLearning Objectives\t\t        \tLearning Objectives\t\t\t     Reflect on potential biases in applications of machine learning.  Grapple with complex and difficult decisions that are made as part of the structures of our society.  Build a sense of your own understanding of basic concepts of machine learning and model evaluation.\tA refresher on key metrics and a primer on subgroup effects.Read through this website from Google and play with the visualization. This should help refresh your memory on terms like false positive rate with some great visualizations. It also demonstrates what can happen when you have two subgroups with different rates.COMPAS Model: Race, Criminal Justice, and Machine Learning\t\t        \tNotice\t\t\t   We are going to think about race and criminal justice in the United States. Before we dive into this, we want to acknowledge:  This is a complex and intricate issue that involves policy, society, technology, individual beliefs/values, and history. This topic directly (but not equally) impacts the lives of many people.  We all have our own lenses through which we view the world.  This topic will likely be uncomfortable to grapple with regardless of your background and identity. It may resonate differently with each of us. We (Sam/Paul) are available in person and via email, if you would like to discuss how we can best support you in class. We are planning to have some group discussion in class. One method of support could be pairing you with a partner of your choosing for this discussion. Another could be including your ideas about how class discussion can be informative and challenging without creating unnecessary pain. Please reach out to us if you have any concerns or want to discuss this more.  In this class, we will scratch the surface of the way the US justice system works. Your instructors are not criminal justice experts, but they do care about this topic. We are also continuing to learn more.  We believe in the importance of grappling with difficult topics. While we are in fields like engineering, math, and computing, these are not separate from the complexities of humanity.\tA few basics about the US criminal justice system.A police officer can place a person under arrest. However, an arrest does not necessarily mean that person committed a crime (both in fact and in a legal sense). Legally, someone is considered innocent until proven guilty in court. However, arrested people are often held in jail for months before trail (this is called pretrial detention). To get out of jail before trial, the arrested person can post bail. Bail is a considerable amount of money (“money bond”) that is given to the court to ensure the person shows up to trial. As you might guess, bail represents a way people with money are treated differently by the system than people without money.  (Optional: For more on bail, listen to Episode 62 of the podcast Ear Hustle (the podcast also has other stories from incarcerated people).Legally, a person is considered guilty if they are convicted in court. Practically, innocent people are sometimes convicted. People with a lot of money can hire many lawyers who will work many days, weeks, or years, fighting the case. People without funds for a lawyer will be assigned a public defender. Public defenders are often overwhelmed, and might have just a minute to look over the details of a case, right before trail.                        \tExercise 1    \tRead the Report of The Sentencing Project to the United Nations Special Rapporteur on Contemporary Forms of Racism, Racial Discrimination, Xenophobia, and Related Intolerance. This article is intended to provide some background information on criminal justice and race in the US.In Canvas, share at least 3 things that you learned from this article. Or if you knew this all, share 3 relevant pieces of information from another source.    Show / Hide Solution    Solution     We’ll be spending time talking about the Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) algorithm, produced by the company Northpointe, Inc. COMPAS was intended to assess the risk of recidivism. This is a well-known algorithm in machine learning communities.Below we will provide you a list of readings on this topic. As you read, please prepare to reflect on the following themes:  Social justice in a non-ideal world.  The roles of machine learning engineers and the roles of other professional roles in the application of machine learning in our society.  The major things that you would want to consider in this type of undertaking.  Framing things mathematically versus from a social justice standpoint.  The level of technical debate in model choices that is brought up in this discussion (especially in the technical responses).                        \tExercise 2    \tIn the articles below, we will read about an assessment of the use of the COMPAS metric. The COMPAS metric  We would like to be clear about when the COMPAS metric is applied. It is applied after someone is arrested, and the prediction COMPAS gives is if that person will be arrested again. A person who was arrested twice could be legally and actually innocent. It is important to be clear in our language that these are arrested people, and not convicted criminals.We would like to note one inconsistency in language: The term recidivism, which is generally defined as a criminal who commits a second crime, is used in the readings. ProPublica actually redefines recidivism as “a criminal offense that resulted in a jail booking and took place after the crime for which the person was COMPAS scored.” Here, ProPublica conflates an arrest for a crime with a conviction for that crime. Note that a jail booking is pre-trial, and different than prison, which is post-trial and conviction. This language is also used by the Northpointe rebuttal. We will use this recidivism language to match the data labels, but it is important to note that this should actually be referred to as re-arrests, which we will try to use in conversation.Please read:  the ProPublica article.  the technical details of the ProPublica analysis: How We Analyzed the COMPAS Recidivism Algorithm  Optional: read the Northpointe rebuttal. This is a long reading. It has a lot of jargon, and some acronyms are not defined. We strongly suggest limiting yourself to 60 minutes for this reading (perhaps read the conclusion early on). You may consider working with a classmate on this reading, so you can both discuss what you think the author is saying. We’re including this whole reading here because we would like you to engage with the real-world material.On Canvas: Please summarize what you see as the key parts of the ProPublica case. You can use words, diagrams, concept maps, or another method that works for you. If you read the Northpointe rebuttal, you can include this side too.    Show / Hide Solution    Solution                             \tExercise 3    \tOn Canvas:Reflect on what you’ve just read.  We think the themes brought up above will provide good fodder for your response, but please feel free to take it in any direction.  Aim for around two paragraphs in your response.    Show / Hide Solution    Solution     AcknowledgementsThanks to Micah Reid (Olin alum) and Miranda Lao (Olin alum) for their contributions to this assignment as part of a previous ML final project. Also thanks to Carrie Nugent for some of the framing work above.",
        "url": "/assignments/assignment06/assignment06.html"
      },"assignments-assignment07-assignment07-html": {
        "title": "Assignment 7",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Implement an automatic differentiation engine  Become familiar with the basic gradient descent loop for model training\tAutomatic Differentiation Through MicrogradThe exercises for this assignment are embedded in a Colab notebook.",
        "url": "/assignments/assignment07/assignment07.html"
      },"assignments-assignment08-assignment08-html": {
        "title": "Assignment 8",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Learn about multi-layer perceptrons (MLPs)  Implement an MLP in Pytorch  Understand how a multi-layer network can solve problems without the need for feature engineering.\tNeural Networks MotivationWe’re going to start out our journey into neural networks by revisiting the Titanic dataset that we saw a couple of classes ago.  The exercises are embedded within assignment 8 Colab notebook part 1.  Go through those exercises, and then check back to unpack things further.Neural Networks as Stacked Logistic Regression ModelsNow that you’ve seen a neural network in action, we’ll be digging into how a neural network works.  The presentation will be specific to a particular type of neural network that we used in the companion notebook known as a multilayer perceptron (MLP), but the main ideas generalize to many other types of networks.  While the name MLP might be a bit intimidating, what we’ll see in just a bit is that an MLP is nothing more than some logistic regression models stacked on top of each other!Thinking back to the Colab notebook, we observed that the features in the original dataset age and sex were not conducive to predicting whether someone would survive.  We showed that by augmenting the input features with a column called is young male that captured whether or not a person was young and male, that the algorithm could effectively learn the task.  The fundamental idea of a neural network is that the network automatically constructs useful representations of the input data as a part of the learning process.Before moving on, let’s show some diagrams that contrast these approaches.  First we’ll show the logistic regression model that we applied in the notebook.flowchart BTid1[\"age\"]id2[\"male\"]id3[\"is young male\"]id4[\"1\"]id5[\"$$p(survival) = 1/(1+e^{-s})~~~~$$\"]id6[\"$$s = w_1 \\text{age} + w_2 \\text{male} + w_3 \\text{is young male} + w_4~~~$$\"]id1 --\"$$w_1$$\"--&gt; id6id2 --\"$$w_2$$\"--&gt; id6id3 --\"$$w_3$$\"--&gt; id6id4 --\"$$w_4$$\"--&gt; id6id6 --&gt; id5A few notes here:  Instead of putting the weights (e.g., $w_1$) as separate boxes (which we’ve done when computing partial derivatives), here we are putting them on the arrows between the features and the $s$.  This is a common way of writing the architecture for neural networks, and we want you to be familiar with it.  If you prefer to think of a separate box for each weight connecting to $s$, that is fine too.  To be consistent with the notebook, we are using a variable that takes on 1 if the sex of the passenger is male (this is different than what we did a few classes ago when we used 1 for female).Notice how we had to manually introduce the feature is young male in order for the logistic regression model to utilize it to make its prediction.  Before giving you the equivalent figure for the multi-layer perceptron, let’s look at a little bit more cartoonish version of the multi-layer perceptron.  This version will leave off the math and the particular notation we are using.  Once you have a good sense of what this model is doing, we will draw a diagram to represent the multi-layer perceptron that you met in the notebook.  If you are looking for more information on how to think about MLPs, check out the 3B1B videos we linked previously.\t\t        \tExternal Resources\t\t\t   Here are some additional resources that explain the concept of a multi-layer perceptron.  If the explanations we give below are not working for you, consider checking out some of these.  You do not need to consult these resources if you feel like our explanations are working well for you.  3B1B: What is a neural network?  2D fully connected network visualization\tflowchart BTid1[\"age\"]id2[\"male\"]id4[\"1\"]id10[\"$$p(survival) = 1/(1+e^{-s_3})~~~~$$\"]id6[\"$$s_1 = w_{1,1} \\text{age} + w_{1,2} \\text{male} + w_{1,3}~~~$$\"]id8[\"$$s_2 = w_{2,1} \\text{age} + w_{2,2} \\text{male} + w_{2,3}~~~$$\"]id7[\"$$h_1 = 1/(1+e^{-s_1})$$\"]id9[\"$$h_2 = 1/(1+e^{-s_2})$$\"]id11[\"1\"]id12[\"$$s_3 = w_{3,1} h_1 + w_{3,2} h_2 + w_{3,3}$$\"]id1 --\"$$w_{1,1}$$\"--&gt; id6id2 --\"$$w_{1,2}$$\"--&gt; id6id4 --\"$$w_{1,3}$$\"--&gt; id6id1 --\"$$w_{2,1}$$\"--&gt; id8id2 --\"$$w_{2,2}$$\"--&gt; id8id4 --\"$$w_{2,3}$$\"--&gt; id8id6 --&gt; id7id8 --&gt; id9id7 --\"$$w_{3,1}$$\"--&gt; id12id9 --\"$$w_{3,2}$$\"--&gt; id12id11 --\"$$w_{3,3}$$\"--&gt; id12id12 --&gt; id10Oh no! Our notation has gotten more complicated.  Notice here that we are using subscripts to differentiate between our various summation nodes ($s_1$ versus $s_2$).  We are also using $w_{i,j}$ to refer to weight that corresponds to the $i$th summation node and the $j$th feature (e.g., $w_{1,2}$ tell us how much the feature age influences $s_2$).Input data (in this case we just use age, male, and a bias term) are propagated via a set of connection weights to a set of hidden representations ($h_1$ and $h_2$).  These hidden representations are propagated via another set of a connection weights to the output of the network.   In the companion notebook we showed that for the Titanic dataset, the network learned two hidden representations: one that seemed to encode is young male and the another that encoded sex.  Of particular importance is that we did not have to manually introduce the is young male feature.                        \tExercise 1    \tBefore going on, let’s make sure you have a firm handle on what’s being represented in the figure above.  Just as in logistic regression, we will try to tune the weights to fit the data.  How many weights are there to tune in this network?  While the figure looks pretty crazy, it has a lot of similarities with the logistic regression model.  Where does the logistic regression model show up in the figure?    Show / Hide Solution    Solution  There are a total of 9 weights in the network.  There are 6 connecting the 3 input units to the 2 hidden summation units.  There are another 3 connecting the 1 output summation unit.  There are three different logistic regression models represented.  There is one going from the inputs to the $s_1$.  There is another going from the inputs to $s_2$.  There is a third going from the hidden units ($h_1$ and $h_2$) to $s_3$.  The models are connected together such that the two lower logistic models feed into the higher-level one.                             \tExercise 2    \tFor each of the 3 behavors described below (questions a, b, and c), determine reasonable values for the weights in this network ($w_{1,1}, w_{1,2}, w_{1,3}, w_{2,1}, w_{2,2}, w_{2,3}, w_{3,1}, w_{3,2}, w_{3,3}$) so that the MLP behaves as described. You will not need to use any training data except general knowledge that a person’s reported sex is recorded as 0 or 1 and age is within a set of reasonable numbers (this question is about testing your understanding of the model itself).  Recall that the first input to the model is the passenger’s age, the second is a binary variable that is 1 if the passenger is male and 0 if female, and the third is always 1.Part A$h_1$ encodes whether or not the passenger is female (i.e., it should take a value close to 1 when the passenger is female and close to 0 when the passenger is male).Show / Hide Solution    SolutionSetting $w_{1,2} = -10$, $w_{1,1} = 0$, and $w_{1,3} = 5$ will do the trick.  If the passenger is male then $h_1 = \\sigma(-10 + 5) = \\sigma(-5) = 0.0067$ and if the passenger is female then $h_1 = \\sigma(5) = 0.9933$Part B$h_2$ encodes whether or not the passenger is a young male (i.e., it should take a value close to 1 when the passenger is male under the age of say 5 and close to 0 otherwise).Show / Hide Solution    SolutionSetting $w_{2,2} = 15$, $w_{2,1} = -1$, and $w_{2,3} = -10$ will do the trick.  If the passenger is female and one years-old $h_2 = \\sigma(-10 - 1) = \\sigma(-11) \\approx 0$ (any older female passengers will have even lower values. and if the passenger is male and 1 years-old then $h_2 = \\sigma(15 - 1 - 10) = \\sigma(4) = 0.982$.  A four year old male would have $h_2 = \\sigma(15 - 4 - 10) = \\sigma(1) = 0.731$.  An older male (e.g., a 10 year old) would have $h_2 = \\sigma(15 - 10 - 10) = \\sigma(-5) = 0.0067$Part C$p(\\text{suvival})$ should be close to 1 (i.e., predict survival) when the passenger is female \\emph{or} a male under the age of 5 and close to 0 otherwise.Show / Hide Solution    SolutionSet $w_{3,1} = 2$ and $w_{3,2} = 2$ and $w_{3,3} = -1$.  That way if either $h_1$ or $h_2$ are close to 1, then $p(\\text{suvival}) \\approx \\sigma(1) = 0.73$.Believe it or not, computing these weights by hand was fairly common before we had algorithms for automatically tuning weights from data.  The reason for this was that early techniques for learning the weights were very inefficient and often unable to converge to good solutions.  By now you’ve seen how to tune these weights using gradient descent for a logistic regresion model, and given what we’ve learned from implementing the micrograd framework, you probably suspect that the same approach could be used here.Neural Networks in PytorchNext, we’ll go back over to Colab to show how we can tune these weights automatically using pytorch.  Here is a listing of what you’ll do in this notebook.  You’ll implement a multilayer perceptron to recognize handwritten digits (similar to this previously linked example).  You’ll see how overfitting can become an issue for more complex networks  We’ll introduce (at a very high-level) three methods for dealing with overfitting.Okay, back to Colab for round 2.But don’t forget about the stuff below!Dataset exploration                        \tExercise 3    \tShortly, we will begin a mini-project in which you’ll perform classification on an existing dataset. We’d like you to take 10-20 minutes to explore potential datasets that you might be interested in and add one to our group slide deck (so others might use it too). The slide deck is linked on Canvas under this assignment on the home page. As you search, think about the size and type of the data (you could always take a small subset of an existing dataset).There are lots of data repositories to explore.  Kaggle, Hugging Face, and OpenML.org might be good places to start. You can often filter by the type of data as well as the topic.    Show / Hide Solution    Solution     ",
        "url": "/assignments/assignment08/assignment08.html"
      },"assignments-assignment09-assignment09-html": {
        "title": "Assignment 9: Small data project on classification",
        "author": "",
        "category": "",
        "content": "The project descriptionYou will be working solo on this project (1.5 to 2 weeks). The syllabus calls this a mini-project, but we’ll just call it a project here.In this project, you will contemplate a potential application for classification, you will implement and improve upon a machine learning algorithm on a data set in support of this application, and you will evaluate the models performance.As part of this project, you will:  Select a “small data” dataset.          “Small data” here is to indicate that you don’t need to choose a giant data set (too much for Colab to hold in memory). The goal is to learn about the machine learning process, building your skills and intuition. There is no requirement to get high accuracy. That said, you do need a fair number of data points (exemplars) to meaningfully train your network. This varies by the size of your network and the number of parameters. (You’ll be in rough shape if you have fewer than 30 exemplars per category even if your model has a small number of parameters.)        Document the important considerations for your application. For example:          What data are available for training?      How well would the algorithm need to work to responsibly create value?      How could the algorithm and application be tested (beyond the testing you choose to implement)?      What are the implications of this application in the world; who are the stakeholders; what are the risks; how (if at all) could they be mitigated?        Build and iterate on a classification model as a step toward this application.          We don’t expect you to build the entire application, just to work toward implementing an early version of an algorithm that could be used for this application. Your dataset doesn’t need to be sufficient (e.g.,  big or broad enough) to actually make the application.      The iteration aspect is important. You will build and test multiple versions of your model and document the effects of these changes. You will likely manipulate a parameter and see how your results change at different values of that parameter.                  For full credit, you should evaluate at least two major changes to your model (e.g., comparison of different types of models; manipulate the number of nodes in a hidden layer; manipulate the number of hidden layers; experiment with preprocessing or data augmentation techniques; experiment with different activation functions such as relu, sigmoid, etc.)                    You can use pre-built libraries like pytorch. It’s highly likely that you will use a neural network, but not required. Please talk with us if you plan on using a different type of model.        Visualize key aspects of your data/model. Include at least 3 meaningful visualizations in your report with clear labeling and a discussion of their meaning (though you’ll likely want more than three visualizations).          You’ll probably find it valuable to visualize many aspects of the data and model as you work. This is helpful in sanity checking and can give good insight into how the model is working.      It’s likely that you’ll visualize: some things about your data (before even making the model); a graph that shows the loss of your model as during the training process (see figures and caption at the end of this page); changes in some key metrics as you manipulate a parameter (e.g., number of hidden layers); comparison of key metrics for different versions of your model; final training and testing metrics.        Test and evaluate your model. This will likely include accuracy and other key metrics on training and test sets. Depending on your application, you may consider testing with additional data from another source (e.g., data you collect; another internet dataset that’s similar; simulated data based on theory). You will also evaluate the effectiveness of this model for your specific application and describe the limitations of your current model and data.          Your accuracy and other metrics of your actual model don’t have to be good enough for your application. The goal here is to iterate on your model, measure its effectiveness, and reflect on this in the context of an application.        Document your final analysis pipeline for transparency. (A simplified version that does not need to include every parameter, visualization, or tweak that you tried.) It should be well-organized and easy to follow (this takes time, so budget for it).Learning Objectives\t\t        \tLearning Objectives\t\t\t   This mini-project relates to all of the intended learning outcomes of this course:  Execute the iterative machine learning workflow of model design, fitting to training data, testing, and interpretation in order to be able to successfully apply machine learning techniques in specific contexts.          Yup, definitely this one.        Successfully implement machine learning algorithms in Python (both by using only minimal external libraries and by leveraging state-of-the-art machine learning libraries).          You can use libraries (e.g., PyTorch)        Consider the potential impacts of a machine learning system when deployed in a real-world context and make design decisions to mitigate potential harmful impacts.          Definitely the first part of this, and you should think about the design decisions you would make.        Understand a variety of machine learning techniques from both a mathematical and algorithmic perspective.          This project is not focused on the math, but in the past, this kind of project was where conceptual things clicked for several students (see Appendix).      \tGoal-Setting and CustomizationA good project as one that successfully uses a neural net on a dataset and demonstrates iteration (you try the neural net, you make improvements, you try again, and you assess the model performance thinking about a specific application). If you wish to go farther, that’s great!We’ve highlighted the learning objectives, and we also (informally) ask you to consider your own learning goals. Is there a specific skill you want to practice? Is there a way of learning (like, asking for help more, trying code without looking at examples first, etc) that you want to practice?  You can customize this project to support your own learning, and we are happy to help you shape the project to support your goals and challenge yourself.TimelineThe project will officially launch on Thursday, October 3, 2024, and end on Thursday, October 17, 2024. While this is 2 weeks of time, we also want to note that Fall break is on October 14th and 15th (Monday and Tuesday, so no class on Oct 14), so we encourage you to work on this project like it is one week with a little time for revisions (but you should make your own choices based on your situation).Use of external resources (including peers, the internet, and AI)You should lead your own project, and by “lead”, we mean that you should be the active thinker and doer of the work. This is how you build your skills and intuition. You should write and understand the code and text in your project.We are extending our trust to you (we will not run your report through a plagiarism checker), and we expect that you will follow the Olin Honor Code. The values of integrity and respect for others seem most directly relevant. We expect that your submitted work represents you own skills and understanding. However, we also recognize that this is a fuzzy thing to navigate. We’ve tried to articulate some guidelines here for equity and transparency, and we invite open discussion about what is appropriate and fair. We can navigate this fuzzy world together (like James and his friends in the the giant peach).Peer collaboration (students in this class or other humans, squirrels, and monkeys with typewriters)We encourage collaboration and supporting each other to enhance everyone’s learning. However, it’s inappropriate to have someone else write your code for you. It is okay to talk to someone about something that you’re stuck on. It’s also okay for them to show you how they solved it. It’s not okay to mindlessly copy several lines of code or text directly from someone else’s assignment.The (not actually) magical world of the internet and artificial intelligenceIt’s quite likely that someone has used your dataset for a machine learning project and posted that somewhere online. You can use these materials to help you when you are stuck, but you should not just copy and paste large chunks of code from the internet or AI (likely scraped from the internet). You do not need to turn off the auto-complete functions in Colab or your IDE, but please be aware that these also make mistakes.You should not start this project by having AI generate your first draft; the thought process of thinking through each of the steps is important to build your understanding. It is great to look at examples online that use a different dataset in order to build your understanding of the process, and then to emulate that in your own code.Class-owned editable resources fileWe will continue to use Slack and office hours to answer questions. However, we also know that a great deal of learning happens outside of those places. This shared, class-owned, editable document is intended to serve as a communal set of resources for troubleshooting as we figure things out together. Anyone can add to it, so as you run into problems (you will) and figure out solutions (sometimes on your own, sometimes with help), please add to this document to help others. Learning is not a zero-sum game.This shared document already has two years of notes from Machine Learning students in the past (from a image-focused project), so some things may be outdated (you can delete something if it no longer works or applies to this project). We also want to note that the field of machine learning is constantly changing, as are things like libraries and toolboxes. It’s likely that you’ll run into something that worked 3 years ago and does not work now. Please help us find and fix these things!Deliverables &amp; AssessmentDeliverables  A clean report in notebook (.ipynb) format with thoughtful explanations of the considerations for your classification application and important highlights of your analysis. This should include in-line code and figures. This should not include every analysis and figure that you generated. Choose the important pieces of information to meet the project description and rubric. You can mention other things that you investigated in the text and include supplemental code in your repository. This is about quality, not quantity.          The submission can be an uploaded .ipynb notebook or link to a notebook on Colab (please make sure you have appropriate sharing settings selected and test with someone else so we don’t have to request access; let us know if you’d like our Colab account email addresses).        A PDF of your clean notebook with all of the cells run and graphs appearing clearly. If you run into issues with this, try a different browser and experiment with the print function within Colab. If you have a problem and then figure something out, add it to the shared, class-owned, editable document.There are rubrics in the appendices in this document. The intention of these rubrics is to create shared expectations about the project, while also giving you lots of latitude to explore and emphasize your own learning.Check-in Deliverables (Grading Option B)By October 4, you will submit a progress goal that you will be accountable to.Before class on October 10, you will self-evaluate on the progress toward your goal and include a link or copy of your current notebook. In class, we will have a brief meeting with you to review your status and your self-evaluation.AssessmentAssessment for this project will be based on the quality of project work, which will be assessed by the teaching team.During the week of October 7, we will have a project check-in. For students who chose assessment partially based on process (grading Option B), this will be an assessed check-in to create an accountability system to help you make progress on your project. It will count in the “Daily assignments with markup” category. Project check-ins will also be available to students who chose grading Option A.At the end of the project, the teaching will assess and provide feedback on your final report. We apologize if this takes us a while, as this is a large class and we’re also redesigning many aspects of it given advances in machine learning.We want to acknowledge that we are all coming to this course with varying experience with machine learning. This is great, and we’re actively trying to help you all have positive learning experiences. We intend for the course not to require prior experience with machine learning to participate, learn new things, and feasibly receive a high grade. With this in mind, we want to be explicit about how we anticipate this playing out in assessment.With the project work and report, we will assess with a mental model of a team beginning the course with no real machine learning experience. The key aspects of this assessment are described in the rubric and project description. In practice, this means that everyone could receive an A for this project, and it will be more challenging for some people than others.Appendix A: Some questions to considerThese questions built from from this webpage.  What do you want your model to be able to do?  How can you imagine your model (or an extension of it) being used in the real world? Feel free to get creative.  If those ideas came true, who might they affect? In what ways?  What measures would your model’s real-world implementers need to take to ensure its effects live up to your intentions?  What pitfalls might your model fall into, and what could you quantitatively measure to avoid those?  Why was the dataset you used to train your model created?  In what other ways could the same data be used? How do you feel about those possibilities?  How was that dataset assembled? From where was the data sourced? Who or what labeled it? If there are any elements of this process you think were either particularly well done or problematic, how so?  If your dataset contains information about people, to what degree did those people have agency over their inclusion? Do you feel that matters in this case (your application and/or for a college project)? Why or why not?  Skimming through your dataset, does anything stand out to you about representation in its contents?  Do you feel the potential use cases for this dataset justify it being created and published? Why or why not?Appendix B: Lessons from those that have come before youIn a prior version of the class, we did a classification project using images with something called a convolutional neural network or CNN, which we’ll learn about later (the images part of this course). Here we’re doing a mini-project with simpler data, though you can use images if you want. At the end, we asked students to reflect on their project. We thought it might be helpful or entertaining to see what they had to say.Appendix C: RubricsJupyter NotebookPlease submit both a PDF of your Jupyter Notebook (with the code executed) and an executable Jupyter Notebook (or link to Colab with appropriate sharing set and tested) to Canvas.You should refer to the Project Description at the top of this document for what to include (we try to refer to that section here). Your project will be graded on the following aspects.General  The notebook is well-organized.  The notebook balances code and text well.  The notebook runs without errors in the Google CoLab environment.  The notebook is free of typos.  The notebook demonstrates good coding practices, including but not limited to docstrings, appropriate variable names, and comments as appropriate.  The code demonstrates a significant amount of effort (roughly 3 assignments’ worth), made clear by careful consideration of the data, model, and implications for the model you developed.Motivation (See: Document the important considerations for your application.)  It is clear what data you used.  The application of your algorithm is clear and well-motivated.  The notebook explains how well the algorithm would need to work to provide value.  The notebook explains how the algorithm is to be evaluated (how do you know it is working well?).  The notebook explains the implications of this approach (including risks and stakeholders).Implementation (See: Build and iterate on a classification model as a step toward this application.)  The notebook explains the dataset and the features, in text and/or graphics.  The notebook contains a classification model.  The model(s) are implemented correctly.  The notebook includes experimentation and evaluation of at least two major changes to your model (e.g., comparison of different types of models; manipulate the number of nodes in a hidden layer; manipulate the number of hidden layers; experiment with preprocessing or data augmentation techniques; experiment with different activation functions such as relu, sigmoid, etc.)Interpretation and Visualization (See: Build and iterate;  Visualize key aspects of your data/model; Test and evaluate your model.)  The code generates at least 3 meaningful visualizations of the data, model, and/or outputs.  The visualizations have clear and appropriate labels and connections to the text.  The evaluation uses appropriate key metrics based on the proposed application and dataset.  The notebook accurately describes the effectiveness and limitations of the model on both training and test data in text and numbers.  The text explains the relationship between the effectiveness and limitations of the model and the proposed application.",
        "url": "/assignments/assignment09/assignment09.html"
      },"assignments-assignment10-assignment10-html": {
        "title": "Assignment 10: Bag of Words and Text Classification",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Learn about the field of natural language processing (NLP) and see some important problems from NLP  Learn about bag of words methods for representing text as data  Use a bag of words methods for text classification\tText as DataThe theme of this module is text as data.  In this module we will begin to explore how we can use machine learning approaches to process text in order to solve problems (e.g., text classification or language translation).  Throughout this module, we will learn different methods to convert text to numbers that can be operated upon using the machine learning techniques we learned about in the last module (e.g., logistic regression and MLPs).Key PropertiesBefore we dive into some of the key applications of machine learning for text processing, let’s take some time to think about what makes processing text different than much of the data we’ve looked at thus far.Text consists of symbolsPieces of text are comprised of symbols.  For example, the text you are reading right now consists of symbols that include letters, numbers, punctuation, and other special characters.  Perhaps the most important distinction for us as machine learning practitioners is that these symbols do not necessarily have a meaningful numerical representation that we can use for learning.  As we move forward in this module, we’re going to learn different methods for changing these symbols into useful numerical representations so that we can use techniques like logistic regression and MLPs for further processing.  It’s also worth mentioning that when representing text we can also choose the symbols that we use.  Some models treat each letter as an individual symbol, and others treat each word as a symbol.  Other models treat parts of words as symbols.  We’ll be digging into all of this in a few assignments.Text has sequential structureWhen we first met the supervised learning problem, we represented our input to the model as a d-dimensional vector $\\mathbf{x}$.  Each of the dimensions of this vector represented some characteristic of the data.  In the logistic regression model and the MLP, each dimension of $\\mathbf{x}$ was treated more-or-less independently.  We did not assume any specific relationship between $x_i$ and $x_j$ (we could just as easily have shuffled the dimensions of the data and our learning approaches wouldn’t have behaved any differently).  When processing text, we need to consider that pieces of text have sequential structure.  The order of the symbols matters.  Our first attempts (in this assignment) to map machine learning onto text processing will not do a great job encoding this sequential structure, but as we move through the module we will begin to represent this sequential structure in important ways.Text has variable lengthAgain, thinking back to our input vector $\\mathbf{x}$, it had a fixed number of dimensions (we used $d$ to refer to the number of dimensions).  Pieces of text consist of sequences of symbols of variable length.  As a concrete example, later in this document you’ll learn about sentiment analysis (predicting if a piece of text is positive or negative) from text.  The individual pieces of text will contain varying numbers of symbols.  Our machine learning methods must handle this variability, and so far it’s not obvious how we can make this happen (but we’ll see one way by the end of this assignment).Important Problems in the Field of Natural Language ProcessingBefore we get into how to process text, let’s ask why we might want to process text.  Perhaps this seems like a silly question given the fact that everywhere you turn these days folk are talking about processing text with large language models (LLMs).  We’re going to go over a few of the specific problems that arise in a field called Natural Language Processing (or NLP for short), but we’re also going to have you do some of your own research.  NLP is a field concerned with, not surprisingly, processing and making sense of natural language.  Don’t let the term “natural language” confuse you, all we mean here is that we want to be able to process text that is written in natural form (i.e., how humans communicate).  In this case the world “natural” might be seen as a contrast to the notion of processing text that is constructed in some specific way as to be easily interpretable by a computer (e.g., a programming language is a good example).Here are some examples (not even close to an exhaustive list) of NLP problems that are commonly studied in the field.  Machine translation: translating text from one language to another.  Text completion: given the beginning of a piece of text, complete it (this is at the heart of LLMs)  Question answering: given a question, answer it in natural language (again this is a big part of LLMs)  Named entity recognition: “seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.” (source)  Sentence parsing: given a sentence, determine parts of speech and how they relate to each other  Sentiment analysis: given a sentence, determine whether the sentiment contained is positive or negative (this could be generalized to emotion detection or transferred to thinking about other types of text classification, e.g., spam filters for email).                        \tExercise 1    \tChoose one of the natural language processing tasks listed above (or substitute one of your own).  Do some research to determine some applications for algorithms that solve the problems listed above.  The distinction here is between problems and how a solution to that problem can be used for some purpose (an application).  Some of these problems may be harder to find information on than others, so do your best.  Aim for a medium length paragraph, 5-6 sentences, for your response.  If you choose an NLP problem not listed above, include a brief description of the problem itself along with the applications you found.Text Processing Beyond Natural LanguageMany of the same techniques we will be learning about can be used to process text data other than natural language.  Examples of this sort of text data could be genomic sequences (where each symbol in the sequence consists of nucleotides A, C, T, and G), amino acid chains (where each symbol is one of the 20 amino acids present in the human body), structured text (e.g., Python code), etc.  For example, the Google’s DeepMind team’s AlphaFold program for protein structure prediction just led to a Nobel prize in chemistry.  AlphaFold predicts protein structure from an Amino acid chain.  We won’t be going into this sort of text processing in this module (although some of the methods we will learn could be adapted fairly easily).  If you are interested in the idea of processing non-linguistic text, this might be a fruitful topic for a final project.Bag of WordsNext, we’re going to learn about our first technique for adapting the machine learning approaches from the previous module to processing text.  In doing so, we’re going to find ways of dealing with some of the unique features of text that initially might seem to make text incompatible with the techniques we’ve learned about.  Our first technique of the module is called “bag of words,” and it deals with two important challenges we’ve already discussed in using machine learning methods with text.  First, it converts the symbols in a piece of text into a numerical representation.  Second, the technique is able to handle pieces of text that are variable in length.  We hope you will enjoy these great external resources for learning about bag of words.\t\t        \tExternal Resources\t\t\t   Let’s learn about bag of words!  Begin by watching a video from IBM called “What is Bag of Words?”.  Towards the end, this video gets into two more advanced topics that we’ll be digging into shortly.  The first is tf-idf and you’ll learn about that in the notebook.  The second is the idea of word embeddings (or word2vec), and you’ll see that in the assignment after this one.  We point this out since we want you to focus on the bag of words content and avoid getting thrown off by this other content.  If you want one more (shorter video), we also recommend this video from Socratica.\t                        \tExercise 2    \tAs a quick check of your understanding, encode the following three pieces of text using bag of words.  What would you need to do to normalize the data?  What does it mean that the bag of words is a sparse representation?  How do you see that in your solution to the exercise?  goodnight moon  goodnight cow jumping over the moon  and a little toy house and a young mouse  and goodnight mouse    Show / Hide Solution    SolutionIf we examine the texts as a whole, we can identify the unique words that occur and assign each word to a dimension in our bag of words vector.  As long as we’re consistent in how we do so, It doesn’t matter how we assign words to vector dimensions (we could shuffle the rows of the table below, and we would still have a valid bag of words representation).  Here is what the sentences could look like in bag of words form.            dimension      word      text 1      text 2      text 3      text 4                  1      goodnight      1      1      0      1              2      moon      1      1      0      0              3      cow      0      1      0      0              4      jumping      0      1      0      0              5      over      0      1      0      0              6      the      0      1      0      0              7      and      0      0      2      1              8      a      0      0      2      0              9      little      0      0      1      0              10      toy      0      0      1      0              11      house      0      0      1      0              12      young      0      0      1      0              13      mouse      0      0      1      1      If we were to normalize these representations, we would divide each column by the sum of the column (i.e., the total number of words in each piece of text).The bag of words representation is sparse as most of the entries in the table are 0.  If we had a larger vocabulary the sparsity would be even more apparent (a higher proportion of entries that are 0).     Text Classification with Bag of WordsIn the video from IBM, there were several examples used to motivate the notion of bag of words for text classification.  Let’s use one of the problems mentioned, sentiment analysis, and apply it to analyzing movie reviews.  We’ll be using a fairly old dataset for our analysis, but it is one that is easy to work with and big enough for us to learn some important skills about working with text.  The dataset is Stanford’s Large Movie Review Dataset. Here is a snippet from the README.md file that is included with the dataset.  Large Movie Review Dataset v1.0  Overview  This dataset contains movie reviews along with their associated binarysentiment polarity labels. It is intended to serve as a benchmark forsentiment classification. This document outlines how the dataset wasgathered, and how to use the files provided.  Dataset  The core dataset contains 50,000 reviews split evenly into 25k trainand 25k test sets. The overall distribution of labels is balanced (25kpos and 25k neg). We also include an additional 50,000 unlabeleddocuments for unsupervised learning.  In the entire collection, no more than 30 reviews are allowed for anygiven movie because reviews for the same movie tend to have correlatedratings. Further, the train and test sets contain a disjoint set ofmovies, so no significant performance is obtained by memorizingmovie-unique terms and their associated with observed labels.  In thelabeled train/test sets, a negative review has a score &lt;= 4 out of 10,and a positive review has a score &gt;= 7 out of 10. Thus reviews withmore neutral ratings are not included in the train/test sets. In theunsupervised set, reviews of any rating are included and there are aneven number of reviews &gt; 5 and &lt;= 5.In the assignment 10 notebook, you’ll be working with this dataset and implementing your own machine learning system for predicting the sentiment of a movie review using a bag of wordsd representation.Bag of Words and Machine Learning Bias                        \tExercise 3    \tLet’s do a little spiraling back to one of the big ideas in machine learning we started the semester with.  We want to draw your attention to this specific example.  You may have heard that Amazonscrapped a secret AI recruiting tool that showed bias against women.More specifically, the tool performed automatic keyword analysis of job applications to predict whether or not the applicant was worth forwarding on to a human for further evaluation. Early in the development of this system researchers discovered that the model the system had learned placed a negative weight on words such as “women’s” as well as the names of some women’s colleges.Given what you just learned about the bag of words approach and what we learned about confounding variables in assignment 4, how might Amazon’s system have learned to associate negative feature weights with the gendered words or words associated with women’s colleges?    Show / Hide Solution    SolutionThe Amazon engineers probably didn’t think to screen out particular words from their machine learning model.  Likely, they assigned a dimension in their bag of words to all unique words as a way to increase the predictive power of the model.  In the data there was likely a correlation between resumes not doing as well and the presence of gendered words and the names of women’s colleges.  It’s hard to say why this correlation might have existed without more investigation (e.g., it could have been conscious or subconscious bias on the part of the evaluations that were used to make the training set, some systemic factor, or a combination).  Given this correlation, the machine learning model associated a negative weight with these words and baked it into the model.  In this way a correlation (that having these words in your resume was correlated with being screened out) was made causal by the model (if this model were to be applied to real resumes, then people with these words would be more likely to be discriminated against).     ",
        "url": "/assignments/assignment10/assignment10.html"
      },"assignments-assignment11-assignment11-html": {
        "title": "Assignment 11: Word Embeddings",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Learn about the concept of word embeddings and understand them as a form of unsupervised learning  Understand the pros and cons of word embeddings versus the bag of words approach  Examine word2vec encodings\tWord EmbeddingsThe concept of a word embedding was introduced in the day 13 materials.  During class, we learned that a key motivation for word embeddings is to overcome a limitation that we observed with our sentiment classification algorithm from assignment 10.  Specifically, in the bag of words approach, each word is represented as an independent dimension in the vector that represents a particular movie review (recall that we analyzed sentiment of movie reviews in the previous assignment).                        \tExercise 1    \tBefore getting into word embeddings in more detail, want to make sure you have a good handle on an important drawback of bag of words approaches.Suppose, we had a training set consisting of the following movie reviews (you can assume that these are the only reviews in the training set and that we trained the model using a similar technique to what we used in assignment 10).            Review      Label                  The casting of the movie was impeccable      +              The movie was great      +              The movie was awful      -              The movie was the worst I’ve ever seen      -              The movie was an affront to the art of film-making      -      Explain why a bag of words model trained on this data would have a difficult time evaluating the following movie reviews from a test set.  “The movie was fantastic”  “The cast of the movie did a superb job”    Show / Hide Solution    SolutionFor the first review, “the movie was fantastic”, the word “fantastic” does not appear in our training set.  Even though fantastic and great are closely related words, in the bag of words approach we treat each word as an independent dimension in our input vector.  If we want to understant fantastic as a synonym for great, we would need training data of movie reviews that contains the word fantastic.For the second movie review, “The cast of the movie did a superb job”, even though we use many similar words to what is present in the training set, the forms of the words (e.g., the chosen tenses) prevent a match with the training set.  In order to generalize to the word forms in this movie review, we would have to have the same word forms represented in the training set.     Word embeddings were introduced as a way to overcome the issues highlighted by the previous problem.  Instead of treating each word as an independent entity, we can learn to represent (embed) each word in a vector space that preserves key properties of the words themselves.  Let’s use the symbol $r$ to represent our embedding (we’ll use $r$ since it is a representation of the word).  We can think of $r$ as a function from words to the vector space $\\mathbb{R}^d$ (don’t get confused by this notation, $\\mathbb{R}^d$ just means a d-dimensional vector of real numbers).In order to learn our word embedding function $r$, we can use a form of machine learning called unsupervised learning.  As we discussed in the previous module, unsupervised learning involves learning from unlabeled data (in contrast to the supervised learning setting we’ve been studying for most of the term where we assume we have access to a training set consisting of input / output pairs).  We can use the concept of unsupervised learning as a way to create word embeddings.  There are quite a few ways to accomplish this goal, but two foundational approaches were proposed in the paper Efficient Estimation of Word Representations in Vector Space.  Here is the key figure from the paper.                            Figure 1: Given a sequence of words, we can pose a prediction task where we try to either predict the center word based on the embeddings of the surrounding words (CBOW) or the predict the surrounding words based on the center word (skip-gram).    As mentioned in the caption for Figure 1, we can use the data itself to pose a prediction task.  You might be wondering how we can call this unsupervised learning given that we are trying to predict something (either the surrounding words or the center word).  Well, the key is that the thing we are trying to predict is derived directly from the data itself (there is no need for any additional information, or label, to be added that is not in the data already).  As such, we can use this approach to learn a word embedding from a database of text (without the need for any additional labeling).Word2vecAs mentioned before, word2vec was introduced in the paper Efficient Estimation of Word Representations in Vector Space.  We don’t think you need to read the paper (but you are certainly welcome to!), but we do want you to get a feel the word embeddings created by word2vec.  We have put together a notebook that downloads the word embeddings and allows you to explore them a bit.Bias in Word Embeddings                        \tExercise 2    \tDepending on what experiments you tried with word2vec, you may have already seen some examples of bias.  We would like you to read the paper Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings.  The paper gets quite technical in places, although many of the ideas you have seen before (PCA??!?).  We would like you to read sections 1-4 of the paper (sadly PCA only shows up in the later sections of the paper).  Please take notes on key takeaways and unanswered questions.  If you’d like to go into the latter sections of the paper (section 5 and beyond), please feel free to do so (this is not required, at all).It’s also probably worth mentioning that the literature on bias in word embeddings is quite extensive with a lot of fascinating things to explore (and we’d love to learn from you if you if you do more explorations!).",
        "url": "/assignments/assignment11/assignment11.html"
      },"assignments-assignment12-assignment12-html": {
        "title": "Assignment 12: Generative Pre-Trained Transformers (GPTs) Part 1",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Learn about the concept of self-attention in neural networks and the role it plays in Generative Pre-trained Transformers (GPTs)  Implement self-attention in Pytorch\tDemystifying GPTThis assignment and the next one are building towards the goal of demystifying large language models (LLMs) like ChatGPT.  While we won’t be able to learn everything there is to know about these models, we will be learning, in-depth, about the concept of Generative Pre-Trained Transformers (GPTs).  We hope that by seeing the GPT mechanism up close, you are able to develop a better understanding of how LLMs work, giving you the option to explore LLMs further in your final projects.  You’ll also learn some useful, generalizable tricks for text processing along the way.The roadmap for our work (over this and the next assignment) is that we are going to use two video resources.  First, we’ll watch a sequence of two videos from 3B1B that will help us build a conceptual understanding of GPTs through a visual approach. The second, is a walkthrough of how to turn our conceptual understanding into an implementation of a GPT in Pytorch (we’ll use NanoGPT from Andrej Karpathy for that).Word Embbeddings and Predicting the Next Word\t\t        \tExternal Resources\t\t\t   Let’s start off by watching the 3B1B video How large language models work, a visual intro to transformers.Here are some of the key things we would like you to take away from this video.  That text can be tokenized in different ways (either as letters, chunks of words, or whole words)  How predicting the next token (or word) given a piece of text can be used repeatedly to do text completion.  That we can use the concept of embeddings to represent tokens in a high-dimensional space (make sure you understand how this connects to word embeddings)  Why the context that surrounds a word might be important for updating its embedding vector (e.g., to disambiguate between multiple meanings of the same word).  That the last layer of a GPT model maps from the embedding space to a real number for each possible next token (this is called the “unembedding matrix” in the video).  These numbers are called “logits”.  To take our real numbers from the previous step into a probability of the next token, we use the softmax function.  Make a note of what materials are review from this video (based on things we’ve already done).\tSelf-attention Under the HoodHopefully, you found that video to connect some dots from the last assignment and set the stage nicely for where we are going next.  Our next move is going to be to watch the next chapter in the 3B1B series on deep learning.  This is where we will meet the concept of self-attention, which is going to be at the heart of our GPT model.\t\t        \tExternal Resources\t\t\t   Now, let’s watch the 3B1B video Attention in transformers, visually explained.Here are some of the key things we would like you to take away from this video.  That the initial embedding of a token also encodes its position (not just the token’s identity)  That it is useful for words to be able to ask questions (query) of other words.  That queries can be specified as vectors and the answers to those queries can also be specified as vectors (called keys).  That the degree to which a key answers a query can be determined by taking the dot product of the key vector and the query vector and that we can compute the dot product of each query token and each query key as $QK^\\top$.  Note that the way Grant Sanderson (the creator of the video) has defined the matrices Q and K, the correct equation for him woudl be $K^\\top Q$ (he discusses this issue in the video’s top comment).  In our presentation, we are sticking with the original equation $QK^\\top$.  At 9:04, Grant Sanderson talks about the key attending to the query.  This is backwards from our understanding of how this language is typically used (there is some discussion of this in the comments).  We think of the query as attending to the key.  Applying a softmax to the matrix of dot products of queries and keys gives us a probability distribution of which tokens each token should attend to.  That the idea of causal attention (where we are predicting future tokens from past tokens) requires that future tokens are not allowed to send information to past tokens.  Further, to accomplish this goal, we can force entries in our query-key matrix corresponding to future tokens influencing past tokens to negative infinity (before applying softmax).  This is called “masking”.  That the token embeddings are updated by adding the value vectors from other tokens (weighted by attention).  (Note: this is presented in the video through the example of using adjectives to update the meaning of a noun.)  Note: there is a discussion of how to cut down the number of parameters in the value map by decomposing it into the product of the value up and the value down matrices ($V_{\\uparrow}$ and $V_{\\downarrow}$).  While this is interesting, and we are happy to talk about it,  we don’t advise getting hung up on this detail (we will not be using this architecture in the implementation to follow).  Similarly, don’t worry about the note about how the $V_{\\uparrow}$ matrices are all combined into one matrix called the output matrix.  That multiple heads of attention can be used to capture multiple ways in which token embeddings can influence each other.  Note: you shouldn’t have a super precise notion of what this means, but you should have a notion that multiple heads of attention might be useful.\tAlright, hopefully you are starting to put the pieces together.  We are going to some more steps to help thing solidify.  First, let’s do some exercises to help you with your understanding of self-attention.                        \tExercise 1    \tLet’s use a toy problem to make sure we have a handle on the mechanics of self-attention.  Instead of words, let’s think of individual letters as our tokens (again, sorry for this sleight-of-hand.  We are doing this to make the problem as simple as possible to highlight the important bits of self-attention.  We’ll also be using a resource called NanoGPT that will implement a GPT, at first, on the character level).  Let’s imagine that we want our attention head to take in a sequence of letters and compute for each token whether a consonant has occurred at any point up to and including the current token.  Here are some examples.  Input text: “eaeia”, our attention head should output no, no, no, no, no (none of our token have the property that they are or are preceded by a consonant).  Input text: “ccrs”, our attention head should output yes, yes, yes, yes (all tokens either are or are preceded by a consonant)  Input text: “aeri”, our attention head should output no, no, yes, yes (starting with the third token, “r”, we have at least one consonant).We haven’t quite defined how the responses “no” and “yes” will be represented as vectors, but we will get to that shortly.Let’s use a tokenization scheme where each letter is mapped to its position in the alphabet (starting with $a \\rightarrow 0$ and ending with $z \\rightarrow 25$).Part AExplain what each of the features (the rows) of the input tokens (the columns) in the embedding matrix $\\mathbf{W_E}$ captures.[\\mathbf{W_E} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp;  0 &amp; 1 &amp; 0 &amp;  0 &amp;  0 &amp; 1 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp; 1 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp; 1 &amp; 0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 \\ 0 &amp;  1&amp; 1 &amp;  1 &amp; 0 &amp; 1 &amp;  1 &amp;  1 &amp; 0 &amp;  1 &amp;  1 &amp;  1 &amp;  1 &amp;  1 &amp; 0 &amp;  1 &amp;  1 &amp;  1 &amp;  1 &amp;  1 &amp; 0 &amp; 1 &amp;  1 &amp;  1 &amp;  1 &amp;  1  \\end{bmatrix}]Show / Hide Solution    SolutionThe first row of the matrix encodes whether the token is a vowel (1) or consonant (0).  The second row of the matrix encodes whether the token is a consonant (1) or a vowel (0).Part BDefine a query ($\\mathbf{W_q}$) and key ($\\mathbf{W_k}$) matrix pair that causes all letters to attend to consonants.$\\mathbf{W_q}$ and $\\mathbf{W_k}$ are both matrices with $n_{q}$ rows and $n_{e}$ columns, where $n_q$ is the query dimension (you can choose this) and $n_e$ is the dimensionality our embeddings (in this example, 2).Hint 1: You should be able to solve the problem with $n_{q} = 1$ (that is, the key and query matrices are both 1 row and 2 columns).Hint 2: The key equation you’ll want to use is that the degree to which token $i$ attends to token $j$ can be computed from the embeddings $\\mathbf{r}_i$ and $\\mathbf{r}_j$ (these would be found in the appropriate column of $\\mathbf{W_E}$) of tokens $i$ and $j$ respectively using the following formula.\\begin{align}attention &amp;= (\\mathbf{W_q} \\mathbf{r}_i) \\cdot (\\mathbf{W_k} \\mathbf{r}_j)\\end{align}Show / Hide Solution    SolutionLet’s define the matrices as follows.\\(\\begin{align}\\mathbf{W_q} &amp;= \\begin{bmatrix} 1 &amp; 1 \\end{bmatrix} \\\\ \\mathbf{W_k} &amp;= \\begin{bmatrix} 0 &amp; 5 \\end{bmatrix}\\end{align}\\)Notice how no matter whether we have a consonant or a vowel, our query will always be $1$.  This makes sense since all tokens issue the same query (is there a consonant in front of me).  In contrast, our keys will only be non-zero if the token is a consonant.  This is also consistent with what we want.Taking it for a test spin, let’s look at the different cases.  query is vowel and key is vowel $\\bigg (\\mathbf{W_q}\\begin{bmatrix} 1 \\ 0 \\end{bmatrix} \\bigg ) \\cdot \\bigg(\\mathbf{W_k} \\begin{bmatrix} 1 \\ 0 \\end{bmatrix}\\bigg) = \\bigg (\\begin{bmatrix} 1 &amp; 1 \\end{bmatrix}\\begin{bmatrix} 1 \\ 0 \\end{bmatrix} \\bigg ) \\cdot \\bigg(\\begin{bmatrix} 0 &amp; 5 \\end{bmatrix} \\begin{bmatrix} 1 \\ 0 \\end{bmatrix}\\bigg) = (1)(0) = 0$  query is consonant and key is vowel $\\bigg (\\mathbf{W_q}\\begin{bmatrix} 0 \\ 1 \\end{bmatrix} \\bigg ) \\cdot \\bigg(\\mathbf{W_k} \\begin{bmatrix} 1 \\ 0 \\end{bmatrix}\\bigg) = \\bigg (\\begin{bmatrix} 1 &amp; 1 \\end{bmatrix}\\begin{bmatrix} 0 \\ 1 \\end{bmatrix} \\bigg ) \\cdot \\bigg(\\begin{bmatrix} 0 &amp; 5 \\end{bmatrix} \\begin{bmatrix} 1 \\ 0 \\end{bmatrix}\\bigg) = (1)(0) = 0$  query is vowel and key is consonant $\\bigg (\\mathbf{W_q}\\begin{bmatrix} 1 \\ 0 \\end{bmatrix} \\bigg ) \\cdot \\bigg(\\mathbf{W_k} \\begin{bmatrix} 0 \\ 1 \\end{bmatrix}\\bigg) = \\bigg (\\begin{bmatrix} 1 &amp; 1 \\end{bmatrix}\\begin{bmatrix} 1 \\ 0 \\end{bmatrix} \\bigg ) \\cdot \\bigg(\\begin{bmatrix} 0 &amp; 5 \\end{bmatrix} \\begin{bmatrix} 0 \\ 1 \\end{bmatrix}\\bigg) = (1)(5) = 5$  query is consonant and key is consonant $\\bigg (\\mathbf{W_q}\\begin{bmatrix} 0 \\ 1 \\end{bmatrix} \\bigg ) \\cdot \\bigg(\\mathbf{W_k} \\begin{bmatrix} 0 \\ 1 \\end{bmatrix}\\bigg) = \\bigg (\\begin{bmatrix} 1 &amp; 1 \\end{bmatrix}\\begin{bmatrix} 0 \\ 1 \\end{bmatrix} \\bigg ) \\cdot \\bigg(\\begin{bmatrix} 0 &amp; 5 \\end{bmatrix} \\begin{bmatrix} 0 \\ 1 \\end{bmatrix}\\bigg) = (1)(5) = 5$Why $5$?  This helps make the attention to consonants higher relative to attention to vowels (remember, this has to get passed through a softmax).Part CCome up with a short sequence of characters, $s$, consisting of some vowels and some consonants (keep the length pretty small).  Compute the matrix of all queries corresponding to your sequence, $\\mathbf{Q}$, where the number of rows of $\\mathbf{Q}$ is equal to the number of tokens (the length of $s$) and the number of columns is equal to the query dimension.  Compute the matrix of all keys corresponding to your sequence, $\\mathbf{K}$, where the number of rows of $\\mathbf{K}$ is equal to the number of tokens (the length of $s$) and the number of columns is equal to the query dimension.  Compute the (pre-masking) attention of each token to each other token using the formula $\\mathbf{Q} \\mathbf{K}^\\top$.  Apply masking to ensure that keys (columns) corresponding to later tokens do not influence earlier queries (rows).  Note: that the visualization in the 3B1B video (at this time stamp) has this matrix laid out with query tokens as columns and the keys as rows (we wanted to let you know to minimize confusion).  Apply a softmax across each row (as before, this is shown on columns in the 3B1B video) to determine a weight for each token and show the resultant matrix.Show / Hide Solution    SolutionLet’s take our string to be $s = \\text{abcce}$.Step 1: Compute our embeddings by picking out appropriate columns of our matrix. $r_1 = \\begin{bmatrix} 1 \\ 0 \\end{bmatrix}$, $r_2 = \\begin{bmatrix} 0 \\ 1 \\end{bmatrix}$, $r_3 = \\begin{bmatrix} 0 \\ 1 \\end{bmatrix}$, $r_4 = \\begin{bmatrix} 0 \\ 1 \\end{bmatrix}$, and $r_5 = \\begin{bmatrix} 1 \\ 0 \\end{bmatrix}$.Step 2: Compute each query using the formula $\\mathbf{W_q} \\mathbf{r}_i$ and each key using the formula $\\mathbf{W_k} \\mathbf{r}_i$ and put each query as a row to form $\\mathbf{Q}$ and each key as a row to form $\\mathbf{K}$.\\[\\begin{align}\\mathbf{Q} &amp;= \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix} \\\\ \\mathbf{K} &amp;= \\begin{bmatrix} 0 \\\\ 5 \\\\ 5 \\\\ 5 \\\\ 0 \\end{bmatrix}\\end{align}\\]Step 3: Compute the unmasked attention $\\mathbf{Q} \\mathbf{K}^\\top$.\\[\\begin{align}\\mathbf{Q} \\mathbf{K}^\\top &amp;= \\begin{bmatrix} 0 &amp; 5 &amp; 5 &amp; 5 &amp; 0 \\\\ 0 &amp; 5 &amp; 5 &amp; 5 &amp; 0 \\\\ 0 &amp; 5 &amp; 5 &amp; 5 &amp; 0 \\\\ 0 &amp; 5 &amp; 5 &amp; 5 &amp; 0 \\\\ 0 &amp; 5 &amp; 5 &amp; 5 &amp; 0 \\end{bmatrix}\\end{align}\\]Step 4: Mask the matrix so that future tokens can’t influence past tokens.\\[\\begin{align}mask(\\mathbf{Q} \\mathbf{K}^\\top) &amp;= \\begin{bmatrix} 0 &amp; -\\infty &amp; -\\infty &amp; -\\infty &amp; -\\infty \\\\ 0 &amp; 5 &amp; -\\infty &amp; -\\infty &amp; -\\infty \\\\ 0 &amp; 5 &amp; 5 &amp; -\\infty &amp; -\\infty \\\\ 0 &amp; 5 &amp; 5 &amp; 5 &amp; -\\infty \\\\ 0 &amp; 5 &amp; 5 &amp; 5 &amp; 0 \\end{bmatrix}\\end{align}\\]Step 5: Take softmax along the rows.\\[\\begin{align}softmax(mask(\\mathbf{Q} \\mathbf{K}^\\top)) &amp;= \\begin{bmatrix}    1 &amp;  0 &amp;  0 &amp; 0 &amp; 0 \\\\ 0.0067 &amp;  0.9933  &amp; 0   &amp;      0   &amp;    0 \\\\ 0.0034   &amp; 0.4983 &amp;   0.4983     &amp;    0     &amp;    0 \\\\   0.0022  &amp;  0.3326  &amp;  0.3326  &amp;  0.3326    &amp;     0 \\\\ 0.0022  &amp;  0.3318  &amp;  0.3318  &amp;  0.3318  &amp;  0.0022 \\end{bmatrix}\\end{align}\\]Part DDefine the value for the $i$th token as $\\mathbf{W_V} \\mathbf{r}_i$ where $\\mathbf{W_V}$ is the identity matrix and $\\mathbf{r}_i$ is the embedding of the token.  Construct the matrix $\\mathbf{V}$ by computing the values of each token using the formula $\\mathbf{W_V} \\mathbf{r}_i$ and then transforming each value to a row of a matrix.  Show that taking your attention matrix from Part C and multiplying it on the right by $\\mathbf{V}$ computes the output of the attention head which will give a vector close to $\\begin{bmatrix} 1 \\ 0 \\end{bmatrix}$ if no consonants preceded a token and $\\begin{bmatrix} 0 \\ 1 \\end{bmatrix}$ if at least one consonant preceded a token.Show / Hide Solution    SolutionThe values are going to be the same as our embeddings.  We can lay them out as the rows of $\\mathbf{V}$.\\[\\begin{align}\\mathbf{V} &amp;= \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\\\ 0 &amp; 1 \\\\ 0 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}\\end{align}\\]We get the final outputs of our attention head by multiplying our matrix from part C by $\\mathbf{V}$.\\[\\begin{align}\\begin{bmatrix}    1 &amp;  0 &amp;  0 &amp; 0 &amp; 0 \\\\ 0.0067 &amp;  0.9933  &amp; 0    &amp;     0   &amp;    0 \\\\ 0.0034   &amp; 0.4983 &amp;   0.4983     &amp;    0     &amp;    0 \\\\   0.0022  &amp;  0.3326  &amp;  0.3326  &amp;  0.3326    &amp;     0 \\\\ 0.0022  &amp;  0.3318  &amp;  0.3318  &amp;  0.3318  &amp;  0.0022 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\\\ 0 &amp; 1 \\\\ 0 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix} &amp;= \\begin{bmatrix} 1.0000     &amp;    0 \\\\ 0.0067  &amp;  0.9933 \\\\ 0.0034  &amp;  0.9966 \\\\ 0.0022  &amp; 0.9978 \\\\  0.0045  &amp;  0.9955 \\end{bmatrix}\\end{align}\\]Part ESuppose you wanted the attention head to determine the proportion of consonants that precede (rather than just whether a consonant precedes a word or not).  How would you modify $\\mathbf{W_Q}$ and $\\mathbf{W_K}$ to achieve this result?  You should not need to change $\\mathbf{V}$.Show / Hide Solution    SolutionWe could keep $\\mathbf{W_Q} = \\begin{bmatrix} 1 &amp; 1 \\end{bmatrix}$ the same.  We can now modify the key so that all tokens have the same key (all respond to the query) by setting $\\mathbf{W_K} = \\begin{bmatrix} 1 &amp; 1 \\end{bmatrix}$. Let’s turn the crank.\\[\\begin{align}\\mathbf{Q} &amp;= \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix} \\\\ \\mathbf{K} &amp;= \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}\\end{align}\\]\\[\\begin{align}\\mathbf{Q} \\mathbf{K}^\\top &amp;= \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\end{bmatrix}\\end{align}\\]\\[\\begin{align}mask(\\mathbf{Q} \\mathbf{K}^\\top) &amp;= \\begin{bmatrix} 1 &amp; -\\infty &amp; -\\infty &amp; -\\infty &amp; -\\infty \\\\ 1 &amp; 1 &amp; -\\infty &amp; -\\infty &amp; -\\infty \\\\ 1 &amp; 1 &amp; 1 &amp; -\\infty &amp; -\\infty \\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; -\\infty \\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\end{bmatrix}\\end{align}\\]\\[\\begin{align}softmax(mask(\\mathbf{Q} \\mathbf{K}^\\top)) &amp;= \\begin{bmatrix}    1 &amp;  0 &amp;  0 &amp; 0 &amp; 0 \\\\ 0.5 &amp;  0.5  &amp; 0   &amp;      0   &amp;    0 \\\\ 0.3333   &amp; 0.3333 &amp;   0.3333     &amp;    0     &amp;    0 \\\\   0.25  &amp;  0.25  &amp;  0.25  &amp;  0.25    &amp;     0 \\\\ 0.2  &amp;  0.2  &amp;  0.2  &amp;  0.2  &amp;  0.2 \\end{bmatrix}\\end{align}\\]Finally, combine our attention with our values (since they haven’t changed from part D, let’s just use those).\\[\\begin{align}\\begin{bmatrix}    1 &amp;  0 &amp;  0 &amp; 0 &amp; 0 \\\\ 0.5 &amp;  0.5  &amp; 0   &amp;      0   &amp;    0 \\\\ 0.3333   &amp; 0.3333 &amp;   0.3333     &amp;    0     &amp;    0 \\\\   0.25  &amp;  0.25  &amp;  0.25  &amp;  0.25    &amp;     0 \\\\ 0.2  &amp;  0.2  &amp;  0.2  &amp;  0.2  &amp;  0.2 \\end{bmatrix}\\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\\\ 0 &amp; 1 \\\\ 0 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix} &amp;= \\begin{bmatrix}  1.0000   &amp;      0 \\\\    0.5000  &amp;  0.5000 \\\\ 0.3333  &amp;  0.6667 \\\\   0.2500  &amp;  0.7500 \\\\   0.4000 &amp;   0.6000 \\end{bmatrix}\\end{align}\\]Next, let’s see how a position embedding might help us.                        \tExercise 2    \tSuppose we want our attention head to take in a sequence of letters and output the vector $\\begin{bmatrix} 1 \\ 0 \\end{bmatrix}$ if there is a consonant at position 1 (where 1 is the first position in the sequence) and $\\begin{bmatrix} 0 \\ 0 \\end{bmatrix}$ otherwise.  Input text: “eacia”, our attention head should output $\\begin{bmatrix} 0 \\ 0 \\end{bmatrix}$, $\\begin{bmatrix} 0 \\ 0 \\end{bmatrix}$, $\\begin{bmatrix} 0 \\ 0 \\end{bmatrix}$, $\\begin{bmatrix} 0 \\ 0 \\end{bmatrix}$, $\\begin{bmatrix} 0 \\ 0 \\end{bmatrix}$ (token 1 is a vowel).  Input text: “ccrs”, our attention head should output $\\begin{bmatrix} 1 \\ 0 \\end{bmatrix}$, $\\begin{bmatrix} 1 \\ 0 \\end{bmatrix}$, $\\begin{bmatrix} 1 \\ 0 \\end{bmatrix}$, $\\begin{bmatrix} 1 \\ 0 \\end{bmatrix}$ (the first token is a consonant).Let’s use the same tokenization scheme as in the previous exercise. That is, each letter is mapped to its position in the alphabet (starting with $a \\rightarrow 0$ and ending with $z \\rightarrow 25$).Part AExplain what each of the features (the rows) of the input tokens (the columns) in the embedding matrix $\\mathbf{W_E}$ captures.[\\mathbf{W_E} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp;  0 &amp; 1 &amp; 0 &amp;  0 &amp;  0 &amp; 1 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp; 1 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp; 1 &amp; 0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 \\ 0 &amp;  1&amp; 1 &amp;  1 &amp; 0 &amp; 1 &amp;  1 &amp;  1 &amp; 0 &amp;  1 &amp;  1 &amp;  1 &amp;  1 &amp;  1 &amp; 0 &amp;  1 &amp;  1 &amp;  1 &amp;  1 &amp;  1 &amp; 0 &amp; 1 &amp;  1 &amp;  1 &amp;  1 &amp;  1 \\ 0 &amp;  0 &amp; 0 &amp;  0 &amp; 0 &amp; 0 &amp;  0 &amp;  0 &amp; 0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp; 0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp; 0 &amp; 0 &amp;  0 &amp;  0 &amp;  0 &amp;  0  \\end{bmatrix}]We can also specify our position embeddings for each token position (we’ll stop at position $8$ since the pattern should be obvious).  Explain what the positional embedding matrix is representing.[\\mathbf{W_P} = \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp;  0 &amp; 0 &amp; 0 &amp;  0 &amp;  0 \\ 0 &amp; 0 &amp; 0 &amp;  0 &amp; 0 &amp; 0 &amp;  0 &amp;  0  \\ 1 &amp; 0 &amp; 0 &amp;  0 &amp; 0 &amp; 0 &amp;  0 &amp;  0  \\end{bmatrix}]Show / Hide Solution    SolutionWe have the same embedding as the previous problem but we’ve added a dimension that is always zero for the token embedding.  The positional embedding places a 1 in this dimension if the position is 1.Part BDefine a query ($\\mathbf{W_q}$) and key ($\\mathbf{W_k}$) matrix pair that causes all letters to attend to only the first position in the sequence.  In this example, each key might emit the same query (no matter if it is a consonant or value), but the key would only match in the case where the key corresponds to the first token in the sequence.$\\mathbf{W_q}$ and $\\mathbf{W_k}$ are both matrices with $n_{q}$ rows and $n_{e}$ columns, where $n_q$ is the query dimension (you can choose this) and $n_e$ is the dimensionality our embeddings (in this example, 3).Hint 1: You should be able to solve the problem with $n_{q} = 1$ (that is, the key and query matrices are both 1 row and 2 columns).Hint 2: The key equation you’ll want to use is that the degree to which token $i$ attends to token $j$ can be computed from the embeddings (both position and token embedding) $\\mathbf{r}_i$ and $\\mathbf{r}_j$ (these would be found in the appropriate columns of $\\mathbf{W_E}$ and $\\mathbf{W_P}$) of tokens $i$ and $j$ respectively using the following formula.\\begin{align}attention &amp;= (\\mathbf{W_q} \\mathbf{r}_i ) \\cdot (\\mathbf{W_k} \\mathbf{r}_j)\\end{align}Show / Hide Solution    SolutionLet’s define the matrices as follows.\\(\\begin{align}\\mathbf{W_q} &amp;= \\begin{bmatrix} 1 &amp; 1 &amp; 0 \\end{bmatrix} \\\\ \\mathbf{W_k} &amp;= \\begin{bmatrix} 0 &amp; 0 &amp; 5 \\end{bmatrix}\\end{align}\\)Thinking of this intuitively, each token will emit the same query (a value of $1$) no matter if it is a consonant or a vowel.  This is consistent with the fact that all tokens want to attend to the same type of token (the first token).  The key will only be non-zero for tokens that are in the first position (since all others will have a value of $0$ for the final dimension).We leave it to you to further validate that these matrices will do the job (sorry!).Part CCome up with a short sequence of characters, $s$, consisting of some vowels and some consonants (keep the length pretty small).  Compute the matrix of all queries corresponding to your sequence, $\\mathbf{Q}$, where the number of rows of $\\mathbf{Q}$ is equal to the number of tokens (the length of $s$) and the number of columns is equal to the query dimension.  Compute the matrix of all keys corresponding to your sequence, $\\mathbf{K}$, where the number of rows of $\\mathbf{K}$ is equal to the number of tokens (the length of $s$) and the number of columns is equal to the query dimension.  Compute the (pre-masking) attention of each token to each other token using the formula $\\mathbf{Q} \\mathbf{K}^\\top$.  Apply masking to ensure that keys (columns) corresponding to later tokens do not influence earlier queries (rows).  Note: that the visualization in the 3B1B video (at this time stamp) has this matrix laid out with query tokens as columns and the keys as rows (we wanted to let you know to minimize confusion).  Apply a softmax across each row (as before, this is shown on columns in the 3B1B video) to determine a weight for each token and show the resultant matrix.Show / Hide Solution    SolutionLet’s take our string to be $s = \\text{cbcce}$.Step 1: Compute our embeddings by picking out appropriate columns of our matrices (for both token and position embeddings). $r_1 = \\begin{bmatrix} 0 \\ 1 \\ 1  \\end{bmatrix}$, $r_2 = \\begin{bmatrix} 0 \\ 1 \\ 0 \\end{bmatrix}$, $r_3 = \\begin{bmatrix} 0 \\ 1 \\ 0 \\end{bmatrix}$, $r_4 = \\begin{bmatrix} 0  \\ 1 \\ 0 \\end{bmatrix}$, and $r_5 = \\begin{bmatrix} 1 \\ 0 \\ 0 \\end{bmatrix}$.Step 2: Compute each query using the formula $\\mathbf{W_q} \\mathbf{r}_i$ and each key using the formula $\\mathbf{W_k} \\mathbf{r}_i$ and put each query as a row to form $\\mathbf{Q}$ and each key as a row to form $\\mathbf{K}$.\\[\\begin{align}\\mathbf{Q} &amp;= \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix} \\\\ \\mathbf{K} &amp;= \\begin{bmatrix} 5 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\\end{align}\\]Step 3: Compute the unmasked attention $\\mathbf{Q} \\mathbf{K}^\\top$.\\[\\begin{align}\\mathbf{Q} \\mathbf{K}^\\top &amp;= \\begin{bmatrix} 5 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 5 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 5 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 5 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 5 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix}\\end{align}\\]Step 4: Mask the matrix so that future tokens can’t influence past tokens.\\[\\begin{align}mask(\\mathbf{Q} \\mathbf{K}^\\top) &amp;= \\begin{bmatrix} 5 &amp; -\\infty &amp; -\\infty &amp; -\\infty &amp; -\\infty \\\\ 5 &amp; 0 &amp; -\\infty &amp; -\\infty &amp; -\\infty \\\\ 5 &amp; 0 &amp; 0 &amp; -\\infty &amp; -\\infty \\\\ 5 &amp; 0 &amp; 0 &amp; 0 &amp; -\\infty \\\\ 5 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix}\\end{align}\\]Step 5: Take softmax along the rows.\\[\\begin{align}softmax(mask(\\mathbf{Q} \\mathbf{K}^\\top)) &amp;= \\begin{bmatrix}    1.0000     &amp;    0     &amp;    0      &amp;   0     &amp;    0 \\\\   0.9933 &amp;   0.0067    &amp;     0     &amp;    0      &amp;   0 \\\\   0.9867  &amp;  0.0066  &amp;  0.0066     &amp;    0    &amp;     0 \\\\    0.9802  &amp;  0.0066  &amp;  0.0066 &amp;   0.0066     &amp;    0 \\\\  0.9738  &amp;  0.0066  &amp;   0.0066 &amp;   0.0066  &amp;  0.0066 \\end{bmatrix}\\end{align}\\]Part DDetermine $\\mathbf{W_V}$ to compute the value of each token as $\\mathbf{W_V} \\mathbf{r}_i$.  $\\mathbf{V}$ will be formed by laying out each of these values as a row of the matrix. Show that taking your attention matrix from Part C and multiplying it on the right by $\\mathbf{V}$ computes the output of the attention head which will give a vector close to $\\begin{bmatrix} 1 \\ 0 \\end{bmatrix}$ if the first token is a consonant and close to $\\begin{bmatrix} 0 \\ 0 \\end{bmatrix}$ otherwise.Hint: you’ll want to construct $\\mathbf{V}$ so consonants are mapped to the vector $\\begin{bmatrix} 1 \\ 0 \\end{bmatrix}$ and vowels are mapped to the vector $\\begin{bmatrix} 0 \\ 0 \\end{bmatrix}$.Show / Hide Solution    Solution\\(\\begin{align}\\mathbf{W_V} &amp;= \\begin{bmatrix} 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{bmatrix}\\end{align}\\)(Notice how if we have a consonant, regardless of position, our output will be the second column of the matrix.  Similarly, if we have a consonant, the output will be the zero vector).Applying our formula for the value of each token, $\\mathbf{W_V} \\mathbf{r}_i$, and transforming these into rows gives us $\\mathbf{V}$.\\[\\begin{align}\\mathbf{V} &amp;= \\begin{bmatrix} 1 &amp; 0 \\\\ 1 &amp; 0 \\\\ 1 &amp; 0 \\\\ 1 &amp; 0 \\\\ 0 &amp; 0 \\end{bmatrix}\\end{align}\\]We get the final outputs of our attention head by multiplying our matrix from part C by $\\mathbf{V}$.\\[\\begin{align}\\begin{bmatrix}    1.0000     &amp;    0     &amp;    0      &amp;   0     &amp;    0 \\\\   0.9933 &amp;   0.0067    &amp;     0     &amp;    0      &amp;   0 \\\\   0.9867  &amp;  0.0066  &amp;  0.0066     &amp;    0    &amp;     0 \\\\    0.9802  &amp;  0.0066  &amp;  0.0066 &amp;   0.0066     &amp;    0 \\\\  0.9738  &amp;  0.0066  &amp;   0.0066 &amp;   0.0066  &amp;  0.0066 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 0 \\\\ 1 &amp; 0 \\\\ 1 &amp; 0 \\\\ 1 &amp; 0 \\\\ 0 &amp; 0 \\end{bmatrix} &amp;= \\begin{bmatrix}       1.0000 &amp;  0   \\\\  1.0000  &amp; 0  \\\\    1.0000 &amp;   0   \\\\  1.0000 &amp; 0  \\\\   0.9934 &amp; 0  \\end{bmatrix}\\end{align}\\]Part EWhy was it important to have a position embedding in order to get this attention head to behave (i.e., have the output) the way we wanted it to?Show / Hide Solution    SolutionWithout the position embedding, we wouldn’t be able to only attend to the first token.  We could have tried to attend only to consonants, but that would still attend to any consonant (not just ones that are in the first position).Implementing Self-Attention\t\t        \tExternal Resources\t\t\t   Hopefully the last problem got you thinking about how attention can cause tokens to attend to other tokens in a flexible manner.  While setting weights by hand can build intuition, we of course want to fit these to data.  Next, we’re going to see how we can do that by implementing self-attention in Pytorch.  We are going to consult our old friend Karpathy (of micrograd fame) and go through his video Let’s build GPT: from scratch, in code, spelled out.  In this assignment, we’re going to go from the beginning to time stamp 1:11:39.  Watching videos like this is way more valuable when you actively try things out as the video is unfolding.  To help scaffold this, below we have a sequence of time stamps in the video along with things to think about or try.Before you start the video, you should probaby pull up the gpt-dev.ipynb Colab notebook (linked in the video description).  10:13: make sure you understand the encoder and decoder for characters.  Try it out in the notebook on some sequences you feed in.  13:45: (something to ponder if you’d like, but not super critical) think through what Karpathy is doing when choosing the train / test split.  Is it a good idea to choose the first 90% of the data as train and the last 10% as test?  16:59: make sure to understand the role of block_size as an upperbound on context length as well as the importance of extracting shorter contexts for training to allow the transformer to generate text starting from just a little bit of context.  20:59: make sure to notice how the print outs of “inputs” and “targets” relate to each other.  Notice that targets(i,j) is what needs to be predicted given the context represented in the $i$th row of inputs up to column $j$.  22:44: at this point Karpathy introduces the bigram language model.  The implementation of this Bigram model is Karpathy’s way of starting with a simple model and gradually transforming it into a GPT.  This move may be a little bit unintuitive given where we are coming from, but we think it will all gel as the video goes on.  While we haven’t seen the bigram model in this class, it’s a pretty straightforward idea.  Imagine training a multiclass logistic regression model (linear layer followed by a softmax) that predicts the probability of the next token given the current token.  To represent these probabilities, we’ll use a lookup table (implemented as a pytorch embedding) where the entry $i$, $j$ will be larger (more positive) if token $j$ often follows token $i$ and negative if token $j$ is unlikely to follow token $i$.  The entries of this lookup table will be learned from data (these would be the weights in our logistic regression model).  27:25: you may want to play around (meaning running code in the notebook) with the the tensor.view function to get a sense for how Karpathy is using it to “unroll” the tensor with dimensions B, T, C.  28:13: notice that Karpathy is actually passing the loss as an output from the forward function.  That’s a bit different to what we’ve been doing, but it’s just a stylistic difference.  Don’t get to hung up on it.  29:07: Karpathy shows code for generating text (basically, continuously feeding the models predictions back into itself).  How this happens is a bit beside the point for us, so we recommend not worrying about the details of how he does this.  35:34: now we are setting up our training loop.  This should look very familiar to what we’ve done earlier in this class.  40:17: we’ve now transitioned to using a script.  We are estimating loss by averaging over multiple batches.  This is to avoid computing loss on the entire training set (which we’ve tended to do since our datasets have been relatively small).  Notice the cool decorator he uses on the estimate_loss function though (that could be handy to avoid having to using with torch.no_grad():)  43:16: notice that Karpathy is now switching to thinking of embedding the tokens in a space (in this case a 2-dimensional space) rather than using the embeddings as a convenient way to implement a bigram model.  This is similar to what we did when we thought about embeddings is the last assignment.  Instead of computing embeddings using nn.Embedding, we’re just generating them randomly to allow us to focus on the machinery of self-attention.  45:12: our old friend the bag of words!  As mentioned in the video, we’re only doing this simple averaging step as a brief stepping stone to the attention mechanism we learned about in the 3B1B videos.  47:48: Karpathy really breaks this down nicely.  We recommend you interact with this toy example by running it yourself and making sure you understand the connection between the code and the matrix math.  53:35: a quick note that if you actually run this code torch.allclose will actually give false!  Presumably some of the default values have changed in pytorch since this video was made.  Passing the keyword argument atol=10**-7 along with the two matrices should give you True.  55:35: this should look familiar!  This is the masking we saw earlier.  59:10: now we are making our bigram model look more like self-attention!  Notice how we are introducing the idea of n_embd to capture the number of embedding dimensions (this was 2 in the toy problem we did earlier).  1:00:17: the version run at this point is still not doing any attention, but we have added some of the machinery necessary to implement self-attention.  1:00:57: we are introducing position embedding, which was mentioned briefly in 3B1B videos since it can be important to self-attention.  1:05:11: we now introduce the variable head_size, which we previously referred to as the query dimension ($n_q$).  Also, not that if we didn’t set bias=False we would have a constant added to the computation of our queries and keys, which we don’t want.  1:07:08: the way that the multiplication of two tensors works is a bit confusing for us, but hopefully we can leverage what we know about matrix multiplication.  If you want to go into this, you can check out Understanding Broadcasting in Pytorch.  1:11:37: we made it to our stopping point for this assignment.  Look at the code to compute out.  Can you connect the dots to the equation we learned about earlier for computing the output of our attention head, $softmax(mask(\\mathbf{Q}\\mathbf{K}^\\top))\\mathbf{V}$, and see how it corresponds?\t",
        "url": "/assignments/assignment12/assignment12.html"
      },"assignments-assignment13-assignment13-html": {
        "title": "Assignment 13: GPTs (part 2)",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Learn about the role of MLPs in transformer models  Read about issues related to collecting datasets for training large language models\tThe Role of MLPs in Transformers\t\t        \tExternal Resources\t\t\t   Now, let’s watch the 3B1B video How might LLMs store facts.  Here are some of the key things we would like you to take away from this video.  A transformer consists of interleaved blocks of attention and multi-layer perceptrons.  Roughly two thirds of the parameters in a transformer are in the MLPs.  MLPs operate on the output vectors from the attention block in parallel (i.e., the vector from two different positions do not interact with each other in the MLP).  One way to interpret each row of the weight matrix corresponding $\\mathbf{W}_{\\uparrow}$ is that they each encode some sort of question (e.g., in the video’s example we can think of one row as asking the question whether the input emedding corresponds to the concept “Michael Jordan”).  We can think of the role of the non-linearity in the MLP (e.g., ReLU) as deciding whether a given embedding is positive enough to consider as having answered the question in the affirmative (e.g., is this vector “Michael Jordan” versus “Michael Phelps” or “Alexis Jordan”).  We can think of the neuron as being “active” if the activation exceeds the threshold and “inactive” if it does not.  We can think of columns of the matrix $\\mathbf{W}_{\\downarrow}$ as referring to different concepts that we would like to add to the input embedding when forming the output from the MLP.  In the example, these concepts could relate to things like “baseketball”, “Chicago Bulls”, etc.  With regards to superposition, you don’t need to worry about this too much.  The main idea is that if we think of concepts in a neural network as representing vectors in the embeddings space, then we can encode a lot of facts by ensuring that each pair of these vectors is nearly perpendicular to each other.  This idea allows us to “fit” many more concepts within our embedding space.\tIssues in Regulation, Minimizing Harms, and Maximizing Benefits for AIA year ago, President Biden issues an executive order on artificial intelligence.  Since we’re interested in this class about issues surrounding ethical use and mitigating harms of machine learning models (which is also a major goal of the executive order), we thought it would be worthwhile to see what has happened since the order was issued.\t\t        \tExternal Resources\t\t\t   Read FACT SHEET: Biden-⁠Harris Administration Announces New AI Actions and Receives Additional Major Voluntary Commitment on AI.  Take notes on the main takeaways.  If you have time, follow at least one link from the document and writeup the main points of that report or resource.\t",
        "url": "/assignments/assignment13/assignment13.html"
      },"assignments-assignment14-assignment14-html": {
        "title": "Assignment 14: Generative Pre-Trained Transformers (GPTs) Part 3",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     How to generalize from single-headed to multi-headed attention  How to Interleave attention and MLPs to create a transformer  Understand the importance of skip connections and layer normalization  Perform an ablation experiment to understand the parts of the NanoGPT model that are relevant to text generation  Consider issues in dataset collection and curation for training and LLM\tOptional: Exploring AI, Building Equity into Innovation at Wellesley on SundaySunday, November 3, 2024, 3-5pmWellesley College, Tishman CommonsRegister here: https://forms.gle/C5REwqZ4B5f7Jx5y6Please join us for the 2024 World of Wellesley Community Book Read of Unmasking AI: My Mission to Protect What Is Human in a World of Machines by Joy Buolamwini. In her research, Dr. Joy Buolamwini uncovered what she calls “the coded gaze”, evidence of encoded discrimination and exclusion in tech products. How can we benefit from AI and also build equity into innovation? Come hear from a panel of Artificial Intelligence experts including:Aaron Pressman, The Boston Globe, Technology Industry JournalistTanuj Barman, WHS student class of 2025, Co-founder nextgenkids.aiCarolyn Anderson, Wellesley College, Asst. Professor of Computer ScienceMichael Dupin, Wolters Kluwer, Director Technology - Generative AI, MerrimackCollege, Data Science Adjunct ProfessorZachary Ziegler, Co-founder and CTO, OpenEvidenceReview of What We’ve Done So FarBefore getting into some new stuff, let’s review what we did in assignments 12 and 13.  We learned that GPT stands for “Generative Pre-trained Transform”  A GPT model consists of a pipeline of interleaving two major types of layers: attention and MLPs.  The attention layers are responsible for allowing tokens to pass information to other tokens. The degree to which a token passes information to another token depends on taking a dot product between a key and query vector, which is then passed through a softmax.  The specific value passed to the other token depends on a value vector which is computed from the input to the attention layer multiplied by a matrix ($W_V$).  While we haven’t gotten our hands dirty with MLPs in this module, we’ve seen them in previous parts of the course.  The MLPs in a GPT take the output of the attention block and perform computation on them.  In the 3B1B video, we saw that one theory of what these MLPs are doing is that they are representing facts that the GPT has learned.  We started to implement NanoGPT by starting with a simple Bigram model and then adding in a self-attention mechanism so that tokens could communicate with each other.Finishing Our Implementation of NanoGPTWe’ll continue to work through Karpathy’s video Let’s build GPT: from scratch, in code, spelled out.  Follow along with our notes and suggestions for things to try below.\t\t        \tExternal Resources\t\t\t     1:11:37: this is our starting point for this assignment.  1:12:08: Karpathy is now linking the concept of attention to a more general idea of information flowing between nodes in a graph.  We don’t think you need to be too concerned about this concept as we haven’t learned the necessary background to think about graphs (although, you may have seen this in DSA, FOCS, or Discrete).  1:15:41: self-attention is not the only type of attention (as has we’ve already heard about, e.g., cross attention is used in language translation tasks). This could be an interesting thing to explore in a final project if you find this concept interesting.  1:16:56: we are now seeing why the normalization term $\\frac{1}{\\sqrt{d_k}}$ is needed.  Karpathy does a nice job showing that this term allows us to achieve the variance we want (this is called scaled attention).  1:19:18: we can now take our self-attention code and package it up into the class Head.  As we’ve seen before in this class, in pytorch you can create your own machine learning modules by inheriting from nn.Module (e.g., as we did with our MLP implementation).  In this part of the video, we also modify our text generation code, which you don’t need to worry about.  1:21:59: we’ll now scale up from a single head of attention to multiple heads of attention.  Notice the use of the nn.ModuleList class, which allows multiple nn.Module objects to be grouped together into a single list.  The key idea here is that our query dimension $n_q$ and the space that our value vectors live in (also $n_q$) is now different than the number of embedding dimensions.  We concatenate the output from each attention head together to get back to the same number of dimensions as our original embedding.  Karpathy makes a reference to this idea of convolutions, which we’ll learn about in the next module of this class.  1:24:27: now we are going to bring in the concept of the multi-layer perceptron.  Based on the 3B1B videos, we have a conceptual idea of where these MLPs fit in and what they might do (e.g., store facts that the LLM has learned).  For the MLPs in our model, we’ll follow a pretty similar implementation to what we’ve done previously in the course.  Initially, the MLP that Karpathy implements will look a little strange (it will be a linear layer followed by a non-linearity with no subsequent linear layer), but eventually the second linear layer will be added (matching what we did in the previous module).  Karpathy also abstracts the sequence of self-attention and an MLP into a block which can be reused / repeated.  1:27:59: now we will introduce the idea of skip connections (or residual connections).  There are many reasons why this helps with the performance of the network, which the video touches upon.  The 3B1B videos give us one more way to think about this.  In those videos we talk about self-attention computing a vector that we can add onto our original embedding to modify a word’s meaning in some way.  Up until now, we have actually used attention to completely overwrite the original embedding. These skip connections allow us to, instead, compute a vector that we add to our embedding to get our output.  We’ll be seeing in more detail how important these connections are later in this assignment.  The concept of the projection self-attention / MLP block back into the residual pathway is confusing.  As with most matrices in neural networks, we can add this project matrix to give our network a bit more flexibility in how it integrates the results of self-attention / MLP with the original embedding.  1:32:56: next we are going to meet the concept of layer norm (this is the link to the documentation page he pulls up on layer norm).  The explanation given here is not particular accessible since we didn’t go through the original video on batch norm that Karpathy references.  For our purposes we can understand that layer norm is a way of standardizing the inputs to various parts of our model.  Given a batch of data, we would like each of the input features of our data to have mean 0 and standard deviation 1.  This standardization is achieved with LayerNorm, which builds on some additional bells and whistles that we don’t really need to worry about.  This sort of normalization can significantly improve the performance of deep (meaning with lots of layers) neural networks.  1:37:57: now we’ll have some fun scaling up our network!  1:38:46: we touch on the idea of dropout, which we discussed a bit in our class on preventing overfitting.  1:42:40: don’t worry about this part.  We are just connecting back to the “Attention is All You Need” paper with its focus on cross-attention.  1:46:31: Karpathy walks through of the NanoGPT repo.  The quick summary is that some changes have been made to clean up the code and make it more efficient.  1:48:55: Karpathy talks about some important steps that would happen after the pre-training step that we’ve learned about if you were going to train a ChatGPT-like system.  This is fascinating stuff, and it could be great fodder for a final project!\tVisualizing NanoGPT and Connecting to NanoGPT                        \tExercise 1    \tThere are some fantastic visualizations of LLMs out there.  Please check out this visualization, which shows the structure of the model from the video we just watched.  The visualizer also allows you to step through the main steps of the model and has some explanations of what’s going on as well as animations that show the computations happening at each stage.  Please step through the visualizations and try to link what you are seeing to Karpathy’s video.  Take some notes about anything that you don’t understand.  Below we have reproduced a selection of model.py, which defines the NanoGPT model.  Try to find as many pieces of the visualization of NanoGPT in the code for model.py.  For example, you might determine which class implements a particular box in the visualization.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154class LayerNorm(nn.Module):    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"    def __init__(self, ndim, bias):        super().__init__()        self.weight = nn.Parameter(torch.ones(ndim))        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None    def forward(self, input):        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)class CausalSelfAttention(nn.Module):    def __init__(self, config):        super().__init__()        assert config.n_embd % config.n_head == 0        # key, query, value projections for all heads, but in a batch        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)        # output projection        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)        # regularization        self.attn_dropout = nn.Dropout(config.dropout)        self.resid_dropout = nn.Dropout(config.dropout)        self.n_head = config.n_head        self.n_embd = config.n_embd        self.dropout = config.dropout        # flash attention make GPU go brrrrr but support is only in PyTorch &gt;= 2.0        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')        if not self.flash:            print(\"WARNING: using slow attention. Flash Attention requires PyTorch &gt;= 2.0\")            # causal mask to ensure that attention is only applied to the left in the input sequence            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))                                        .view(1, 1, config.block_size, config.block_size))    def forward(self, x):        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)        # calculate query, key, values for all heads in batch and move head forward to be the batch dim        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -&gt; (B, nh, T, T)        if self.flash:            # efficient attention using Flash Attention CUDA kernels            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)        else:            # manual implementation of attention            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))            att = F.softmax(att, dim=-1)            att = self.attn_dropout(att)            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -&gt; (B, nh, T, hs)        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side        # output projection        y = self.resid_dropout(self.c_proj(y))        return yclass MLP(nn.Module):    def __init__(self, config):        super().__init__()        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)        self.gelu    = nn.GELU()        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)        self.dropout = nn.Dropout(config.dropout)    def forward(self, x):        x = self.c_fc(x)        x = self.gelu(x)        x = self.c_proj(x)        x = self.dropout(x)        return xclass Block(nn.Module):    def __init__(self, config):        super().__init__()        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)        self.attn = CausalSelfAttention(config)        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)        self.mlp = MLP(config)    def forward(self, x):        x = x + self.attn(self.ln_1(x))        x = x + self.mlp(self.ln_2(x))        return xclass GPT(nn.Module):    def __init__(self, config):        super().__init__()        assert config.vocab_size is not None        assert config.block_size is not None        self.config = config        self.transformer = nn.ModuleDict(dict(            wte = nn.Embedding(config.vocab_size, config.n_embd),            wpe = nn.Embedding(config.block_size, config.n_embd),            drop = nn.Dropout(config.dropout),            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),            ln_f = LayerNorm(config.n_embd, bias=config.bias),        ))        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)        # with weight tying when using torch.compile() some warnings get generated:        # \"UserWarning: functional_call was passed multiple values for tied weights.        # This behavior is deprecated and will be an error in future versions\"        # not 100% sure what this is, so far seems to be harmless. TODO investigate        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying        # init all weights        self.apply(self._init_weights)        # apply special scaled init to the residual projections, per GPT-2 paper        for pn, p in self.named_parameters():            if pn.endswith('c_proj.weight'):                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))        # report number of parameters        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))    def _init_weights(self, module):        if isinstance(module, nn.Linear):            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)            if module.bias is not None:                torch.nn.init.zeros_(module.bias)        elif isinstance(module, nn.Embedding):            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)    def forward(self, idx, targets=None):        device = idx.device        b, t = idx.size()        assert t &lt;= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)        # forward the GPT model itself        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)        x = self.transformer.drop(tok_emb + pos_emb)        for block in self.transformer.h:            x = block(x)        x = self.transformer.ln_f(x)        if targets is not None:            # if we are given some desired targets also calculate the loss            logits = self.lm_head(x)            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)        else:            # inference-time mini-optimization: only forward the lm_head on the very last position            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim            loss = None        return logits, loss    Show / Hide Solution    SolutionHere are a few notes to get you started (more could be said).  The class GPT is the overall model shown in the visualization  All of the V Outputs are computed on line 54 (doing this all at once instead of once per head is an optimization that Karpathy did for computational reasoning).  The Attention Output is computed on line 58 (notice the projection there)  The layer norms in the visualization are shown at a few lines in the code (e.g., 87 and 88).  The Attention Residual is computed on line 87.  The input embeddings are computed on lines 138 and 139.  etc.     Ablation and NanoGPTAn ablation experiment in machine learning seeks to “to determine the contribution of a component to an AI system by removing the component, and then analyzing the resultant performance of the system.” (Wikipedia).  We think that this is a particularly interesting idea to apply to the NanoGPT model.  We saw, as the model was being built up, that adding on new features seemed to improve performance.  Now that we have the entire model built, we will take away several aspects of the model and analyze the change in performance.  This can give us a sense for how important each aspect of the model is to the overall functioning of the system.                        \tExercise 2    \tPart ADescribe how you would modify the excerpt from model.py shown in Exercise 1 to remove each of the following components from the model.  Remove the residual (or skip) connections from the self-attention and MLP steps.  Remove the layer norms from the self-attention and MLP steps.  Remove the position embedding  Use a head size of 1 (instead of multiheaded attention)Show / Hide Solution    SolutionLines 87-88 would become        x = self.attn(self.ln_1(x))        x = self.mlp(self.ln_2(x))Lines 87-88 would become        x = x + self.attn(x)        x = x + self.mlp(x)Line 140 would become        x = self.transformer.drop(tok_emb)There are a few places you could introduce this.  An easy way is to have Line 24 become        self.n_head = 1Part BWe went ahead and performed the ablation experiments described above (removing each of the aforementioned components of the model, indpendently, and then training the model on the Shakespeare character-level dataset).  We’d like you to look at our results and provide your interpretation of the results.  What have you learned about the model from these experiments?  For example, what model components are the most important?  Optional: If you’d like to run these ablation experiments yourself, you can do so either in your own environment or on Colab.  If you do this on Colab, we highly recommend you upgrade to Colab Pro (details on reimbursement for this are on Canvas) and use an L4 or an A100 GPU runtime when training.  We’ve made a starter notebook for you to build from.Show / Hide Solution    SolutionThe experiments show that the skip connections are tremendously important.  Without them the model loss is quite bad.  The model seems to converge to a good solution even without layer norm (although it takes longer to get there).  Not having position embedding seems to be detrimental (the loss never gets as low as the unablated model).  Having just one head of attention also does suprisingly well.  It’s probably best not to extrapolate too much from these results.  These features might be more important on a larger dataset.Proposing an LLM for an Application and Context You Care About                        \tExercise 3    \tBefore closing out this module, we’d like to give some creative space to think through how LLMs might apply in some context you care about.  Please think respond to the following prompts.  What do you think is an interesting application of of LLMs (either at Olin or in some other context you care about).  You can choose something you think is positive, negative, or neutral (no judgment).  Describe your chosen application.  What value does it create and for whom?  If you were to develop such an application, at a high-level how would you come about doing so.  Some areas to focus on could be dataset collection and curation and model evaluation and testing.  When sourcing your data to train your model, how would you navigate risks of data privacy, legal / regulator compliance, avoiding model bias, while achieving good performance with respect to the application you’ve chosen.  What guardrails would you need to put in place to make sure your system is not used in a harmful way that, presumably, you did not intend.  These guardrails could be technical in nature or specific licensing conditions you would impose on your system.  For many of these prompts you will probably not have a very detailed idea of how to go about achieving these outcomes.  That’s okay.  Please write at a high level and make a note if you don’t know something or would need to do more research.",
        "url": "/assignments/assignment14/assignment14.html"
      },"assignments-assignment15-assignment15-html": {
        "title": "Assignment 15: Images as Data and Convolutions",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Identify and explain key components of a convolutional neural network (CNN)  Create and apply filters like a CNN  Calculate the output size and values resulting from a given filter\tMeet Convolutional Neural NetworksConvolutional neural networks were a major step in the world of computer vision (and image generation). In class 17, we did some exploration of why these are cool and how they work. If you missed class, please review these materials. Now, you’ll spend some more time solidifying your understanding.There are a huge number of resources out there. We suggest you look at two types:  One that gives a high level overview and a visualization. We suggest the first one, but are providing a few other great options:          This interactive visual overview of CNNs from a collaboration between Georgia Tech and Oregon State. This one will allow you to explore each of the layers and functions. You can click on each of the parts to see more. There’s a little video at the end that shows how to use the tool.      This write-up with some helpful visualizations by Ujjwal Karn.      One of the earlier types of these visualizations focused on handwritten numbers  by Adam Harley.      Training on MNIST in the browser by Karpathy. This one shows the weights and the gradients.        This lecture by Serena Yeung of Stanford (part of one of the most famous academic AI labs) explaining convolutional neural networks. This lecture provides a little bit of history and does a nice job explaining some key terms and concepts, getting into the specifics and the math. This also gives you a taste of a classic academic lecture on this topic. Here’s the website from their class, which may also be a helpful but not required resource.As always, you’re welcome to find alternative resources (and share them with everyone if they are awesome)!For these first two exercises, we’d like you to attempt to recall the answers based on what you learned above (without immediately looking back at these resources). The act of trying to recall things from your memory helps slow the forgetting process (see this article by researcher Dr. Kathleen McDermott if you want evidence of this). Then you can check your answers with the resources and make your answers better.                        \tExercise 1    \tBased on the materials above, explain the following terms/concepts:  Convolution (conceptually and as a dot product)  Filter size (F)  Stride  Padding (e.g., zero padding)  Max pool  ReLu  Flatten    Show / Hide Solution    SolutionThe questions below will help you figure out if you understand some of these terms. The answers are in the suggested resources or you can look them up from other resources. We’re intentionally not providing them here as we want you to practice making sense of other resources and summarizing, but feel free to use other resources or an LLM to check your understanding.                             \tExercise 2    \tDescribe the general architecture of a convolutional neural network for image classification. You don’t need to go into a lot of detail here, we just want to draw your attention to the major things that happen and the order that they happen in.    Show / Hide Solution    SolutionIn CNNs, we start with an input image. We then apply a series of filters by sliding them across the image and getting a set of outputs that preserve the spatial information. This is typically followed by a non-linear activation function (e.g., ReLU). We often shrink the overall size by using some combination of pooling (e.g., max pool) and stride during the convolution. This can be repeated multiple times depending on the depth of the model. Finally, the output layers (that still have spatial information in their organization) are flattened (put into a vector) and then go through a series of multilayer perceptrons (or other linear layers) until a final classification layer.                             \tExercise 3    \tPart AGiven an input feature map of size 32 × 32 with a single channel, a filter size of 5 × 5, a stride of 1, and no padding, calculate the dimensions of the output feature map after a single convolution operation.Show / Hide Solution    SolutionThe value after the filter (convolutional filter) goes into the spot that is the center of the filter. This means we’ll lose two rows and two columns on each side (since we have no padding). This will give us an output of 28x28.Part BRepeat the above exercise for a filter of size 4 x 4. Why would we not want this filter?Show / Hide Solution    SolutionA 4x4 filter doesn’t have a center that we can index (it’s either the 2nd or 3rd item). It also changes or image size from an even to an odd number, shifting the middle of our image and losing some information in an asymmetrical way.                        \tExercise 4    \tFor an RGB image of size 28x28, apply 6 different 7x7x3 filters with zero-padding of 3 and a stride of 1. What is the size of the output (give all dimensions)?    Show / Hide Solution    Solution28x28x6. Each filter takes the image from a depth of 6 to a depth of 1, but there are 6 of them that get stacked. The padding of 3 balances out the filter size of 7, keeping the height and width at 28.                             \tExercise 5    \tGiven a grayscale image of size 64×64, apply a convolutional layer with the following parameters:Filter size: 5×5 Stride: 2 Padding: 0 (no padding) Calculate the size of the output feature map after applying this convolution.    Show / Hide Solution    Solution\\(Output Dimension = \\frac{Input Size - Filter  Size + (2 * Padding)}{Stride} + 1\\)\\(\\frac{64 - 5 + (2 * 0)}{2} + 1\\)The output will be 30 x 30.                             \tExercise 6    \tCalculate the output from the following filter by hand (calculator fine).  There is no padding for the image.Filter:\\(\\begin{bmatrix}0 &amp; -1 &amp; 0 \\\\  -1 &amp; 4 &amp; -1 \\\\  0 &amp; -1 &amp; 0 \\\\  \\end{bmatrix}\\)Image:\\(\\begin{bmatrix}10 &amp; 0 &amp; 10 &amp; 0 \\\\  10 &amp; 0 &amp; 10 &amp; 0 \\\\  10 &amp; 10 &amp; 10 &amp; 10 \\\\  0 &amp; 0 &amp; 10 &amp; 60 \\\\  \\end{bmatrix}\\)    Show / Hide Solution    SolutionBecause there is no padding, the output image will be smaller. You might realize that the setup for the top right and the bottom left have the same numbers, so you only have to do the math once. Notice how the relevant values in the bottom right are all 10s, so the filter outputs zero. Also notice how the big number in the bottom right corner makes no difference at all in this filtering.\\[\\begin{bmatrix}-30 &amp; 20 \\\\  20 &amp; 0  \\\\  \\end{bmatrix}\\]Please note that ChatGPT4o got this wrong when we put it in, but ChatGPTo1-preview got it correct.                             \tExercise 7    \tIn this notebook, you will create your own filters and apply them like they are part of a convolutional neural network. You will need to do a little research on filter types.https://colab.research.google.com/github/olinml2024/notebooks/blob/main/ML2024_Assignment_15_Manual_Convolutions.ipynb    Show / Hide Solution    SolutionWe are not giving solutions here because we want you to come up with your own filters so we can discuss and compare variations of the filters in class. If you’re stuck on how to write any of the functions, please come to office hours or post in the Slack.     ",
        "url": "/assignments/assignment15/assignment15.html"
      },"assignments-assignment16-assignment16-html": {
        "title": "Assignment 16: Convolutional Neural Networks (ConvNets, CNNs) in Code",
        "author": "",
        "category": "",
        "content": "Learning Objectives\t\t        \tLearning Objectives\t\t\t     Identify and explain key components of a convolutional neural network (CNN)  Implement convolutional neural networks, understanding the sizes of data  Learn about transfer learning and apply it to data\tThis assignment is very open ended with the intent of creating space for you experiment and learn and then share back in class.A CNN notebookFor this assignment, we have created a detailed notebook for you that give you almost all the code that you need to experiment with CNNs. Our goal here is to help you to experiment and build some intuition without spending tons of time troubleshooting code.However, for some of you, you might get a deeper sense of the material if you code the whole thing from scratch. There’s nothing in here that you can’t do, so please feel free to write your own code from scratch if it will help your learning.Here is the notebook.What to submitFor your quality assessed deliverable, we may to ask you to submit answers to some of these questions, so keep that in mind as you document your work.For people using assessment option B, you don’t need to submit all of your code. We aren’t giving you solutions here, so you also don’t need to do the corrections. Please submit a document that answers the questions below. You will need to include some key figures (which are mostly generated for you).What to do and what to answerStart by looking through the whole notebook to get the gist of what is there. Be sure to note where models are defined, where training happens, how a subset of the data is selected, and what variables you can change.MNIST datasetThe MNIST dataset has grayscale images of digits.                        \tExercise 1    \t  Choose 3 digits to include in your model and change the code to select these.  Create a very small training set (e.g. 16 examples per class).  Train the model called FC_only for enough epochs that the loss curve flattens (and ideally begins to overfit).  In your write-up, show the loss over epochs plot, the test confusion matrix, and the training and test accuracy.    Show / Hide Solution    Solution                             \tExercise 2    \t  Research CNNs in PyTorch  Create a model called Grayscale1Convolution. The model should include 1 convolution layer and 1 max pooling layer that reduces the image size by 1/2. You will need to do some math on the sizes of each of the inputs and outputs to make this work. (This model should also have 1 fully connected layer.)  Train the model called Grayscale1Convolution for enough epochs that the loss curve flattens (and ideally begins to overfit).  In your write-up, show your model code for Grayscale1Convolution, the loss over epochs plot, the test confusion matrix, and the training and test accuracy.    Show / Hide Solution    Solution                             \tExercise 3    \tExperiment with at least 2 activation functions and explain how they affect your model results.    Show / Hide Solution    Solution                             \tExercise 4    \t  Increase the amount of data significantly and rerun both models.  In your write-up, show the loss over epochs plot, the test confusion matrix, and the training and test accuracy.  Make observations comparing to the last experiments.    Show / Hide Solution    Solution     CIFAR10 datasetThis dataset shows 10 categories of images. While you are building your model, you may want to work with a small subset of the data. At the end, you should run it with a larger version of the data.                        \tExercise 5    \tCreate, train, and document a model with 1 convolution layer and 1 max pooling layer. (This model should also have 1 fully connected layer.)    Show / Hide Solution    Solution                             \tExercise 6    \t  Create at least two other models that work better than this original model on your dataset.  Document your experiments by including the loss plot, confusion matrices, and relevant metrics.If you are stuck on what to do, you might experiment with increasing the model complexity (more layers), adding dropout, changing the pooling, augmenting the data, etc.    Show / Hide Solution    Solution     Transfer learningPeople often use transfer learning, where we build on a pre-trained model (that was trained on a huge dataset) and then tweak it for our own purpose. This is incredibly powerful. Here’s one video on transfer learning, but feel free to find your own resource (and skip ahead in this video).The PyTorch documentation has a nice description and example of transfer learning. Note that you can open it in a Colab notebook at the top of the page.You can modify our existing notebook to do transfer learning. You’ll need to read through the given transfer learning example and extract relevant parts of the code.                        \tExercise 7    \tResearch transfer learning. Apply transfer learning to the CIFAR10 and our dessert dataset (our notebook should help you with loading these), comparing how well it works on these two datasets under a few different conditions (e.g., small number of epochs, small number of training images).Write a short summary what you experimented with and what you learned (including key figures or pieces of information). You do not need to share your full code (and it’s fine to run things and then copy an image).    Show / Hide Solution    Solution     ",
        "url": "/assignments/assignment16/assignment16.html"
      },"assignments-assignment17-assignment17-html": {
        "title": "Final Project",
        "author": "",
        "category": "",
        "content": "OverviewThe final project is your chance to really customize this learning experience.  In contrast to previous projects, you have substantially more autonomy to choose a project topic that is exciting / important / valuable to you.  As a result, you will be charting your own course, exercising and practicing your independent learning skills, and potentially working with a partner.The deliverables for this project will consist of the following.  A project proposal detailing your learning goals for the project, your project topic, initial steps, MVP, stretch goals, and whether or not you are working with another person.  A deliverables proposal that fleshes out the deliverables you expect to produce by the end of the project.  A video summary that presents the main results of your project in a polished manner.  Your project deliverables (as appropriate to your project and following the plan put forth in your deliverables proposal).  A final reflection on the project and your contributions to it.Please see this spreadsheet for due dates and grading percentagesChoosing a Project Topic and Possibly a PartnerOn Canvas (Project Topic Brainstorm assignment), we gave you a link to the 2019 project posters. We also have some slides we’d like to go through to help introduce the final project.Deliverable: Project ProposalProject TopicDescribe the project you plan to do.  As part of this discussion, make sure to explain why you’ve chosen the particular project (why it’s important).  This section should be sufficiently detailed (and specific) for us to give you meaningful feedback.Learning goalsWhat are your learning goals for this project? How might they relate to the broad categories of implementation, context, and theory? (Just to be clear, we are not suggesting you have to address all of these categories).  Identity, in terms of percentages, in each of these three categories (they should add to 100%, because math), where your ideal project would land.  We’ve also requested that your project is no more than 70% in one category.Collaboration / Execution PlanDiscuss how you are going to get the work for this project done.  This should include a definition of your best guess as to what the deliverables of your project will entail (apart from the deliverables we discuss here).  For each deliverable, you may want to define your MVP (minimum viable product) as well as stretch goals.  You should also identify  initial steps to take to get off to a strong start (this is an area where we can help you quite a bit if you give us some details).  For team-based projects you should include a discussion about how you anticipate communicating and coordinating work with your partner.  For example, you could discuss your plans for synchronous versus asynchronous work, layout a specific strategy for managing / tracking tasks, and discuss your planned communication channels.Rubric:  20%: The project topic is well-described and some reasoning for why you want to investigate it is given.  20%: Your learning goals for the project are provided and the learning goals are appropriate to the project, specific, and measurable.  10%: The proportion of emphasis on the themes of theory, implementation, and context and ethics is included (and explained) and no theme is more than 70% of the total work.  20%: Initial steps are provided and appropriate.  20%: For each deliverable you have specified an MVP and stretch goals.  10%: You have a plan for coordinate work and (if applicable) communicating with your partner, or, you have a plan to make sure you make progress if working aloneDeliverable proposalYour projects have a lot of variability in their topics and learning goals, and we want to give you the freedom to choose deliverables that are appropriate for your project and best support your learning. We also want to make sure that you feel you are being fairly assessed and that we (your team and the teaching team) have a shared sense of what a “good” output looks like. Therefore, at some point in your project, you will propose what you think appropriate final deliverables will look like for your project, and we will discuss this together (probably via a check-in conversation).You should be sure to read the Project Deliverables section.This proposal should reference your learning goals. (Since what you are doing should probably support your learning goals.)We strongly suggest that you point to some existing source to give an example of what you might model your deliverables on. For example, if you wanted to make a blog entry to give a detailed explanation of the theory behind a new method (convolutions on graphs), you might point to this example and say “I’m thinking about doing something like this: https://distill.pub/2021/understanding-gnns/”.  Or, you might be focusing on implementation and context, and you could decide to point back toward your small data mini project as an example.  You don’t have to find the perfect deliverable template, but showing us an example might help clarify your own thinking and also lead to a clearer conversation with us.Video SummaryPrepare a 1-minute video that summarizes your project topic and your primary accomplishments (e.g., what you built, what you learned, etc.).  Your video should be professional and polished and accessible to folks who have some familiarity with machine learning but are not experts in the particular area that you investigated.  As the project unfolds, we will provide more guidance, examples, and a peer review process to help you make a great video.We will post a detailed rubric for the video summary soon.Project DeliverablesWe’ll post an assignment on Canvas to allow you to turn in appropriate, project-specific deliverables.  Depending on the project you chose, these may take on a variety of forms.  Here are some other important guidelines for your project deliverables to keep in mind.Guideline 1: Any aspect of the project that you would like us to assess should be included in your submission with clear guidance on what is what (e.g., a repository of code, Colab notebooks, a final report). Deliverable should be uploaded instead of linked (e.g., please upload a pdf of a report instead of linking to a google drive); for some deliverables, a link may be more appropriate, so chat with us if this is the case (e.g., you made a huge dataset and can’t upload it to canvas; or your code is written with a large number of function files).Guideline 2: Your deliverables should properly frame the project and contextualize your work.  This means that the deliverable should be stand-alone in the sense that someone who hasn’t been following along with your project for the last several weeks should be able to understand what you did.  Additionally, your deliverables must “tell the story” of your project.Guideline 3: In your individual final reflection you will be able to help us understand both what you got out of this project and what your general approach to the project was.  This information does not need to be duplicated in the deliverables here.Guideline 4: Please attribute to others appropriately (including a link when possible). When writing about context or theory, this means citing your sources (format of this depends on your deliverable). You do not need to write all of your own code from scratch (for many situations, it’s actually a great choice to build off of the code of others, depending on what your learning goals are). However, you should be clear about what you wrote and what was taken directly from other sources. This gets a little fuzzy in code-land, so we’ll try to provide some guidance here. You don’t need to attribute to every stackoverflow page that helped you solve a problem (even if it means you copied a few lines of code to fix something). If you are working with a kaggle dataset and used someone else’s code as a guide for your data loading and analysis, you should be sure to note this.The two major things that we will assess your final project deliverables on are:  Quality: Is this a high-quality project and set of deliverable appropriate to a course at this level  Demonstration of understanding: Do the project deliverables appropriately demonstrate your understanding of the material (in such a way that it is clear to us that you understand what you did)?The assessment will also include smaller allocation to:  Appropriate amount of work given number of team members  Intellectual difficulty of work (challenge given course)  Deliverable clarity / communication  Completeness and submission of work agreed upon in Deliverables Proposal  Ability of work to standalone and tell the story  Appropriate attribution  Wow factor (only a bonus, no detriment for not having a wow factor, learning is more important than flashiness, this is just a place for us to use our judgement to give bonus to some notable work if that isn’t effectively captured by our rubric)Final EventDuring the final event, we will celebrate your work with a project expo.  We’ll have stations setup for you to show your work to your fellow classmates (and instructors).  If you’d like, you can make a poster for this event, but you can also use a laptop to show your final deliverables.Rubric: attendance and full participation in the final will earn a 100%.  If you cannot attend the final event, you must make arrangements to meet with Sam or Paul to go over your final project (similarly to what you would do for folks who come by our station if you were to be there for the final event).Final ReflectionIn this assignment you will reflect on the course and the project. We will give you some specific prompts. You will be assessed on completion and thoughtfulness, but not on if we agree with you or like what you say.For you, this process of reflection is intended to help you grow and to understand more about yourself.For us, this reflection will help us have more context about your experience in the project and the course. We acknowledge that assessments of “quality” and “demonstrating understanding” are somewhat subjective, that project work is not always distributed equally, and that people come to the class with different levels of experience. Additionally, this reflection will help us think about the class next time and grow as instructors (we went back and looked at prior final reflections when designing this project).",
        "url": "/assignments/assignment17/assignment17.html"
      },"activities-day01-html": {
        "title": "Day 1: Course intro and welcome to ML!",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:22am: Everyone come hang out in MAC128.  10:22-10:30am: We’ll provide brief orienting remarks about the course!  10:30-10:35am: Introduction to our main activity (see below).  10:35-11:15am: Mapping the Machine Learning Ecosystem  11:15-11:40am: Report out  11:40-12:00pm: Orientation to first assignment and basic course logistics for assignment submissions.  We’ll show you the Canvas page, grading options, how to find office hours, etc.\tThe Big PictureWelcome to Machine Learning!  We’re not going to spend a ton of time talking at you today (we want to get you engaging with the material as quickly as possible).  A few quick things.What is Machine Learning?As a running example, let’s take the idea of creating a computer program to predict various characteristics of a person (e.g., age and gender) from a picture of their face.One way to frame machine learning is by contrasting it with the traditional approach to writing an algorithm to solve a problem.  Here is a somewhat cartoonish version.flowchart LR  id1[Data]  id2[Hand-coded Program]  id3[Output]  id1 --&gt; id2  id2 --&gt; id3This might seem like a seemingly impossible task, but it’s one that the machine learning approach can be applied to quite easily.  Here is the workflow when adopting a machine learning approach.flowchart LR  id1[Data]  id2[Machine Learning Algorithm]  id3[Program]  id4[Desired Outputs]  id1 --&gt; id2  id2 --&gt; id3  id4 --&gt; id2This picture helps us undertand the potential scope of the machine learning approach.  Is machine learning just what happens in the middle box?  What about the inputs and outputs?  We probably have a lot of questions about those.  Let’s take a minute to throw out a few considerations.Learning GoalsMachine learning is a vast field that touches upon many disciplines.  In this class we aim to take a broad view towards the subject that covers the underlying theory, implementation, and critically evaluating how machine learning systems impact the world and its people.  Understand a variety of machine learning techniques from both a mathematical and algorithmic perspective.  Successfully implement machine learning algorithms in Python (both by using only minimal external libraries and by leveraging standard machine learning libraries).  Execute the iterative machine learning workflow of model design, fitting to training data, testing, and interpretation in order to be able to successfully apply machine learning techniques in specific contexts.  Contemplate the potential impacts of a machine learning system when deployed in a real-world context and make design decisions to mitigate potential harmful impacts while maximizing positive impacts.Mapping the machine learning ecosystemA few years back when we were originally designing this course, we were struck by this incredible visualization of a machine learning-powered system (the Amazon Echo).  (note: click on the following link to see the original, high-resolution, vector graphics version).We don’t necessarily recommend diving into the nitty gritty here, but we do want to point out some of the interesting features of this map.  This map looks at the lifecycle of the system.  This includes development, manufacturing, usage, and disposal.  This map examines the diverse (along many dimensions) group of people that interacts with the Amazon Echo.  This map shows relationships between different organizations (e.g., transportation companies and distributors).  This map explores a variety of inputs and outputs to the product (e.g., data, energy, raw materials, human knowledge).One of the hallmarks of this course will be in contextualizing machine learning systems within larger systems (e.g., economic, social, environmental) so we can better understand the likely impacts of machine learning technology and how we, as engineers, can increase positive outcomes while reducing negative ones.  We’ll have dedicated class activities and readings to help make the picture clearer of how machine learning fits into various contexts, but today we want you to dive into the deep end of the pool and do some research to map out a machine learning system of your choosing.Step 1: Do Some Background ReadingRead the article Machine Learning Lifecycle Explained.  This article will give you a nice high-level view of what it takes to create a machine learning model.  The article doesn’t look at all of the possible dimensions you might consider, but it does give some good jumping off points (e.g., the article doesn’t talk about electricity or environmental impacts).Step 2: Choose a Machine Learning System to MapYou probably have a few in mind that you are interested in thinking about. For the purposes of this exercise you should probably choose examples that you are already familiar with (or that you can quickly lookup key information).Here are some ideas off the top of our heads:  Large language models (e.g., ChatGPT, Claude, etc.)  Google  Generative image models (e.g., Midjourney)  The SeeingAI app (Microsoft’s app to make various tasks more accessible for folks who are blind)  Job applicant screening tools  Self-driving cars  Facial recognition software  Fitness, health, and safety features in Apple Watches (e.g., fall detection, health monitoring, etc.)Step 3: Make your MapOn a whiteboard, draw a system map of the various stakeholders, stakeholder interactions, inputs into the system (e.g., energy, cost, knowledge), outputs (impacts of the system), potential pitfalls, and opportunities.  As you go, make a list of the key questions that you would like to answer to better understand how your chosen system (if you have time, you may throw these into a search engine or an LLM to see if you can get some quick ideas as to an answer).Here are some prompts to consider to help get you thinking:  Who is involved?  Consider data creators, research scientists, data labelers, machine learning engineers, user-experience specialists, consumers, legislators / regulators, etc.  Who are the organizations? Of the folks involved, what organizations are they a part of (these could be governmental, commercial, or non-profit).  Where are the interaction points?  How do individual or organizations interact with each other?  What is exchanged between them (e.g., knowledge, money, data, computing resources)?  With respect to the benefits of the system, consider the experience of the end user (what do they get from using the system?), consider the knock-on benefits to the system creator (e.g., providing more training data), and does anyone else benefit?  With respect to potential pitfalls (or negative impacts), consider issues of environmental and financial impact along with the potential for model bias that causes differential impacts to different groups of people that interact with the system (e.g., based on some identity characteristic like race or gender).Step 4: Share Your MapMake sure you take a high-resolution picture of your map and add it to this shared Slide deck.  We’ll give each team a chance to discuss an interesting feature of their map (there won’t be time to present the map in its entirety, so you’ll have to choose 1-2 things to share).Orientation to Assignment 1, Course Logistics, and Educational Research Opportunity  Where to find first assignment  Canvas (where to find stuff)Educational Research Opportunity  11:40-12:00pm: Orientation to first assignment and basic course logistics for assignment submissions.  We’ll show you the Canvas page, grading options, how to find office hours, etc.",
        "url": "/activities/day01.html"
      },"activities-day02-html": {
        "title": "Day 2: Community-Centered Design for Machine Learning",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:45am: Debrief at tables about the last assignment.  10:45-12pm: Presentation on Community-centered design for ML\tDebrief on the last assignment  Introduce yourselves  Quickly draw a confusion matrix at your table and write the equations for accuracy, precision, and recall.      Discuss your answers for Exercise 9 in the Colab notebook (see exercise below as a reminder).    Exercise 9: Summarize how well the dessert classifier works for french toast and red velvet cake. Come to class prepared to share this at your table. Consider the confusion matrix, precision, and recall. How do you interpret this? What does it mean for life as french toast or as red velvet cake?  Community-Centered Design for ML  Slide deck from summer + something more active to cap it off (e.g., critiquing something we did or extending it in some way)",
        "url": "/activities/day02.html"
      },"activities-day03-html": {
        "title": "Day 3: 	Model Validation and Community-centered Machine Learning",
        "author": "",
        "category": "",
        "content": "Mapping frameworks for community-centered design to various problemsTodoSome prep work for the model evaluation part of the assignment  Idea of ranking and hard negativesPlay with appExamine qualitative data.",
        "url": "/activities/day03.html"
      },"activities-day04-html": {
        "title": "Day 4: 	Metrics and Meeting ML as Optimization",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:45am: Applying Frameworks for Community-Centered ML  10:45-10:55am: Supervised Learning Problem Setup  10:55-12:00pm: Start assignment\tThe Supervised Learning Problem Setup (Learning as Optimization)We’re now switching gears to talk about how machine learning can be thought of as an optimization problem.  We’re going to start with a mathematical definition the simplest type of machine learning: supervised learning.  Along the way you’ll get a chance to build your conceptual knowledge about how learning can be thought of as a learning problem.  Note: this next section is also in the homework, but we wanted to have a chance to go over this together.Suppose you are given a set of training data points, $(\\mathbf{x_1}, y_1), (\\mathbf{x}_2, y_2), \\ldots, (\\mathbf{x}_n, y_n)$ where each $\\mathbf{x_i}$ represents an element of an input space (e.g., a d-dimensional feature vector) and each $y_i$ represents an element of an output space (e.g., a scalar target value).  In the supervised learning setting, your goal is to determine a function $\\hat{f}$ that maps from the input space to the output space.  For example, if we provide an input $\\mathbf{x}$ to $\\hat{f}$ it would generate the predicted output $\\hat{y} = \\hat{f}(\\mathbf{x})$.We typically also assume that there is some loss function, $\\ell$, that determines the amount of loss that a particular prediction $\\hat{y_i}$ incurs due to a mismatch with the actual output $y_i$.  We can define the best possible model, $\\hat{f}^\\star$ as the one that minimizes these losses over the training set.  This notion can be expressed with the following equation  (note: that $\\argmin$ in the equation below just means the value that minimizes the expression inside of the $\\argmin$, e.g., $\\argmin_{x} (x - 2)^2 = 2$, whereas $\\min_{x} (x-2)^2 = 0$).\\begin{align}\\hat{f}^\\star &amp;= \\argmin_{\\hat{f}} \\sum_{i=1}^n \\ell \\left ( \\hat{f}(\\mathbf{x_i}), y_i \\right )\\end{align}Getting Started on Linear RegressionA particular type of supervised learning problem is called linear regression or least squares.  You met this algorithm way back in QEA1, but we don’t expect you to recall all of those details!  We’re going to go over linear regression from a different perspective in this class.  We find that it often takes us multiple encounters with the same idea to start to really achieve proficiency (hopefully this is another step along that journey for you).The way we recommend engaging with this material is by starting on assignment 3.  We would like to invite those who want to adopt a quieter, more independent work style to travel over to MAC126.  We’ll circulate around to that room and answer any questions.  Those who want to collaborate and work through problems together, can remain here.",
        "url": "/activities/day04.html"
      },"activities-day05-html": {
        "title": "Day 5: 	Linear, Ridge, and Logistic Regression &amp; Train-Test Split",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:30am: Debrief at tables  10:30-10:50am: Ridge Regression  10:50-11:40am: Classification and train/test split  11:40-12:00pm: Logistic Regression Primer\tDebrief on the last assignment (5 minutes)Warm up your brains by refreshing on the last assignment, including the derivation of linear regression… we’re going to use it in a minute.Ridge Regression Math (20 minutes)You’ll do some more on ridge regression in the assignment, including an exploration of why it’s useful. In class, we’re going to go over the math of ridge regression (which will also be an exercise on your assignment).One way to mitigate the problem of having two little data or having features that are linear combinations of each other is to modify the linear regression problem to prefer solutions that have small weights.  We do this by penalizing the sum of the squares of the weights themselves.  This is called ridge regression (or Tikhonov regularization).  Below, we show the original version of ordinary least squares along with ridge regression.Ordinary least squares:\\[\\begin{align*}\\mathbf{w^\\star} &amp;= \\argmin_\\mathbf{w} \\sum_{i=1}^n \\left ( \\mathbf{w}^\\top \\mathbf{x_i} - y_i \\right)^2  \\\\  &amp;= \\argmin_\\mathbf{w} \\left ( \\mathbf{X}\\mathbf{w} - \\mathbf{y} \\right)^\\top \\left ( \\mathbf{X}\\mathbf{w} - \\mathbf{y} \\right)\\end{align*}\\]Formula for the optimal weights in linear regression:\\[\\begin{align*}\\mathbf{w^\\star} = \\left ( \\mathbf{X}^\\top \\mathbf{X} \\right)^{-1} \\mathbf{X}^\\top \\mathbf{y}\\end{align*}\\]Ridge regression (note that $\\lambda$ is a non-negative parameter that controls how much the algorithm cares about fitting the data and how much it cares about having small weights):\\[\\begin{align*}\\mathbf{w^\\star} &amp;= \\argmin_\\mathbf{w} \\sum_{i=1}^n \\left ( \\mathbf{w}^\\top \\mathbf{x_i} - y_i \\right)^2 + \\lambda\\sum_{i=1}^d w_i^2  \\\\  &amp;= \\argmin_\\mathbf{w} \\left ( \\mathbf{X}\\mathbf{w} - \\mathbf{y} \\right)^\\top \\left ( \\mathbf{X}\\mathbf{w} -  \\mathbf{y} \\right) + \\lambda \\mathbf{w}^\\top \\mathbf{w}\\end{align*}\\]The penalty term may seem a little arbitrary, but it can be motivated on a conceptual level pretty easily.  The basic idea is that in the absence of sufficient training data to suggest otherwise, we should try to make the weights small.  Small weights have the property that changes to the input result in minor changes to our predictions, which is a good default behavior.Derive an expression to compute the optimal weights, $\\mathbf{w^\\star}$, to the ridge regression problem.Classification and Train/Test Split in scikit-learn (40 minutes)Overfitting our model to our data can lead to diminished results when we apply our model to a new set of data. One of the ways we try to avoid overfitting is by splitting our data into a training and testing set. (In the future, we will talk about another split of the training data called cross-validation, but for now, we won’t worry about that.)Scikit-learn is a common python library for classic machine learning.We are going to do a guided tour of this Colab notebook on classificationLogistic Regression PrimerWe’ve met the idea of classification. Logistic regression is one algorithm for binary classification. It builds nicely on linear regression and feeds nicely into neural networks (which we will explore soon).                            Figure 1: Graphical representation of both linear and logistic regression.  The key difference is the application of the squashing function shown in yellow. Original Source - Towards Data Science    In your assignment, you’ll be meeting loss functions for binary classification.",
        "url": "/activities/day05.html"
      },"activities-day06-html": {
        "title": "Day 5: 	Logistic Regression Sample Problem, Foundations of Micrograd",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:35am: Debrief at tables  10:35-11:00am: Logistic Regression Example Problem  10:50-11:30am: Logistic Regression Learning Rule  11:30-12:00pm: Foundations of Micrograd\tDebrief on the last assignment (10 minutes)Warm up your brains by refreshing on the last assignment.  As a reminder, some of the big ideas were classification algorithms, log loss, and confounding variables.Logistic Regression Example Problem (25 minutes)We’re now going to be diving into logistic regression.  We’ll start out by writing the basic ideas of logistic regression up on the board, and we’ll go through a notebook that shows a sample problem.The content we’re going to use for this is contained in the beginning part of assignment 5.  Let’s jump over there and look at it together.Next, we’re going to go thorugh a Colab notebook that shows an example logistic regresion problem.Logistic Regression Learning Rule (40 minutes)Let’s use assignment 5 to begin to unpack some of the concepts behind choosing the best set of weights for logistic regression.  Before we start, we’ll go over our high-level strategy.Foundations of MicrogradLet’s use assignment 5 to build some of the foudnations we’re going to need to optimize a wide range of machine learning models given a trainig set.",
        "url": "/activities/day06.html"
      },"activities-day07-html": {
        "title": "Day 6: Starting COMPAS and Building Towards Autodifferentiation",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:35am: Debrief at tables  10:35-10:40am: Going Over Simplification in Logistic Regression Learning Rule  10:40-10:50am: Preview of where we are going  10:50-12:00pm: Foundations of Micrograd\tDebriefBased on responses to the survey, we think people are still a bit fuzzy on data flow diagrams.  We recommend you come up with a function, create a dataflow diagram to represent it, and then use that dataflow diagram to compute the partial derivative of the function with respect to each of its inputs.Preview of where we are goingWe’ll go over the upcoming gate on model evaluation.  We’ll also talk about the COMPAS algorithm and the readings we will be doing / the discussions we will be having.Buildings towards AutodifferentiationWhile you may still be having a bit of difficulty applying dataflow diagrams, hopefully the process is starting to become more mechanical.  In fact, given how mechanical it is, you may be wondering if there is a way to automate the process entirely.  Of course there is, and that’s where we are going to go next.  What we will be doing in assignment 7 (not this coming assignment but the next), is using the concepts of data flow diagrams to implement a system for automatically computing the gradient of any function!Next, we’ll go step-by-step through the process of going from dataflow diagrams to auto differentiation.Step 1: Modify our dataflow diagram to compute gradientsLet’s go back to our minimal example of a multivariable function that we used to first introduce the concept of dataflow diagrams.flowchart BT id1[\"$$f = f(x,y)~~~~$$\"] id2[\"$$x = x(t)~~$$\"] id3[\"$$y = y(t)~~$$\"] id2 --&gt; id1 id3 --&gt; id1 t --&gt; id2 t --&gt; id3In order to compute $\\frac{\\partial f}{\\partial t}$ we traced all possible paths from $t$ to $f$, multiplied the partial derivatives along the way, and then added up each of these paths.\\begin{align}\\frac{\\partial f}{\\partial t} &amp;= \\frac{\\partial f}{\\partial x} \\frac{\\partial x}{\\partial t} +  \\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial t}\\end{align}This all seems well and good, but this approach is not quite as systematic as we might like and it suffers from some computational challenges.  Consider a more complex dataflow diagram in the next problem.                        \tExercise 1    \tflowchart BT id1[\"$$f = f(q,p)~~~~$$\"] id2[\"$$x = x(t)~~$$\"] id3[\"$$y = y(t)~~$$\"] id4[\"$$r = r(x, y)~~$$\"] id5[\"$$s = s(x, y)~~$$\"] id6[\"$$q = q(r, s)~~$$\"] id7[\"$$p = p(r, s)~~$$\"] id2 --&gt; id4 id2 --&gt; id5 id3 --&gt; id4 id3 --&gt; id5 id4 --&gt; id6 id4 --&gt; id7 id5 --&gt; id6 id5 --&gt; id7 id6 --&gt; id1 id7 --&gt; id1 t --&gt; id2 t --&gt; id3Use the data flow diagram method to compute $\\frac{\\partial{f}}{\\partial t}$.    Show / Hide Solution    Solution     You can see that things are getting a bit out of hand.  If you started adding more layers, we would be in even more trouble.  At this point things might seem a bit hopeless, but there are a few observations we can make.  A lot of the paths from $t$ to $f$ go through the same parts of the dataflow diagram.  The procedure above is great for computing a symbolic expression to compute $\\frac{\\partial{f}}{\\partial t}$, however, when optimizing a function, for example using gradient descent, all we care about is computing the gradient given some specific values of our parameters.Given these two observations we can modify our dataflow diagram to more efficiently compute the partial derivatives we need.  Let’s now return to our simpler case and see how we can modify it.  Before we provide this example, let’s state our assumptions and define some notation.  Assumption: We assume that already executed our original dataflow diagram.  That is, given $t$, we have computed $x, y, f$.  We are using the notation $grad_{v}$ to represent the evaluation of $\\frac{\\partial f}{\\partial v}$ based on the values $t, x, y, f$ (that is, $grad_{v}$ will just be a number, not a symbolic expression).  When we write $\\frac{\\partial g}{\\partial v}$ we think of this as the evaluation of the partial derivative of $g$ with respect to $v$ given the values $t, x, y, f$ (again, not a symoblic expression.  it is just a number).Given the above, let’s modify our dataflow diagram to more naturally compute our gradients.flowchart TB id1[\"$$grad_f = 1 ~~~~$$\"] id2[\"$$grad_x = \\frac{\\partial f}{\\partial x} grad_f~~$$\"] id3[\"$$grad_y = \\frac{\\partial f}{\\partial y} grad_f~~$$\"] id4[\"$$grad_t = \\frac{\\partial x}{\\partial t} grad_x + \\frac{\\partial y}{\\partial t} grad_y~~~~~~$$\"] id1 --\"$$\\frac{\\partial f}{\\partial x} grad_f~~$$\"--&gt; id2 id1 --\"$$\\frac{\\partial f}{\\partial y} grad_f~~$$\"--&gt; id3 id2 --\"$$\\frac{\\partial x}{\\partial t} grad_x ~~$$\"--&gt; id4 id3 --\"$$\\frac{\\partial y}{\\partial t} grad_y ~~$$\"--&gt; id4                        \tExercise 2    \tMake sense of the example above.  Try to understand where the expression for $grad_f$ comes from.  If you think about the concept of a recursive function, what might you call this?  Look at the other expressions for the partial derivatives.  Make sure these jibe with the rules you learned for dataflow diagrams.    Show / Hide Solution    Solution     Hopefully, this is making sense.  Let’s do a bigger example next.                        \tExercise 3    \tConvert the following dataflow diagram to efficiently compute $grad_v$ for $f, x, y, r, s, q, p$.  You should wind up with something similar to the previous example.flowchart BT id1[\"$$f = f(q,p)~~~~$$\"] id2[\"$$x = x(t)~~$$\"] id3[\"$$y = y(t)~~$$\"] id4[\"$$r = r(x, y)~~$$\"] id5[\"$$s = s(x, y)~~$$\"] id6[\"$$q = q(r, s)~~$$\"] id7[\"$$p = p(r, s)~~$$\"] id2 --&gt; id4 id2 --&gt; id5 id3 --&gt; id4 id3 --&gt; id5 id4 --&gt; id6 id4 --&gt; id7 id5 --&gt; id6 id5 --&gt; id7 id6 --&gt; id1 id7 --&gt; id1 t --&gt; id2 t --&gt; id3    Show / Hide Solution    SolutionExcuse the lack of annotation of the arrows.  We can show you in class as we walk around.flowchart TB id1[\"$$grad_f = 1 ~~~~$$\"] id2[\"$$grad_x = grad_r \\frac{\\partial r}{\\partial x} + grad_s \\frac{\\partial s}{\\partial x}~~$$\"] id3[\"$$grad_y = grad_r \\frac{\\partial r}{\\partial y} + grad_s \\frac{\\partial s}{\\partial y}~~~~$$\"] id4[\"$$grad_r = grad_q \\frac{\\partial q}{\\partial r} + grad_p \\frac{\\partial p}{\\partial r}~~$$\"] id5[\"$$grad_s = grad_q \\frac{\\partial q}{\\partial s} + grad_p \\frac{\\partial p}{\\partial s}~~$$\"] id6[\"$$grad_q = grad_f \\frac{\\partial f}{\\partial q}~~$$\"] id7[\"$$grad_p = grad_f \\frac{\\partial f}{\\partial p}~~$$\"] id8[\"$$grad_t = grad_x \\frac{\\partial x}{\\partial t} + grad_y \\frac{\\partial y}{\\partial t}~~~~$$\"] id4 --&gt; id2 id5 --&gt; id2 id4 --&gt; id3 id5 --&gt; id3 id6 --&gt; id4 id7 --&gt; id4 id6 --&gt; id5 id7 --&gt; id5 id1 --&gt; id6 id1 --&gt; id7 id2 --&gt; id8 id3 --&gt; id8     Thinking Through Autodifferentiation in Python                        \tExercise 4    \tOn assignment 7, you will be implementing autodifferentation in Python (using the exact procedure above).  We will guide you through a specific way to implement if (based on the micrograd framework by Andrej Karpathy).  If you have time though, you might think with your table about how to implement this algorithm.  You are probably not going to be able to get to the level of mapping our Python code, but you can think about the major building blocks you would need (e.g., you would need something to compute the forward pass through the dataflow diagram).    Show / Hide Solution    Solution     ",
        "url": "/activities/day07.html"
      },"activities-day08-html": {
        "title": "Day 8: COMPAS discussion",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:45am: Gathering information based on sources  10:45-11:00am: Large group debrief and introduction of impossibility theorem  11:00-11:20am: Small group exploration and sense-making of fairness metrics  11:20-12:00pm: Large group discussion of the big picture\tGather information based on external sourcesOn the whiteboard, please gather pieces of information that we learned from the readings or other sources. Take turns having each person share one thing that they wrote down for Exercise 1 in the last assignment.Large group debrief and introduction of the impossibility theoremHere are some summary slides, which also include refernce to the study Sam mentioned with humans attempting to predict re-arrest.We’ll summarize some key takeaways and show an example from an extreme version to help us wrap our heads around different models of fairness.https://medium.com/@alex.liu.roc/understanding-the-impossibility-of-fairness-199bba6c9072Small group exploration and sense-making of fairness metricsThe field of fairness and applications to human or algorithmic decision making is vast. Here are a few resources to guide your exploration of fairness metrics:  IBM’s exploration of COMPAS and fairness metrics  One group that made a tool for fairness and has a flowchart  Orange and blue dot example of fairness from the last assignment  Fair prediction with disparate impact - math paper on COMPASLarge group discussion of the big pictureWe will close our computers for this part and have a large group guided discussion.",
        "url": "/activities/day08.html"
      },"activities-day09-html": {
        "title": "Day 9: From Micrograd to Pytorch",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:45am: Instructor-led debrief of the homework… what just happened?!?  10:45-11:05am: Cross-entropy loss  11:05-12:00pm: From micrograd to Pytorch\tInstructor-led DebriefWe’ll debrief on what happened in the previous assignment.  The focus will be on connecting mathematical concepts to Python.  We hope that by the end of this everything is coming into focus for you (it may take a little longer to fully click).From Micrograd to PytorchWhile it may be tempting to ride our micrograd framework for the rest of the semester, you can probably tell that there are some good reasons to move to something a little more powerful.  We’re going to be using the pytorch framework for the remainder of the scaffolded work in this course (it’s possible you might venture into a different framework for the final project).  Machine learning frameworks like pytorch provide some really important capabilities for us.  An autograd engine  Built-in optimizers (that do, for example, gradient descent)  Optimized code that can efficiently handle large models (e.g., by running on a GPU or across several GPUs)  Specific building blocks for machine learning algorithms that are used by current state of the art algorithms.  The ability to be extended easily when the library doesn’t provide the necessary functionality.To help introduce pytorch, we’re going to jump right into a looking at some pytorch code.  This is a great chance to practice reading code and looking up documentation.  Your goal should be to understand the given code as well as possible.  If there are pieces that you can’t figure out, please ask us or make a note of your confusion so you can revisit it later.  You’ll also get a head start on the assignment (so that is a bonus!).The code in question is in the assignment 8, part 2 Colab notebook. The first two code cells load a dataset of handwritten digits and visualize them.  The third code cell is where the action is, we’d like you to go over that one, read documentation, ask ChatGPT, ask an instructor, etc., so that you leave here today with a solid understanding of a training / testing loop in pytorch.More Resources on PytorchWe’re going to be introducing Pytorch functionality on an as needed basis, but if you’d like to get some more practice with the basics, we recommend checking out some of the Pytorch tutorials.  Start with the basics of using Tensors.",
        "url": "/activities/day09.html"
      },"activities-day10-html": {
        "title": "Day 10: Pytorch Demystified and Trust and Trustworthiness in Machine Learning Systems",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:45am: Demystifying Pytorch  10:25-10:55am: Cross entropy and how to interpret the graphs from the homework  11:00-11:20am: Small data mini-project on classification  11:20-12:00pm: Choosing data for your mini-project and start working\tDemystifying PytorchWe’ll be going through the day 9 notebook.  There are three things we want you to get out of this notebook.  Pytorch is quite similar in its basic concepts to the micrograd framework you implemented.  We can use pytorch to compute a line of best fit.  This will allow us to visualize the optimization process more easily.  We can use pytorch modules (e.g., nn.Linear) to make our lives easier.Discussion on Trust and Trustworthiness of Machine Learning Systems",
        "url": "/activities/day10.html"
      },"activities-day11-html": {
        "title": "Day 11: Cross Entropy, Privacy in ML Systems, and Small Data Project Kickoff",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:45am: Demystifying Pytorch  10:25-10:55am: Cross entropy and how to interpret the graphs from the homework  11:00-11:20am: Small data mini-project on classification  11:20-12:00pm: Choosing data for your mini-project and start working\tCross entropy loss and softmaxIn the previous assignment you generated graphs that showed the cross entropy of a model to classify handwritten digits.  These graphs looked something like this.                            Figure 1: The cross entropy on the handwritten digit classification task.  The x-axis refers to the number of gradient descent steps.    Right now we are going to help you interpret what these graphs mean.  The y-axis is cross entropy, which for now we can simply understand as a measure of the model’s loss when its predictions are compared to the actual classes of the digits in either the training (blue line) or the test set (orange line).  The x-axis of this graph should be fairly easy to interpret.  The axis is labeled step, which refers to how many gradient descent steps have been taken by your optimizer in order to drive down the loss.In order to interpret these graphs we are going to need two ingredients.  First, we need to understand how a classifier, in response to a given input, can assign a probability of that input being a member of each of $k$ possible classes (notice how this contrasts with the binary classification case where we had to assign a single probability of the input being a $1$).  Second, we need a way to assign a loss value (cross entropy in this case) given a set of predicted probabilities and the actual class label of the digit.Assigning probabilities when there are more than 2 classesRecalling binary logistic regression, we needed a way to assign a probability to the class being 1.  To do this, we passed our weighted sum of features, $s$, through the sigmoid function $\\sigma(s) = \\frac{1}{1+e^{-s}}$.  In the multi-class case (again, where we have $k$ classes), we assume that we have computed a weighted sum of features for each of these k classes $s_1, s_2, \\ldots, s_k$.  We now calculate the probability of each particular class using the following formula called the softmax function.\\begin{align}p(y = i) = \\frac{e^{s_i}}{\\sum_{j=1}^{k} e^{s_j}}\\end{align}Here are some exercises to help you think through this.                        \tExercise 1    \t  Probabilities should always be non-negative and less than or equal to 1.  Additionally, a set of probabilities that forms a probability distribution should add up to 1.  Show that both of these conditions are satisfied for the softmax function.  Think about some limiting cases, what happens to the probability for class $i$ when $s_i$ gets really big?  What about when it becomes very negative?  Consider the case where $k=2$ and $s_1 = 0$.  How does this relate to the sigmoid function we learned about for log loss?    Show / Hide Solution    Solution     Calculating cross entropyNow that we have a way to calculate probabilities, we need to figure out how to assign a loss to any particular prediction.  The loss function we’re going to use here is called cross entropy and we’ll use the notation $ce$ to refer to it.  Let’s use the shorthand $\\hat{y}_i$ to be $p(y=i)$ (as defined, for example, by the softmax formula).  We can now think of $\\mathbf{\\hat{y}}$ as a vector of all of these probabilties.\\begin{align}ce(\\hat{\\mathbf{y}}, y) = \\sum_{i=1}^{k} -\\mathbb{I}[y = i] \\log \\hat{y}_i \\end{align}The following exercise will take you through some important takeaways.                        \tExercise 2    \t  Make sure you understand the role of the indicator function $\\mathbb{I}$, what is it doing to the terms in the summation?  The formula for log loss for binary classification is $\\ell(\\hat{y}, y) = -y \\log(\\hat{y}) - (1-y)\\log(1-\\hat{y})$.  Show that this formula is essentially the same as cross entropy when $k=2$.  Imagine that at the beginning of the learning process the digit classifier assigns equal probability to each digit (0-9) regardless of what the actual class is (i.e., the model hasn’t learned anything yet).  What do you think the model’s cross entropy should be in this case?    Show / Hide Solution    Solution     Small data mini-project on classificationWe’ll talk about the “Small data” mini-project on classification.Choosing data for your mini-project and start workingOur general recommendation is to choose a dataset that has at least one other person working on that dataset. This is not a requirement, so if you have something you’re passionate about, go for it! While this is a solo project, it may be helpful to have others to confer with who are also figuring out the nuances of your dataset. A lot of time in machine learning and data science go into interacting with the data before it even goes into the model. There are many canned (pre-curated data sets) out there which reduce this time, but it’s still important to understand your data, as it drives your model.We’ll do a little activity to help you find others who have overlapping dataset interest.Privacy in Machine Learning SystemsTODO",
        "url": "/activities/day11.html"
      },"activities-day12-html": {
        "title": "Day 12: Project Shareout and Course Feedback",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:55am: Share out about small data projects!  10:55-11:10am: Key takeaways from the project  11:10-11:35am: Reflection on the course so far  11:35-11:40am: Quality Assessed Deliverable: Key concepts of ML as Optimization  11:40-12:00pm: Preview of next assignment and text as data\tFind a home for thisOverfitting in Neural NetworksWe’ll talk about the common problem of overfitting in neural networks.  Here are some resources to look at to learn more.  We’ll go through this notebook, but we also have some more resources for you to look at.  PyTorch – Popular techniques to prevent the Overfitting in a Neural Networks  Dropout Regularization Using PyTorch: A Hands-On GuideShare out about small data projects!We want to celebrate and share about your small data mini-projects. Hooray, you did it! We’ll do a little share-out so that you can learn from each other and give high fives!Share at tablesLet’s start out by sharing what you did with the folks around you.  Take about 2 minutes each to go over what you did for the project and how it turned out.If you feel inclined, step up to the frontIf you have something you want to show the class (could be something you are proud of, a hard fought lesson, advice, etc.), please jump up and connect to the projector.Key takeaways from the mini-projectLet’s mix up the seating.  Please sit with people you don’t normally sit with.  As a group make a list of key takeaways for this project.  Some good prompts would be:  New things I learned through this project are…  I solidified my knowledge of…  Next time I use machine learning I will be sure to…Take about 10 minutes for this in groups and then we’ll do a 10 minute share out.Reflection on the course so farWe’re approaching the midpoint of the course (not quite yet), but this felt like a good time to pause and reflect on how things are going.First we’ll debrief at tables. Then we’ll devote a some time to reflecting via a survey (see “Interim reflection on course so far” in Canvas).Quality Assessed Deliverable: Key concepts of ML as OptimizationOne of the quality assessed deliverables for this course is a check-in on Key Concepts of ML as Optimization. In class last week, you made concept maps of the course content related to ML as optimization. We are planning to use an in-class, on paper assessment. The goal of this assessment is for you to demonstrate your understanding of the key concepts related to ML as optimization (see this Learning As Optimization Takeaways for details about what we expect).While we know that you’ll be using external resources for any future ML work that you do, we want to take this time to check in about your conceptual understanding of key ideas. We also want you to get a sense of what you understand well enough to articulate, which may be different than what we understand well enough to nod along to. The assessment will be designed to be done without the need for external sources (if calculators are needed, we’ll let you use your phones for this part). Through some recent conversations, we’re wrestling with how to both extend trust and also not ask you to carry the burden of willpower to not use external resources for a take-home assessment. We’re curious to hear what you think about this!If you have any accommodations that we need to prepare for to make this assessment work for you, please let us know so we can best support you. Our tentative plan is to give lots of time to complete the assessment in class and have it be the last activity before lunch (so folks can leave when they are done without putting time pressure on folks who want more time).Please show up to class for this assessment if you can. If you are out sick, we can schedule a make-up time.Preview of next assignment and text as dataIn addition to preparing for the Key Concepts of ML as Optimization assessment, we have another assignment to kick off our next module: TEXT! text. Text?",
        "url": "/activities/day12.html"
      },"activities-day13-html": {
        "title": "Day 13: Word Embeddings Introduction",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:25-10:30am: Reflection reflection  10:30-11:10am: Assignment debrief and preview  11:10-12:00pm: Quality Assessed Deliverable - Key concepts of Learning as Optimization\tReflection, ReflectionAssignment DebriefLet’s bring our heads together and clear up any issues with the previous assignment.Motivating Example for Our Next AssignmentWe’ll be going over the concept of word embeddings using a combination of a mini-lecture and a Colab notebook.Quality Assessed Deliverable - Key concepts of Learning as OptimizationWe will take an in-class quiz on the key concepts of Learning as Optimization.As discussed last class:One of the quality assessed deliverables for this course is a check-in on Key Concepts of ML as Optimization. In class last week, you made concept maps of the course content related to ML as optimization. We are planning to use an in-class, on paper assessment. The goal of this assessment is for you to demonstrate your understanding of the key concepts related to ML as optimization (see this Learning As Optimization Takeaways for details about what we expect).While we know that you’ll be using external resources for any future ML work that you do, we want to take this time to check in about your conceptual understanding of key ideas. We also want you to get a sense of what you understand well enough to articulate, which may be different than what we understand well enough to nod along to. The assessment will be designed to be done without the need for external sources (if calculators are needed, we’ll let you use your phones for this part). Through some recent conversations, we’re wrestling with how to both extend trust and also not ask you to carry the burden of willpower to not use external resources for a take-home assessment. We’re curious to hear what you think about this!If you have any accommodations that we need to prepare for to make this assessment work for you, please let us know so we can best support you. Our tentative plan is to give lots of time to complete the assessment in class and have it be the last activity before lunch (so folks can leave when they are done without putting time pressure on folks who want more time).Please show up to class for this assessment if you can. If you are out sick, we can schedule a make-up time (tentative date is Wednesday afternoon).",
        "url": "/activities/day13.html"
      },"activities-day14-html": {
        "title": "Day 14: GPTs Part 1",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:40am: Brief additional reflection on assessment  10:40-12:00pm: GPT party\tReflection on assessment and courseIf you already filled out the 2019 version of the survey, please still fill this one out, but it’s fine to skip over the general course comments if you’ve already shared what you want to share in the other survey.  Again, sorry for the wrong link last time!GPT partyWe’ll start on the homework together by watching one of the 3B1B videos and pausing to talk through each of the steps.",
        "url": "/activities/day14.html"
      },"activities-day15-html": {
        "title": "Day 15: GPTs Part 2",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:40am: Brief reflection on mid-semester reflection  10:40-12:00pm: Choose your own GPT adventure\tReflection mid-semester reflectionWe’ll show a couple of the graphs from the survey.Choose your own GPT adventure (or let AI choose it for you)We’ll take a quick poll on what to do today. Here are our two proposed activities:  Continue watching 3B1B videos together, pausing to talk through what is happening and collecting the variables.  Work on the assignment at tables (individual or together) with office hours style help (survey mentioned that office hours have been helpful)  Something else that you all propose. Let’s take a few minutes at tables to see if you all come up with something else that would be more helpful that what we proposed.We’ll do some quick voting and then decide how to split the rooms.",
        "url": "/activities/day15.html"
      },"activities-day16-html": {
        "title": "Day 16: GPTs Part 3 and Context Discussion",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:40am: Debrief on last two assignments  10:45-11:20am: Discuss Prior Readings on Bias and Regulations  11:20-12:00pm: Preview of the next assignment\tDebrief on last two assignmentsWe have two assignments due today. We’ll give a little time to debrief and ask questions.Discuss Prior Readings on Bias and RegulationsOver the past two weeks, we had two readings that we’d now like to come back to:      In Assignment 11, we read sections 1-4 of the paper Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings.        In Assignment 13, we read the FACT SHEET: Biden-⁠Harris Administration Announces New AI Actions and Receives Additional Major Voluntary Commitment on AI.  You were asked to take notes on the main takeaways.  You were asked to (if you had time) follow at least one link from the document and writeup the main points of that report or resource.  Let’s form medium sized groups (6-12 people) and do some discussion on these.  Write the main points or themes of each reading on the board. Your group should write down at least 10 things.  Discuss the status of the government fact sheet. Here are some guiding questions (use them to the extent they are helpful for good conversation):          What were you already aware of?      What (if anything) were you surprised about?      Where do you think the US should be putting more or fewer resources?      What roles do you see engineers playing in this space? What about other disciplines?        Now go back to the Debiasing Word Embeddings paper. Here are some guiding questions (use them to the extent they are helpful for good conversation):          How did the paper attempt to remove bias?      How well did it work?      What other strategies could you imagine trying?      Do you think it’s easier to debias a person or a large language model? Why?      What questions are you wrestling with about removing bias? What’s the world you want these models to reflect?      Preview of the next assignmentWe’ll be wrapping up our exploration of LLMs with one last assignment Assignment 14 - Generative Pre-Trained Transformers (GPTs) Part 3.",
        "url": "/activities/day16.html"
      },"activities-day17-html": {
        "title": "Day 17: Goodbye Text, Hello Images and Convolution",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:50am: Closing out LLMs  10:50-12:00pm: Images as data\tShare-out your application of LLMsIn Assignment 14, we asked you to propose an application of an LLM for a context that you care about. We’ll do a share-out about our applications and possibly think about where they fall on some axes (e.g., at Olin or beyond; positive to negative; practical to whimsical).Identifying Gaps in KnowledgeLet’s return to the visualization from the exercise 1 of assignment 14.  With folks around you, identify aspects of the visualization that you don’t understand.  That is, what are the pieces in this diagram that we did not touch on in class thus far?Follow-up From ClassHi folks.  We wanted to take a little bit of time to clarify a few pieces of the walkthrough of the nano-GPT visualization.  The questions people asked were great, so hopefully this information can help.Point 1: In this visualization we have 3 attention heads.  Each attention head has its own independent matrices for computing keys, queries, and values.Point 2: The value vectors for each token in each of our 3 attention heads is 16-dimensional.  These 16-dimensional vectors are added together in a weighted fashion (with the weight given by the self-attention matrix) to compute the output of each attention head.Point 3: We stack the outputs of each attention head to get back to our original 48-dimensional space (the dimensionality of the embedding space is $C=48$).Point 4: We then take the vector from the previous step and pass it through a projection matrix to translate from whatever representations were learned by each attention head to something that is appropriate to add to the input embedding (via the residual pathway).  Amanda asked a brilliant question about this in class, which was why this translation is needed since all of the attention heads have the same inputs.  This is still a hard question to answer, and Jess Brown did a nice job offering a suggestion that each of the attention heads might learn a different internal meaning of value space (the $V$ matrix), and we need a linear mapping (a matrix) in order to combine these different value spaces (across heads) in a meaningful way. After reviewing the visualization again, there is one more way to explain this.  If we look back at this section of the 3B1B video we see two ways to think about computing value vectors in an attention head.We could (but don’t) think of the matrix, $\\mathbf{W_V}$, that maps from embeddings to value vectors as a $C \\times C$ matrix (where $C$ is the embedding dimension).  As Grant Sanderson, of 3B1B, points out, this approach would use many more parameters to represent the mapping from embeddings to value vectors (versus embeddings to keys or embeddings to queries).  To make the number of parameters similar between these three entities (keys, queries, and values), we can instead think of two steps for computing our value vectors.  First, we use a matrix $\\mathbf{V_\\downarrow}$ to go from the embedding space to a lower dimensional space (in the visualization we go from $C=48$ to $16$ dimensions).  Second, we use a matrix called $\\mathbf{V_\\uparrow}$ to go from the 16-dimensional representation back to the $48$ dimensional representation.  As Grant explains, this change to how we compute our value vectors constrains the number of parameters versus having $\\mathbf{W_V}$ as a $C \\times C$ (48 by 48) matrix.  Mapping this intuition onto our visualization of NanoGPT, we can think of the box labeled V Weights as playing the role of $\\mathbf{V_\\downarrow}$ and the box labeled Project Weights as containing the $\\mathbf{V_\\uparrow}$ matrices for each of the three attention heads (stacked).LLM Quality Assessed Deliverable and plans for the rest of the semesterWe’ll talk about the timeline (some details now added to the homepage).Images as dataLet’s discuss:What is different about images compared to a set of variables (like in the Titanic data set)? What about compared to text data?One common application of image data is in medical image processing. Here’s a few recent papers, including one about one about clinical trials.  McKinney, S.M., Sieniek, M., Godbole, V. et al. International evaluation of an AI system for breast cancer screening. Nature 577, 89–94 (2020). https://doi.org/10.1038/s41586-019-1799-6  Esteva, A., Chou, K., Yeung, S. et al. Deep learning-enabled medical computer vision. npj Digit. Med. 4, 5 (2021). https://doi.org/10.1038/s41746-020-00376-2  Abràmoff, M.D., Lavin, P.T., Birch, M. et al. Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care offices. npj Digital Med 1, 39 (2018). https://doi.org/10.1038/s41746-018-0040-6Preview of assignment and talking about convolutionWe’ll learn about convolutional neural networks to process images. First, we need to understand what a convolution means in this context.Assignment 15 - Images as Data and Convolutions",
        "url": "/activities/day17.html"
      },"activities-day18-html": {
        "title": "Day 18: Convolutional Neural Networks",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:30am: Quick ConvNet review  10:30-11:00am:ConvNets - What are they good for?  11:00-11:30pm: Image filter debrief  11:30-12:00pm: Next assignment preview\tOverview of a ConvNet/CNN/Convolutional Neural NetworkIn your assignment, you looked at some of:  This interactive visual overview of CNNs from a collaboration between Georgia Tech and Oregon State. This one will allow you to explore each of the layers and functions. You can click on each of the parts to see more. There’s a little video at the end that shows how to use the tool.  This write-up with some helpful visualizations by Ujjwal Karn.  One of the earlier types of these visualizations focused on handwritten numbers  by Adam Harley.  Training on MNIST in the browser by Karpathy. This one shows the weights and the gradients.You might have some questions, like:  I looked at the architecture, but I’m not sure if I could explain in. Can you help?  Why not do this whole thing as a bunch of fully connected layer?  Everyone loves to make these brain analogies, is this really what the brain does?ConvNets - What are they good for?At your tables, research an application of convolutional neural networks. Your objective is to find a meaningful, humorous, or otherwise interesting application to share with the larger class.You will come to the front, explain your application, and show something (an image, a video, a graph from a paper).Image filter debriefFilters: Not just to keep you from saying something you’ll regret. They also help ConvNets process images!In your assignment, you manually created filters to detect different properties of images (e.g., vertical lines). There are many correct ways to do this, and they may lead to different results. At tables, compare your filters and results with others. Be prepared to share one observation or comparison with the larger group.Next assignment previewWe’ll discuss the next assignment and get started.",
        "url": "/activities/day18.html"
      },"activities-day19-html": {
        "title": "Day 19: CNNs and GANs",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:45am:  Review CNNs  10:45-10:55am: Jess!  10:55-12:00pm: GANs\tSay hello to our guests (5 minutes)Hi guests! Come to Olin and be our students!Review CNNs (20 minutes)  Filter review  Loss functions: how to know when your model is overfitting or not learning  Transfer learning          Feature extractor      Freezing weights      Quality assessed deliverable preview (5 minutes)The quality assessed deliverable is now posted.Jess give a 5 minute talk! (10 minutes)Hmm… interesting time math!Yay, Jess!Generative Adversarial Networks (GANs)  (40 minutes)Let’s warm up with a little game: https://real-or-fake-the-ai-game.onrender.com/We will rotate which table is the decider (you have 6 seconds to decide).GAN simulation activity (30 minutes)A short video with a very general overview: https://youtu.be/X994dDnmRmYThere is lots of code out there with varying degrees of complexity, but one thing to note is that we’ve learned many of the basic building blocks. Example: https://github.com/sw-song/PyTorch-GAN/blob/master/implementations/dcgan/dcgan.pyBonus: Explore some fun image generation applications (alternative activity)We probably won’t get to these in class, but they could be interesting to explore (and may also help you think about your final project deliverables):  https://mitmedialab.github.io/GAN-play/  https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html  https://github.com/nashory/gans-awesome-applications  https://github.com/sw-song/PyTorch-GAN  https://github.com/ZZUTK/Face-Aging-CAAEAssignment preview - Project prep (5 minutes)It’s final project time! We are going to kick-off next class and share more details. However, we want you to take a little time to explore in preparation for coming up with a good final project. Our goal is that everyone leaves class Thursday with a final project idea and a partner (if they want one).",
        "url": "/activities/day19.html"
      },"activities-day20-html": {
        "title": "Day 20: Final Project Launch",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:45am: We’ll go over the final project deliverables and structure  10:45-11:00am: Discuss projects with folks sitting around you  11:00-12pm: Idea clustering and team formation\tOverview of Final Project StructureWe’ll walk you through the final project deliverables, due dates, and assessment.Discuss Projects at TablesYou had some time to think of final project topics and why they are important to you. Take some time and share with folks around you (aim for a group size of around 5) what you came up with.  As a listener feel free to offer additional ideas, mutual interest in the project, or useful clarifying questions (we won’t have time for long discussions though).Idea Clustering and Team FormationWrite your favorite ideas on Post-It notes and include your name.  Place the Post-Its on the board in the appropriate category.  Once the ideas are clustered, you can congregate by one of the clusters to find students who are interested in similar topics.  Through this process we hope you will find someone to work with or additional ideas for your own project topic (if you are working alone).If you are not able to find a partner (and want one) or could work alone but are open to having a partner, please fill out this survey no later than 5pm on Thursday November 14th.  If you have a partner already, you do not (and should not) fill out this survey.",
        "url": "/activities/day20.html"
      },"activities-day24-html": {
        "title": "Day 24: Energy Usage and Machine Learning Plus Project Worktime",
        "author": "",
        "category": "",
        "content": "\t\t        \tAgenda    \t\t     10:20-10:25am: Everyone come hang out in MAC128, we’ll talk about the plan and answer any logistics questions.  10:25-10:55am: Energy usage and machine learning  10:55-11:15am: Standups  11:15-12pm: Project work time\tEnergy Usage and Machine LearningWe’ll go over some slides related to machine learning and environmental impact (focused around energy use).StandupsWe’ll go over standups (link to deck is in Canvas)Project Worktime",
        "url": "/activities/day24.html"
      },"education-research-education-research-html": {
        "title": "Educational Research Opportunity",
        "author": "",
        "category": "",
        "content": "This semester, we are conducting a research study on student experiences within this course. Through this study, we hopeto better understand how the course affects things such as student motivation, interest and knowledge in human-centered design approachesfor machine learning, and the type of work students see themselves doing going forward.Your participation in this study is completely voluntary, and your grade will not depend onwhether or not participate.If you decide that you want to participate, you can read our informed consent form.  To enroll in the study, please return (either physically or electronically) asigned copy of the form to me (Paul Ruvolo).The data we collect for this study will include:  Pre-course and post-course surveys (each will take approximately 20 minutes).  These surveys are required to be done by all students in the course, but only the data from students who are participants will be used for research.  Reflection prompts, which will appear as part of some assignments.  Similar to (1), all students will be required to do these reflections, but we will only use responses from students in the study for research.  Interview or focus-group with Chelsea Andrews (Research Assistant Professor at Tufts University).  All students who participate in the research study, have the (optional) opportunity to meet with Chelsea Andrews to provide additional details about your experiences in the course.  Meetings will be available for individual conversations with Chelsea and focus-group sessions.  Unlike (1) and (2), if you are not part of the research study, you will not be required to do one of these sessions.",
        "url": "/education_research/education_research.html"
      },"": {
        "title": "Machine Learning Spring 2026",
        "author": "",
        "category": "",
        "content": "            Final projectFinal Project DocumentsIn-class ActivitiesSample solutions for in-class assignments will be made available on GitHub.            Day #      Activity                  1      Course intro and welcome to ML!              2      Community-Centered Design for Machine Learning              3      Model Validation and Community-centered Machine Learning              4      Metrics and Meeting ML as Optimization              5      Linear, Ridge, and Logistic Regression &amp; Train-Test Split              6      Day 5: \tLogistic Regression Sample Problem, Foundations of Micrograd              7      Day 6: Starting COMPAS and Building Towards Autodifferentiation              8      COMPAS discussion              9      From Micrograd to Pytorch              10      Pytorch Demystified and Trust and Trustworthiness in Machine Learning Systems              11      Cross Entropy, Privacy in ML Systems, and Small Data Project Kickoff              12      Project Shareout and Course Feedback              13      Word Embeddings Introduction              14      GPTs Part 1              15      GPTs Part 2              16      GPTs Part 3 and Context Discussion              17      Goodbye Text, Hello Images and Convolution              18      Convolutional Neural Networks              19      CNNs and GANs              20      Final Project Launch                  24      Energy Usage and Machine Learning Plus Project Worktime      Assignments            Due at beginning of class #      Assignment                  2      Assignment 1              3      Assignment 2              4      Assignment 3              5      Assignment 4              6      Assignment 5              7      Assignment 6              8      Assignment 7              9      Assignment 8              12      Small data project on classification              13      Bag of Words and Text Classification              14      Word Embeddings              15      Generative Pre-Trained Transformers (GPTs) Part 1              16      GPTs (part 2)              17      Generative Pre-Trained Transformers (GPTs) Part 3              18      Images as Data and Convolutions              19      Convolutional Neural Networks (ConvNets, CNNs) in Code              final event      Final Project      Other Important DocumentsNotation conventionsLearning as Optimization Key Concepts",
        "url": "/"
      },"assignments-assignment01-notation-conventions-html": {
        "title": "Notation Conventions",
        "author": "Machine Learning",
        "category": "",
        "content": "NotationScalarsWe will use lower-case, unbolded letters to refer to scalar quantities. For example, we would refer to the scalar quantity x using the following notation.\\[x\\]VectorsWe will use lower-case, bolded letters to refer to vector quantities. For example, we would refer to the vector quantity v using the following notation.\\[\\mathbf{v}\\]Vector IndexingWe will use the notation $v_i$ to refer to the i-th element of the vector $\\mathbf{v}$.Row Versus Column VectorsWhen we talk about a vector, unless otherwise specified, we will be referring to a column vector (i.e., a matrix with shape $d \\times 1$).MatricesWe will use upper-case, bolded letters to refer to matrix quantities. For example, we would refer to the matrix quantity A using the following notation.\\[\\mathbf{A}\\]Matrix Indexing  We will refer to the i-th column of the matrix $\\mathbf{A}$ as $\\mathbf{a}_{i}$.  We do not currently have a shorthand to refer to the i-th row of a matrix.  We will refer to the element at row $i$, column $j$ of matrix $\\mathbf{A}$ as $a_{i, j}$.Independent versus Dependent variablesWe will use x to refer to independent (i.e., input) variables and y to refer to dependent (i.e., output) variables. For instance, when describing training data, we will always use x to refer to the input variables and y to refer to the output variable.",
        "url": "/assignments/assignment01/notation_conventions.html"
      },"search-html": {
        "title": "Search Results",
        "author": "",
        "category": "",
        "content": "{% include search-box.html %}",
        "url": "/search.html"
      },"assets-css-main-css": {
        "title": "",
        "author": "",
        "category": "",
        "content": "@charset \"utf-8\";@import \"minimal-mistakes/skins/{{ site.minimal_mistakes_skin | default: 'default' }}\"; // skin@import \"minimal-mistakes\"; // main partialsimg.mermaid {  max-width: 75%;    height: auto;  }.notice blockquote {  font-style: normal;}.notice--success blockquote {    font-style: normal;}",
        "url": "/assets/css/main.css"
      },"assets-js-lunr-lunr-en-js": {
        "title": "",
        "author": "",
        "category": "",
        "content": "var idx = lunr(function () {  this.field('title')  this.field('excerpt')  this.field('categories')  this.field('tags')  this.ref('id')  this.pipeline.remove(lunr.trimmer)  for (var item in store) {    this.add({      title: store[item].title,      excerpt: store[item].excerpt,      categories: store[item].categories,      tags: store[item].tags,      id: item    })  }});$(document).ready(function() {  $('input#search').on('keyup', function () {    var resultdiv = $('#results');    var query = $(this).val().toLowerCase();    var result =      idx.query(function (q) {        query.split(lunr.tokenizer.separator).forEach(function (term) {          q.term(term, { boost: 100 })          if(query.lastIndexOf(\" \") != query.length-1){            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })          }          if (term != \"\"){            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })          }        })      });    resultdiv.empty();    resultdiv.prepend(''+result.length+' {{ site.data.ui-text[site.locale].results_found | default: \"Result(s) found\" }}');    for (var item in result) {      var ref = result[item].ref;      if(store[ref].teaser){        var searchitem =          ''+            ''+              ''+                ''+store[ref].title+''+              ''+              ''+                ''+              ''+              ''+store[ref].excerpt.split(\" \").splice(0,20).join(\" \")+'...'+            ''+          '';      }      else{    \t  var searchitem =          ''+            ''+              ''+                ''+store[ref].title+''+              ''+              ''+store[ref].excerpt.split(\" \").splice(0,20).join(\" \")+'...'+            ''+          '';      }      resultdiv.append(searchitem);    }  });});",
        "url": "/assets/js/lunr/lunr-en.js"
      },"assets-js-lunr-lunr-gr-js": {
        "title": "",
        "author": "",
        "category": "",
        "content": "step1list = new Array();step1list[\"ΦΑΓΙΑ\"] = \"ΦΑ\";step1list[\"ΦΑΓΙΟΥ\"] = \"ΦΑ\";step1list[\"ΦΑΓΙΩΝ\"] = \"ΦΑ\";step1list[\"ΣΚΑΓΙΑ\"] = \"ΣΚΑ\";step1list[\"ΣΚΑΓΙΟΥ\"] = \"ΣΚΑ\";step1list[\"ΣΚΑΓΙΩΝ\"] = \"ΣΚΑ\";step1list[\"ΟΛΟΓΙΟΥ\"] = \"ΟΛΟ\";step1list[\"ΟΛΟΓΙΑ\"] = \"ΟΛΟ\";step1list[\"ΟΛΟΓΙΩΝ\"] = \"ΟΛΟ\";step1list[\"ΣΟΓΙΟΥ\"] = \"ΣΟ\";step1list[\"ΣΟΓΙΑ\"] = \"ΣΟ\";step1list[\"ΣΟΓΙΩΝ\"] = \"ΣΟ\";step1list[\"ΤΑΤΟΓΙΑ\"] = \"ΤΑΤΟ\";step1list[\"ΤΑΤΟΓΙΟΥ\"] = \"ΤΑΤΟ\";step1list[\"ΤΑΤΟΓΙΩΝ\"] = \"ΤΑΤΟ\";step1list[\"ΚΡΕΑΣ\"] = \"ΚΡΕ\";step1list[\"ΚΡΕΑΤΟΣ\"] = \"ΚΡΕ\";step1list[\"ΚΡΕΑΤΑ\"] = \"ΚΡΕ\";step1list[\"ΚΡΕΑΤΩΝ\"] = \"ΚΡΕ\";step1list[\"ΠΕΡΑΣ\"] = \"ΠΕΡ\";step1list[\"ΠΕΡΑΤΟΣ\"] = \"ΠΕΡ\";step1list[\"ΠΕΡΑΤΑ\"] = \"ΠΕΡ\";step1list[\"ΠΕΡΑΤΩΝ\"] = \"ΠΕΡ\";step1list[\"ΤΕΡΑΣ\"] = \"ΤΕΡ\";step1list[\"ΤΕΡΑΤΟΣ\"] = \"ΤΕΡ\";step1list[\"ΤΕΡΑΤΑ\"] = \"ΤΕΡ\";step1list[\"ΤΕΡΑΤΩΝ\"] = \"ΤΕΡ\";step1list[\"ΦΩΣ\"] = \"ΦΩ\";step1list[\"ΦΩΤΟΣ\"] = \"ΦΩ\";step1list[\"ΦΩΤΑ\"] = \"ΦΩ\";step1list[\"ΦΩΤΩΝ\"] = \"ΦΩ\";step1list[\"ΚΑΘΕΣΤΩΣ\"] = \"ΚΑΘΕΣΤ\";step1list[\"ΚΑΘΕΣΤΩΤΟΣ\"] = \"ΚΑΘΕΣΤ\";step1list[\"ΚΑΘΕΣΤΩΤΑ\"] = \"ΚΑΘΕΣΤ\";step1list[\"ΚΑΘΕΣΤΩΤΩΝ\"] = \"ΚΑΘΕΣΤ\";step1list[\"ΓΕΓΟΝΟΣ\"] = \"ΓΕΓΟΝ\";step1list[\"ΓΕΓΟΝΟΤΟΣ\"] = \"ΓΕΓΟΝ\";step1list[\"ΓΕΓΟΝΟΤΑ\"] = \"ΓΕΓΟΝ\";step1list[\"ΓΕΓΟΝΟΤΩΝ\"] = \"ΓΕΓΟΝ\";v = \"[ΑΕΗΙΟΥΩ]\";v2 = \"[ΑΕΗΙΟΩ]\"function stemWord(w) {  var stem;  var suffix;  var firstch;  var origword = w;  test1 = new Boolean(true);  if(w.length '+result.length+' {{ site.data.ui-text[site.locale].results_found | default: \"Result(s) found\" }}');    for (var item in result) {      var ref = result[item].ref;      if(store[ref].teaser){        var searchitem =          ''+            ''+              ''+                ''+store[ref].title+''+              ''+              ''+                ''+              ''+              ''+store[ref].excerpt.split(\" \").splice(0,20).join(\" \")+'...'+            ''+          '';      }      else{    \t  var searchitem =          ''+            ''+              ''+                ''+store[ref].title+''+              ''+              ''+store[ref].excerpt.split(\" \").splice(0,20).join(\" \")+'...'+            ''+          '';      }      resultdiv.append(searchitem);    }  });});",
        "url": "/assets/js/lunr/lunr-gr.js"
      },"assets-js-lunr-lunr-store-js": {
        "title": "",
        "author": "",
        "category": "",
        "content": "var store = [  {%- for c in site.collections -%}    {%- if forloop.last -%}      {%- assign l = true -%}    {%- endif -%}    {%- assign docs = c.docs | where_exp:'doc','doc.search != false' -%}    {%- for doc in docs -%}      {%- if doc.header.teaser -%}        {%- capture teaser -%}{{ doc.header.teaser }}{%- endcapture -%}      {%- else -%}        {%- assign teaser = site.teaser -%}      {%- endif -%}      {        \"title\": {{ doc.title | jsonify }},        \"excerpt\":          {%- if site.search_full_content == true -%}            {{ doc.content | newline_to_br |              replace:\"\", \" \" |              replace:\"\", \" \" |              replace:\"\", \" \" |              replace:\"\", \" \" |              replace:\"\", \" \" |              replace:\"\", \" \" |              replace:\"\", \" \" |              replace:\"\", \" \"|            strip_html | strip_newlines | jsonify }},          {%- else -%}            {{ doc.content | newline_to_br |              replace:\"\", \" \" |              replace:\"\", \" \" |              replace:\"\", \" \" |              replace:\"\", \" \" |              replace:\"\", \" \" |              replace:\"\", \" \" |              replace:\"\", \" \" |              replace:\"\", \" \"|            strip_html | strip_newlines | truncatewords: 50 | jsonify }},          {%- endif -%}        \"categories\": {{ doc.categories | jsonify }},        \"tags\": {{ doc.tags | jsonify }},        \"url\": {{ doc.url | absolute_url | jsonify }},        \"teaser\":          {%- if teaser contains \"://\" -%}            {{ teaser | jsonify }}          {%- else -%}            {{ teaser | absolute_url | jsonify }}          {%- endif -%}      }{%- unless forloop.last and l -%},{%- endunless -%}    {%- endfor -%}  {%- endfor -%}]",
        "url": "/assets/js/lunr/lunr-store.js"
      },"activities-totallyfine-html": {
        "title": "",
        "author": "",
        "category": "",
        "content": "Totally not phishing...... but maybe fishing.  Wow, that was a long way to go for a terrible joke.",
        "url": "/activities/totallyFine.html"
      },"feed-xml": {
        "title": "",
        "author": "",
        "category": "",
        "content": "{% if page.xsl %}{% endif %}Jekyll{{ site.time | date_to_xmlschema }}{{ page.url | absolute_url | xml_escape }}{% assign title = site.title | default: site.name %}{% if page.collection != \"posts\" %}{% assign collection = page.collection | capitalize %}{% assign title = title | append: \" | \" | append: collection %}{% endif %}{% if page.category %}{% assign category = page.category | capitalize %}{% assign title = title | append: \" | \" | append: category %}{% endif %}{% if title %}{{ title | smartify | xml_escape }}{% endif %}{% if site.description %}{{ site.description | xml_escape }}{% endif %}{% if site.author %}{{ site.author.name | default: site.author | xml_escape }}{% if site.author.email %}{{ site.author.email | xml_escape }}{% endif %}{% if site.author.uri %}{{ site.author.uri | xml_escape }}{% endif %}{% endif %}{% if page.tags %}{% assign posts = site.tags[page.tags] %}{% else %}{% assign posts = site[page.collection] %}{% endif %}{% if page.category %}{% assign posts = posts | where: \"categories\", page.category %}{% endif %}{% unless site.show_drafts %}{% assign posts = posts | where_exp: \"post\", \"post.draft != true\" %}{% endunless %}{% assign posts = posts | sort: \"date\" | reverse %}{% assign posts_limit = site.feed.posts_limit | default: 10 %}{% for post in posts limit: posts_limit %}{% assign post_title = post.title | smartify | strip_html | normalize_whitespace | xml_escape %}{{ post_title }}{{ post.date | date_to_xmlschema }}{{ post.last_modified_at | default: post.date | date_to_xmlschema }}{{ post.id | absolute_url | xml_escape }}{% assign excerpt_only = post.feed.excerpt_only | default: site.feed.excerpt_only %}{% unless excerpt_only %}{% endunless %}{% assign post_author = post.author | default: post.authors[0] | default: site.author %}{% assign post_author = site.data.authors[post_author] | default: post_author %}{% assign post_author_email = post_author.email | default: nil %}{% assign post_author_uri = post_author.uri | default: nil %}{% assign post_author_name = post_author.name | default: post_author %}{{ post_author_name | default: \"\" | xml_escape }}{% if post_author_email %}{{ post_author_email | xml_escape }}{% endif %}{% if post_author_uri %}{{ post_author_uri | xml_escape }}{% endif %}{% if post.category %}{% elsif post.categories %}{% for category in post.categories %}{% endfor %}{% endif %}{% for tag in post.tags %}{% endfor %}{% assign post_summary = post.description | default: post.excerpt %}{% if post_summary and post_summary != empty %}{% endif %}{% assign post_image = post.image.path | default: post.image %}{% if post_image %}{% unless post_image contains \"://\" %}{% assign post_image = post_image | absolute_url %}{% endunless %}{% endif %}{% endfor %}",
        "url": "/feed.xml"
      },"sitemap-xml": {
        "title": "",
        "author": "",
        "category": "",
        "content": "{% if page.xsl %}{% endif %}{% assign collections = site.collections | where_exp:'collection','collection.output != false' %}{% for collection in collections %}{% assign docs = collection.docs | where_exp:'doc','doc.sitemap != false' %}{% for doc in docs %}{{ doc.url | replace:'/index.html','/' | absolute_url | xml_escape }}{% if doc.last_modified_at or doc.date %}{{ doc.last_modified_at | default: doc.date | date_to_xmlschema }}{% endif %}{% endfor %}{% endfor %}{% assign pages = site.html_pages | where_exp:'doc','doc.sitemap != false' | where_exp:'doc','doc.url != \"/404.html\"' %}{% for page in pages %}{{ page.url | replace:'/index.html','/' | absolute_url | xml_escape }}{% if page.last_modified_at %}{{ page.last_modified_at | date_to_xmlschema }}{% endif %}{% endfor %}{% assign static_files = page.static_files | where_exp:'page','page.sitemap != false' | where_exp:'page','page.name != \"404.html\"' %}{% for file in static_files %}{{ file.path | replace:'/index.html','/' | absolute_url | xml_escape }}{{ file.modified_time | date_to_xmlschema }}{% endfor %}",
        "url": "/sitemap.xml"
      },"robots-txt": {
        "title": "",
        "author": "",
        "category": "",
        "content": "Sitemap: {{ \"sitemap.xml\" | absolute_url }}",
        "url": "/robots.txt"
      }};
</script>

<!-- Import lunr.js from unpkg.com -->
<script src="https://unpkg.com/lunr/lunr.js"></script>

<!-- Custom search script which we will create below -->
<script src="/js/search.js"></script>


        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      
    </div>

    
  </article>

  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 Machine Learning Spring 2026 @ Olin College.</div>

      </footer>
    </div>

    <script src="/assets/js/copyCode.js"></script>


  <script src="/assets/js/main.min.js"></script>
  <script src="https://kit.fontawesome.com/4eee35f757.js"></script>










  </body>
</html>
