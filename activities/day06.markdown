---
title: "Day 5: 	Logistic Regression Sample Problem, Foundations of Micrograd"
toc_sticky: true 
toc_h_max: 1
layout: problemset
published: true
---

{% capture agenda %}
* 10:20-10:25am: Everyone come hang out in MAC128, we'll talk about the plan and answer any logistics questions.
* 10:25-10:35am: Debrief at tables
* 10:35-11:00am: Logistic Regression Example Problem
* 10:50-11:30am: Logistic Regression Learning Rule
* 11:30-12:00pm: Foundations of Micrograd
{% endcapture %}

{% include agenda.html content=agenda %}

# Debrief on the last assignment (10 minutes)

Warm up your brains by refreshing on the last assignment.  As a reminder, some of the big ideas were classification algorithms, log loss, and confounding variables.

# Logistic Regression Example Problem (25 minutes)

We're now going to be diving into logistic regression.  We'll start out by writing the basic ideas of logistic regression up on the board, and we'll go through a notebook that shows a sample problem.

The content we're going to use for this is contained in [the beginning part of assignment 5](../assignments/assignment05/assignment05#the-logistic-regression-model).  Let's jump over there and look at it together.

Next, we're going to go thorugh a Colab notebook that shows [an example logistic regresion problem](https://colab.research.google.com/drive/1xpGvY-kg7-HOC7_To0nMZIOOHQ_Yxd89?usp=sharing).

# Logistic Regression Learning Rule (40 minutes)

Let's use [assignment 5](../assignments/assignment05/assignment05) to begin to unpack some of the concepts behind choosing the best set of weights for logistic regression.  Before we start, we'll go over our high-level strategy.

# Foundations of Micrograd

Let's use [assignment 5](../assignments/assignment05/assignment05) to build some of the foudnations we're going to need to optimize a wide range of machine learning models given a trainig set.